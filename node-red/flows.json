[
    {
        "id": "dd55f774d9b5b325",
        "type": "tab",
        "label": "Ingest Shelly MQTT",
        "disabled": false,
        "info": "",
        "env": []
    },
    {
        "id": "ac9683af7e82fb53",
        "type": "tab",
        "label": "Analysis API",
        "disabled": false,
        "info": "**Purpose:** This flow provides the backend API endpoint (`/api/analyze`) for the \"Energy Analysis Dashboard\" frontend page. It is responsible for fetching a detailed time-series dataset based on user selections, running a complex Python script to perform statistical and machine learning analysis, and returning the results to the user for visualization.",
        "env": []
    },
    {
        "id": "3248d6a231f4e9d0",
        "type": "tab",
        "label": "Live Predictor",
        "disabled": false,
        "info": "**Purpose:** This flow runs on a schedule to generate real-time power consumption predictions for all active Prusa printers. It uses a pre-trained machine learning model to make these predictions. The results are stored in the `ml_predictions` table, which allows Grafana to display a \"Predicted vs. Actual\" power graph.",
        "env": []
    },
    {
        "id": "fa2590c7f7889790",
        "type": "tab",
        "label": "Fetch Environmental Data",
        "disabled": false,
        "info": "",
        "env": []
    },
    {
        "id": "249c21de5a8d56e0",
        "type": "tab",
        "label": "DPP API",
        "disabled": false,
        "info": "",
        "env": []
    },
    {
        "id": "44c225e855f817f8",
        "type": "tab",
        "label": "ESP Sensors",
        "disabled": false,
        "info": "",
        "env": []
    },
    {
        "id": "28ad1cc5547cbab4",
        "type": "tab",
        "label": "SimplyPrint Ingestion",
        "disabled": true,
        "info": "",
        "env": []
    },
    {
        "id": "c4582a5c3c4d6d09",
        "type": "tab",
        "label": "Master Ingestion Flow",
        "disabled": false,
        "info": "",
        "env": []
    },
    {
        "id": "088fab733419c707",
        "type": "tab",
        "label": "Historical Enrichment",
        "disabled": false,
        "info": "**Purpose:** This flow acts as a dedicated sub-routine for printers managed by the SimplyPrint cloud service. Its primary goal is to enrich the print job data with detailed information that is not available in the initial, high-level status poll.\r\n\r\n**Triggered By:** The \"Call Job Detail Subflow\" `link out` node in the `Master Ingestion Flow`.\r\n\r\n**Process:**\r\n1.  Receives live printer data and triggers a detailed API call to SimplyPrint for the currently active job.\r\n2.  Merges this detailed job data (which includes `customFields`, filament usage, etc.) with the live status.\r\n3.  Detects job start/end transitions to trigger energy calculations.\r\n4.  Triggers the G-code download and analysis process to get thumbnails and per-part data.\r\n5.  Outputs standardized messages to the main flow's `Data Output` section to update the `print_jobs` and `printer_status` tables.",
        "env": []
    },
    {
        "id": "efc63501e85537ea",
        "type": "tab",
        "label": "Job Energy Subflow",
        "disabled": false,
        "info": "**Purpose:** This sub-flow is responsible for a single, critical task: recording the cumulative energy meter reading (`energy_total_wh`) at the precise moment a new print job begins.\r\n\r\n**Triggered By:** The `Master Ingestion Flow` or the `Historical Enrichment Flow` when they detect a printer has transitioned from a non-printing to a printing state.\r\n\r\n**Process:**\r\n1.  Receives a trigger with the `device_id` and `filename`.\r\n2.  Waits a few seconds to ensure the `energy_data` table has been updated.\r\n3.  Checks if the `start_energy_wh` for this job has already been recorded.\r\n4.  If not, it fetches the latest `energy_total_wh` for the device.\r\n5.  It then updates the `print_jobs` table, setting the `start_energy_wh` to this value. This value is essential for calculating the final `session_energy_wh` when the job is complete.",
        "env": []
    },
    {
        "id": "f7f46f6cd7efe35e",
        "type": "tab",
        "label": "Flow 2",
        "disabled": false,
        "info": "**Purpose:** This sub-flow is responsible for the final energy calculation once a print job is complete.\r\n\r\n**Triggered By:** The `Master Ingestion Flow` or the `Historical Enrichment Flow` when they detect a printer has transitioned from a printing to a non-printing state.\r\n\r\n**Process:**\r\n1.  Receives a trigger with the `device_id` and `filename`.\r\n2.  Constructs and executes a single atomic SQL query.\r\n3.  This query fetches the latest cumulative energy reading, calculates the difference from the stored `start_energy_wh`, and saves the result in the `session_energy_wh` column of the `print_jobs` table.",
        "env": []
    },
    {
        "id": "e0b137ff47432f2e",
        "type": "group",
        "z": "44c225e855f817f8",
        "name": "MPU6050 ",
        "style": {
            "label": true
        },
        "nodes": [
            "5e9c772230c2d4b1",
            "fc75ba5343df4163",
            "93d1043233d62247"
        ],
        "x": 48,
        "y": 273,
        "w": 1474,
        "h": 834
    },
    {
        "id": "ce458d19dac54c24",
        "type": "group",
        "z": "44c225e855f817f8",
        "name": "MAX6675 K-Type Thermocouple Temperature:",
        "style": {
            "label": true
        },
        "nodes": [
            "024bf21a6248a91b",
            "8cc82821c9778c40",
            "1be94df15edd18b0",
            "3a967bc486f43c82",
            "cdf20cc9119bd677",
            "798789cfc80de203"
        ],
        "x": 74,
        "y": 1159,
        "w": 1032,
        "h": 142
    },
    {
        "id": "3227026642a6ed7d",
        "type": "group",
        "z": "44c225e855f817f8",
        "name": "DHT22 Temp & Humidity ",
        "style": {
            "label": true
        },
        "nodes": [
            "77f68480bd37ebd6",
            "4fb96e9054bdf405",
            "3e01886783462c76",
            "777b7e75e17f5c70",
            "b04fbf43fa8829ce",
            "7ef660eb1fcdad18",
            "2d1a2e9c46e83e5e",
            "883aea39948696ea",
            "ada47b8b28f15571",
            "eb13bac943346fd7"
        ],
        "x": 274,
        "y": 19,
        "w": 1072,
        "h": 222
    },
    {
        "id": "75074842157a7df5",
        "type": "group",
        "z": "44c225e855f817f8",
        "name": "Smart Plug",
        "style": {
            "label": true
        },
        "nodes": [
            "7a4b6bd3f341238a",
            "d3de12f14d0f6a67",
            "3549f4574b9800c8",
            "2e2665c651268a2b",
            "567460cf38ab8b90",
            "b8b9fa1094ca6c9c"
        ],
        "x": 54,
        "y": 1319,
        "w": 692,
        "h": 222
    },
    {
        "id": "b1bed7a2a4a4d39a",
        "type": "group",
        "z": "c4582a5c3c4d6d09",
        "name": "Data Input & Routing",
        "style": {
            "label": true
        },
        "nodes": [
            "02ea663491d7ef4b",
            "d6bbc141d674690b",
            "3bf69c618d3771ca",
            "b27da203e5c23ee9",
            "f4ec324598c62401",
            "ea15470d20a551d0",
            "2ad6a970bba49d5f",
            "f297e1970a6e9404",
            "5dda7fb58e2cb2a2",
            "9745ef2b3e3aa7e2",
            "e4a60772850676ff",
            "574260bbc0dc2b2f",
            "f3858a8857ffde13",
            "d43ff076a1a9a7bf",
            "b9a4c25e40aeeef0",
            "d72cfa8a09b4ac1a",
            "8df1e9e0aa3c3d82",
            "153a9432435bf76b",
            "23ca3a3983ca05ef",
            "7633245e76a0f219",
            "18c9e99643ee6bcd",
            "7e24e1bcd17d804e",
            "fa5fe3526a66b815",
            "ad0abf33e2e61735",
            "08941a4001c4ec9a"
        ],
        "x": 14,
        "y": 59,
        "w": 1652,
        "h": 702
    },
    {
        "id": "39cad17b39cec1d1",
        "type": "group",
        "z": "c4582a5c3c4d6d09",
        "name": "Data Processing & Enrichment",
        "style": {
            "stroke": "#0070c0",
            "label": true
        },
        "nodes": [
            "3bc77aad3c1f970d",
            "5a0b6ccc23334296",
            "6d7486e2afc97f13",
            "9fb13978446f7b8a",
            "8b6805e59ca0e048",
            "e5f04ef6f5bc94fc",
            "060a8b27d87f8bf9",
            "81d3cb6157d204a7",
            "38850782ee90eabb",
            "bfb231c8765823a8",
            "76e36f5c70691ad5",
            "76faa27c3f22fa95",
            "6f5a6bdde6455ef0",
            "abc0bca12f6f89e4",
            "721f5a33a2061419",
            "f81e90cc3d42a0f9",
            "52a6268367a8d644",
            "af3255605d249b0d",
            "c59b3ae72ac4073a",
            "075caf0daf376cc6",
            "de12c14d1a3c57d5",
            "f56cc50a4481ddce",
            "31b1ea47700de376",
            "4958a8c7f64eaabd",
            "af950d41f1c8252e",
            "b8edd70e91510d03",
            "19af9013e2ec06d3",
            "cb5a40c591c23af4",
            "c4637953a58714ae",
            "95202ab5fa233a47",
            "cda295997d384d1b",
            "3893c4f9f6dfef59",
            "1a68329a7809840d",
            "853372a55c401c65"
        ],
        "x": 1714,
        "y": 419,
        "w": 2112,
        "h": 762,
        "info": "This group takes the raw API data, parses it, standardizes it, detects job state changes, and triggers further enrichment processes."
    },
    {
        "id": "5f3f1baac114fb7c",
        "type": "group",
        "z": "c4582a5c3c4d6d09",
        "name": "Data Output",
        "style": {
            "stroke": "#92d04f",
            "label": true
        },
        "nodes": [
            "434602b76f18b34a",
            "bf152e33e1198b2b",
            "2686e15ef3e6984e",
            "af2f0b8c71e0ef6c",
            "711e7c68cc8edf38",
            "f571406301ee9470",
            "526fc8f040df3cba"
        ],
        "x": 2774,
        "y": 59,
        "w": 552,
        "h": 322
    },
    {
        "id": "97c76169fe166c15",
        "type": "group",
        "z": "3248d6a231f4e9d0",
        "name": "Data Input",
        "style": {
            "label": true
        },
        "nodes": [
            "766af32f4fe6ef26",
            "fb200dd03d87ca0a",
            "727ae746539a786d"
        ],
        "x": 54,
        "y": 119,
        "w": 312,
        "h": 202
    },
    {
        "id": "9c69214ff198d9d8",
        "type": "group",
        "z": "3248d6a231f4e9d0",
        "name": "Data Processing",
        "style": {
            "label": true
        },
        "nodes": [
            "5e276bfbbd3f9bb6",
            "f3cf04893924fa13",
            "ebffcd036e7af362",
            "3be8ddb37a93844d"
        ],
        "x": 454,
        "y": 239,
        "w": 312,
        "h": 262
    },
    {
        "id": "ac90879e0d7b329f",
        "type": "group",
        "z": "3248d6a231f4e9d0",
        "name": "Data Output",
        "style": {
            "label": true
        },
        "nodes": [
            "fb9f1203b23b0fbc",
            "c67612e2cda72292"
        ],
        "x": 834,
        "y": 419,
        "w": 272,
        "h": 142
    },
    {
        "id": "9e77943c233db3eb",
        "type": "group",
        "z": "ac9683af7e82fb53",
        "name": "Data Input",
        "style": {
            "label": true
        },
        "nodes": [
            "4918b67096adabfe",
            "e0f4357542e2412b"
        ],
        "x": 14,
        "y": 459,
        "w": 532,
        "h": 82
    },
    {
        "id": "6382c2e9dcb135c5",
        "type": "group",
        "z": "ac9683af7e82fb53",
        "name": "Data Processing",
        "style": {
            "label": true
        },
        "nodes": [
            "9f67b80add894bed",
            "fd667af16fc7af70",
            "970bdc8e3cb051e8"
        ],
        "x": 594,
        "y": 59,
        "w": 392,
        "h": 202
    },
    {
        "id": "4080a0de8969fa04",
        "type": "group",
        "z": "ac9683af7e82fb53",
        "name": "Data Output",
        "style": {
            "label": true,
            "stroke": "#0070c0"
        },
        "nodes": [
            "fc3e800f7322b583",
            "d69fce717cce3024",
            "c998f79c73ca0cda",
            "3dad15f0c8d11ced",
            "3592a09331fdbdbd",
            "2dc8f0c00c0dd79f"
        ],
        "x": 1034,
        "y": 239,
        "w": 992,
        "h": 302
    },
    {
        "id": "d46e71e1a4ec093a",
        "type": "group",
        "z": "088fab733419c707",
        "name": "Data Input & API Call",
        "style": {
            "label": true
        },
        "nodes": [
            "31749266865874cf",
            "9253f90316936f73",
            "4582f5ee6c82a831",
            "856d2b19e2a0d021",
            "bc7506c79a70c5d8"
        ],
        "x": 234,
        "y": 239,
        "w": 752,
        "h": 362
    },
    {
        "id": "2406f1dc5d32b76a",
        "type": "group",
        "z": "088fab733419c707",
        "name": "Data Processing & Output Triggering",
        "style": {
            "label": true
        },
        "nodes": [
            "4abf6ef935ae28bb",
            "566c89287199eab1",
            "d980d78960bfd999",
            "235f4c81c8825e75",
            "11be79141838bc02"
        ],
        "x": 1074,
        "y": 319,
        "w": 652,
        "h": 242
    },
    {
        "id": "ec87e2210a0fba2e",
        "type": "group",
        "z": "088fab733419c707",
        "name": "G-code Analysis Pipeline",
        "style": {
            "label": true
        },
        "nodes": [
            "548b0a238325e0b8",
            "70cdf05dcd27462d",
            "7ac7a420743ace0c",
            "a6a79f6ee9526497",
            "1895161b40f4b2c6",
            "a849c171e8e54fe4",
            "fa016904d46e14e2",
            "637017bc129598ca"
        ],
        "x": 1434,
        "y": 619,
        "w": 752,
        "h": 402
    },
    {
        "id": "5e9c772230c2d4b1",
        "type": "group",
        "z": "44c225e855f817f8",
        "g": "e0b137ff47432f2e",
        "name": "MPU6050 Accelerometer",
        "style": {
            "label": true
        },
        "nodes": [
            "f77d140fdd22352b",
            "2d183ac8c2d9dfd3",
            "3fecf642c398afec",
            "0c59e6a6c648cb94",
            "2fd609f72fb77e4b",
            "2b0a996e7caaa58d",
            "01929e1883714b74",
            "aa107ae95410814c",
            "341fbee8495b1bd8",
            "0abcfd1a02f4a19a",
            "642a28ac55077c32",
            "03ba2dc03bc7ac47",
            "d6ac7d1660c10d16",
            "4d42faa80d69d4e3",
            "c76f96030d02bb57"
        ],
        "x": 74,
        "y": 299,
        "w": 1422,
        "h": 282
    },
    {
        "id": "fc75ba5343df4163",
        "type": "group",
        "z": "44c225e855f817f8",
        "g": "e0b137ff47432f2e",
        "name": "MPU6050 Gyroscope",
        "style": {
            "label": true
        },
        "nodes": [
            "8950e05ca866624d",
            "7dc2945d2e4ddd8b",
            "52fdc90785b7a1d7",
            "f72a1cf8c3a8820c",
            "60e80e7a6e1a6906",
            "5396a4653d7c0e57",
            "30ea1788a5f64e85",
            "8e0e73e8a1d28b6f",
            "c7e3549eb6f42dda",
            "34f84b9d88038512"
        ],
        "x": 74,
        "y": 679,
        "w": 1092,
        "h": 202
    },
    {
        "id": "93d1043233d62247",
        "type": "group",
        "z": "44c225e855f817f8",
        "g": "e0b137ff47432f2e",
        "name": "MPU6050 Temperature",
        "style": {
            "label": true
        },
        "nodes": [
            "1fa08ed00a895506",
            "4816faa0ed4ee79e",
            "d23eed6a980f1398",
            "857d777ce2057c48",
            "a397a019ff154ae9",
            "ca5aa4b3df152834"
        ],
        "x": 94,
        "y": 959,
        "w": 992,
        "h": 122
    },
    {
        "id": "becc22b8f4461a4d",
        "type": "mqtt-broker",
        "name": "",
        "broker": "89.252.166.188",
        "port": "2010",
        "clientid": "",
        "autoConnect": true,
        "usetls": false,
        "protocolVersion": "4",
        "keepalive": "60",
        "cleansession": true,
        "autoUnsubscribe": true,
        "birthTopic": "",
        "birthQos": "0",
        "birthRetain": "false",
        "birthPayload": "",
        "birthMsg": {},
        "closeTopic": "",
        "closeQos": "0",
        "closeRetain": "false",
        "closePayload": "",
        "closeMsg": {},
        "willTopic": "",
        "willQos": "0",
        "willRetain": "false",
        "willPayload": "",
        "willMsg": {},
        "userProps": "",
        "sessionExpiry": ""
    },
    {
        "id": "07bb42ebce915296",
        "type": "websocket-listener",
        "path": "/ws/plant",
        "wholemsg": "true"
    },
    {
        "id": "349f15e91de8b866",
        "type": "websocket-listener",
        "path": "ws/panel",
        "wholemsg": "true"
    },
    {
        "id": "54b96f2e51565f4f",
        "type": "postgreSQLConfig",
        "name": "",
        "host": "192.168.1.102",
        "hostFieldType": "str",
        "port": "5432",
        "portFieldType": "num",
        "database": "iot_project",
        "databaseFieldType": "str",
        "ssl": "false",
        "sslFieldType": "bool",
        "applicationName": "",
        "applicationNameType": "str",
        "max": "10",
        "maxFieldType": "num",
        "idle": "1000",
        "idleFieldType": "num",
        "connectionTimeout": "10000",
        "connectionTimeoutFieldType": "num",
        "user": "postgres",
        "userFieldType": "str",
        "password": "raptorblingx",
        "passwordFieldType": "str"
    },
    {
        "id": "4259e91acb63e17b",
        "type": "postgreSQLConfig",
        "name": "",
        "host": "localhost",
        "hostFieldType": "str",
        "port": 5432,
        "portFieldType": "num",
        "database": "reg_ml",
        "databaseFieldType": "str",
        "ssl": "false",
        "sslFieldType": "bool",
        "applicationName": "",
        "applicationNameType": "str",
        "max": 10,
        "maxFieldType": "num",
        "idle": 1000,
        "idleFieldType": "num",
        "connectionTimeout": 10000,
        "connectionTimeoutFieldType": "num",
        "user": "reg_ml",
        "userFieldType": "str",
        "password": "raptorblingx",
        "passwordFieldType": "str"
    },
    {
        "id": "aba5185255ddcebc",
        "type": "ui_tab",
        "name": "Home",
        "icon": "dashboard",
        "disabled": false,
        "hidden": false
    },
    {
        "id": "ef780fb3df2addd5",
        "type": "ui_base",
        "theme": {
            "name": "theme-light",
            "lightTheme": {
                "default": "#0094CE",
                "baseColor": "#0094CE",
                "baseFont": "-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif",
                "edited": true,
                "reset": false
            },
            "darkTheme": {
                "default": "#097479",
                "baseColor": "#097479",
                "baseFont": "-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif",
                "edited": false
            },
            "customTheme": {
                "name": "Untitled Theme 1",
                "default": "#4B7930",
                "baseColor": "#4B7930",
                "baseFont": "-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif"
            },
            "themeState": {
                "base-color": {
                    "default": "#0094CE",
                    "value": "#0094CE",
                    "edited": false
                },
                "page-titlebar-backgroundColor": {
                    "value": "#0094CE",
                    "edited": false
                },
                "page-backgroundColor": {
                    "value": "#fafafa",
                    "edited": false
                },
                "page-sidebar-backgroundColor": {
                    "value": "#ffffff",
                    "edited": false
                },
                "group-textColor": {
                    "value": "#1bbfff",
                    "edited": false
                },
                "group-borderColor": {
                    "value": "#ffffff",
                    "edited": false
                },
                "group-backgroundColor": {
                    "value": "#ffffff",
                    "edited": false
                },
                "widget-textColor": {
                    "value": "#111111",
                    "edited": false
                },
                "widget-backgroundColor": {
                    "value": "#0094ce",
                    "edited": false
                },
                "widget-borderColor": {
                    "value": "#ffffff",
                    "edited": false
                },
                "base-font": {
                    "value": "-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif"
                }
            },
            "angularTheme": {
                "primary": "indigo",
                "accents": "blue",
                "warn": "red",
                "background": "grey",
                "palette": "light"
            }
        },
        "site": {
            "name": "Node-RED Dashboard",
            "hideToolbar": "false",
            "allowSwipe": "false",
            "lockMenu": "false",
            "allowTempTheme": "true",
            "dateFormat": "DD/MM/YYYY",
            "sizes": {
                "sx": 48,
                "sy": 48,
                "gx": 6,
                "gy": 6,
                "cx": 6,
                "cy": 6,
                "px": 0,
                "py": 0
            }
        }
    },
    {
        "id": "cc368f00d628f650",
        "type": "ui_group",
        "name": "Printer Status",
        "tab": "aba5185255ddcebc",
        "order": 1,
        "disp": true,
        "width": 6,
        "collapse": false,
        "className": ""
    },
    {
        "id": "0a4d318485c9397e",
        "type": "mqtt-broker",
        "name": "Factory MQTT Broker",
        "broker": "192.168.188.117",
        "port": 1883,
        "clientid": "",
        "autoConnect": true,
        "usetls": false,
        "protocolVersion": 4,
        "keepalive": 60,
        "cleansession": true,
        "autoUnsubscribe": true,
        "birthTopic": "",
        "birthQos": "0",
        "birthRetain": "false",
        "birthPayload": "",
        "birthMsg": {},
        "closeTopic": "",
        "closeQos": "0",
        "closeRetain": "false",
        "closePayload": "",
        "closeMsg": {},
        "willTopic": "",
        "willQos": "0",
        "willRetain": "false",
        "willPayload": "",
        "willMsg": {},
        "userProps": "",
        "sessionExpiry": ""
    },
    {
        "id": "ade67355fcb97ddd",
        "type": "ui_tab",
        "name": "Energy Monitor",
        "icon": "dashboard",
        "disabled": false,
        "hidden": false
    },
    {
        "id": "cf221fa6ee204f3b",
        "type": "ui_group",
        "name": "Device & Time Selection",
        "tab": "ade67355fcb97ddd",
        "order": 1,
        "disp": true,
        "width": 6,
        "collapse": false,
        "className": ""
    },
    {
        "id": "d801508db4a27b0e",
        "type": "ui_group",
        "name": "Analysis Results",
        "tab": "ade67355fcb97ddd",
        "order": 2,
        "disp": true,
        "width": "12",
        "collapse": false,
        "className": ""
    },
    {
        "id": "d067a7043abd1aac",
        "type": "ui_tab",
        "name": "Driver Selection",
        "icon": "dashboard",
        "disabled": false,
        "hidden": false
    },
    {
        "id": "7a33b08f7dea1389",
        "type": "ui_group",
        "name": "Driver Selection",
        "tab": "ade67355fcb97ddd",
        "order": 1,
        "disp": true,
        "width": 6,
        "collapse": false,
        "className": ""
    },
    {
        "id": "f412573e54535aac",
        "type": "ui_tab",
        "name": "Printer Tuning",
        "icon": "dashboard",
        "disabled": false,
        "hidden": false
    },
    {
        "id": "2b76591607efec25",
        "type": "ui_group",
        "name": "Printer Tuning",
        "tab": "f412573e54535aac",
        "order": 1,
        "disp": true,
        "width": 6,
        "collapse": false,
        "className": ""
    },
    {
        "id": "88830791c1951941",
        "type": "tls-config",
        "name": "",
        "cert": "",
        "key": "",
        "ca": "",
        "certname": "",
        "keyname": "",
        "caname": "",
        "servername": "",
        "verifyservercert": false,
        "alpnprotocol": ""
    },
    {
        "id": "3b44ba5a1dc552c7",
        "type": "mqtt in",
        "z": "dd55f774d9b5b325",
        "name": "Shelly Status In",
        "topic": "+/status/switch:0",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 180,
        "y": 260,
        "wires": [
            [
                "6011c11b42aa9370"
            ]
        ],
        "info": "**Purpose:** Subscribes to the MQTT topics for all Shelly smart plugs. This is the primary entry point for live energy data.\n\n**Topic:** `+/status/switch:0`\n- The `+` is a single-level wildcard that captures the unique `shelly_id` from the topic (e.g., `SPPS-02`).\n\n**Output:**\n- `msg.topic`: The full topic string.\n- `msg.payload`: A JSON object containing the status report from the Shelly device, including power, energy, and voltage."
    },
    {
        "id": "6011c11b42aa9370",
        "type": "function",
        "z": "dd55f774d9b5b325",
        "name": "Parse Shelly Data",
        "func": "// msg.topic will be something like \"LAUDS_FabLab_3DP_Klimawandel/status/switch:0\"\n// msg.payload will be the parsed JSON object from the Shelly /status/switch:0 message\n\nconst topicParts = msg.topic.split('/');\nlet shellyId;\n\n// NEW: More robust way to find the Shelly ID.\n// It finds the 'status' part of the topic and assumes the ID is the part right before it.\nconst statusIndex = topicParts.indexOf('status');\nif (statusIndex > 0) {\n    shellyId = topicParts[statusIndex - 1];\n} else {\n    // Fallback to the original logic if 'status' isn't found\n    shellyId = topicParts[0];\n}\n\n// Extract data from the payload, using safe navigation (?. operator)\nlet power = msg.payload.apower;\nlet energyTotal = msg.payload.aenergy?.total;\nlet voltage = msg.payload.voltage;\nlet current = msg.payload.current;\nlet plugTempC = msg.payload.temperature?.tC;\n\n// This block correctly handles the other message type (.../events/rpc) by ignoring it.\n// We add a more descriptive warning.\nif (msg.payload.params?.[\"switch:0\"]?.aenergy?.total !== undefined) {\n    if (power === undefined) {\n        node.warn(`Skipping incomplete energy-only update from topic ${msg.topic}. This is the correct behavior as it lacks full data.`);\n        return null; // Stop processing this message further\n    }\n}\n\n// Validate required data. This is a critical check.\nif (shellyId === undefined || power === undefined || energyTotal === undefined) {\n    node.error(\"Missing required data (shellyId, power, or energyTotal) in payload for topic: \" + msg.topic, msg);\n    return null; // Stop processing this message\n}\n\n// Create a standard timestamp (Node-RED runs on UTC, PG needs TIMESTAMPTZ)\nconst timestamp = new Date().toISOString();\n\n// We need the internal device_id (e.g., ultimaker_2_solex) associated with this shellyId.\n// We'll fetch this using a separate database lookup in the next step.\n// For now, just pass the shellyId along.\nmsg.shellyId = shellyId;\n\n// Prepare the payload for the next step (lookup)\nmsg.payload = {\n    timestamp: timestamp,\n    power_watts: parseFloat(power) || 0,\n    energy_total_wh: parseFloat(energyTotal) || 0,\n    voltage: parseFloat(voltage) || 0,\n    current_amps: parseFloat(current) || 0,\n    plug_temp_c: parseFloat(plugTempC) || null // Allow NULL if temp missing\n};\n\n// Clear the original topic to avoid confusion downstream\nmsg.topic = \"\";\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 390,
        "y": 260,
        "wires": [
            [
                "dea9b58952db33f3",
                "880c7f6b7e9a735f"
            ]
        ],
        "info": "**Purpose:** Extracts the relevant energy metrics from the raw JSON payload and standardizes them into a consistent format.\n\n**Logic:**\n1.  Parses the `shelly_id` from the `msg.topic`.\n2.  Safely extracts `apower`, `aenergy.total`, `voltage`, etc. from the `msg.payload`.\n3.  Validates that essential data is present.\n4.  Creates a new, clean object with standardized keys (`power_watts`, `energy_total_wh`, etc.).\n\n**Output:**\n- `msg.shellyId`: The unique ID of the Shelly plug.\n- `msg.payload`: The new, standardized data object."
    },
    {
        "id": "dea9b58952db33f3",
        "type": "function",
        "z": "dd55f774d9b5b325",
        "name": "Lookup Device ID",
        "func": "// msg.shellyId contains the ID like \"SPPS-02\"\n// msg.payload contains the parsed energy data object\n\nif (!msg.shellyId) {\n    node.error(\"Shelly ID missing, cannot lookup device ID\");\n    return null;\n}\n\n// Prepare the parameters array for the Prepared Statement in the postgres node.\n// The query in the postgres node will expect $1 to be the shelly_id.\nmsg.params = [ msg.shellyId ];\n\n// Pass the energy data along for the next step using a different property\nmsg.energyData = msg.payload;\n\n// Clear payload and topic as they are not needed for the postgres node in this mode\nmsg.payload = {};\nmsg.topic = \"\"; // Ensure topic is empty\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 610,
        "y": 260,
        "wires": [
            [
                "b994af8ea200e124",
                "8a103cd81cf25cb4"
            ]
        ]
    },
    {
        "id": "2d8a7b2473e3360c",
        "type": "function",
        "z": "dd55f774d9b5b325",
        "name": "Prepare Insert Parameters",
        "func": "// msg.payload from the database node will be an array of results.\n// It should contain one object like [{ device_id: 'PrusaMK4-1' }]\n\n// **Improved Check:** Verify msg.payload is a non-empty array first\nif (!Array.isArray(msg.payload) || msg.payload.length === 0) {\n    // Log an informative error including the shellyId that failed the lookup\n    node.error(`Device ID lookup query returned no results for Shelly ID: '${msg.shellyId}'. Check if this Shelly ID exists in the 'devices' table.`, msg);\n    return null; // Stop processing this message flow\n}\n\n// Now we know msg.payload is a non-empty array. Access the first result.\nconst lookupResult = msg.payload[0];\n\n// **Improved Check:** Verify the result object and the device_id property exist\nif (!lookupResult || typeof lookupResult.device_id !== 'string' || lookupResult.device_id.trim() === '') {\n    node.error(`Device ID not found or is invalid in lookup result for Shelly ID: '${msg.shellyId}'. Result object received:`, lookupResult);\n    return null; // Stop processing\n}\n\n// If we reached here, the lookup was successful.\nconst deviceId = lookupResult.device_id;\nconst data = msg.energyData; // Retrieve the energy data we stored earlier\n\nif (!data) {\n    // This error shouldn't happen if the flow logic is correct, but check anyway\n    node.error(\"Internal Error: Energy data missing after successful device ID lookup for device: \" + deviceId);\n    return null;\n}\n\n// Prepare the parameters array in the correct order for the INSERT statement\n// Order MUST match the VALUES clause in the postgres node:\n// $1: timestamp, $2: device_id, $3: power_watts, $4: energy_total_wh,\n// $5: voltage, $6: current_amps, $7: plug_temp_c\nmsg.params = [\n    data.timestamp,        // $1\n    deviceId,              // $2\n    data.power_watts,      // $3\n    data.energy_total_wh,  // $4\n    data.voltage,          // $5\n    data.current_amps,     // $6\n    data.plug_temp_c       // $7\n];\n\n// Clear unnecessary properties that might interfere\ndelete msg.payload;\ndelete msg.topic; // Ensure topic is clear as we're not using it for the query\ndelete msg.energyData;\n// We keep msg.shellyId here so the error messages above have context, but it's not used further.\n// delete msg.shellyId; // Optional: uncomment to remove it fully\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 920,
        "y": 320,
        "wires": [
            [
                "873bd32f3e178cc0",
                "e04ec9e0e6c9a3a5"
            ]
        ]
    },
    {
        "id": "873bd32f3e178cc0",
        "type": "postgresql",
        "z": "dd55f774d9b5b325",
        "name": "Insert Energy Data",
        "query": "INSERT INTO energy_data (\n    timestamp,\n    device_id,\n    power_watts,\n    energy_total_wh,\n    voltage,\n    current_amps,\n    plug_temp_c\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1330,
        "y": 260,
        "wires": [
            []
        ],
        "info": "**Purpose:** The final step. This node inserts the standardized energy data into the `energy_data` hypertable.\n\n**Logic:**\n- The previous node (\"Prepare Insert Parameters\") formats `msg.params` with all the required values in the correct order.\n- An `INSERT` query is executed.\n- `ON CONFLICT DO NOTHING` prevents duplicate entries if a message is received twice."
    },
    {
        "id": "b994af8ea200e124",
        "type": "postgresql",
        "z": "dd55f774d9b5b325",
        "name": "Prepared Statement",
        "query": "SELECT device_id FROM devices WHERE shelly_id = $1;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 840,
        "y": 260,
        "wires": [
            [
                "2d8a7b2473e3360c"
            ]
        ],
        "info": "**Purpose:** Translates the public `shelly_id` into the system's internal `device_id`.\n\n**Logic:**\n- It queries the `devices` table to find the row `WHERE shelly_id = $1`.\n- This is a critical step to link the energy data to the correct printer.\n\n**Output:**\n- `msg.payload`: An array containing the query result, e.g., `[{ \"device_id\": \"PrusaMK4-1\" }]`.\n- `msg.energyData`: The original standardized energy data is preserved and passed through."
    },
    {
        "id": "e04ec9e0e6c9a3a5",
        "type": "debug",
        "z": "dd55f774d9b5b325",
        "name": "debug 22",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 1160,
        "y": 320,
        "wires": []
    },
    {
        "id": "880c7f6b7e9a735f",
        "type": "debug",
        "z": "dd55f774d9b5b325",
        "name": "debug 23",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 400,
        "y": 320,
        "wires": []
    },
    {
        "id": "8a103cd81cf25cb4",
        "type": "debug",
        "z": "dd55f774d9b5b325",
        "name": "debug 24",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 620,
        "y": 320,
        "wires": []
    },
    {
        "id": "4918b67096adabfe",
        "type": "http in",
        "z": "ac9683af7e82fb53",
        "g": "9e77943c233db3eb",
        "name": "POST /api/analyze",
        "url": "/api/analyze",
        "method": "post",
        "upload": false,
        "swaggerDoc": "",
        "x": 130,
        "y": 500,
        "wires": [
            [
                "e0f4357542e2412b"
            ]
        ],
        "info": "**Purpose:** Defines the public HTTP endpoint that the frontend page calls when a user clicks the \"Run Energy Analysis\" button.\r\n\r\n**Endpoint:** `POST /api/analyze`\r\n\r\n**Input:**\r\n- Expects an incoming `msg.payload` containing a JSON object from the frontend, e.g., `{ \"deviceId\": \"PrusaMK4-1\", \"timeRange\": \"24h\", ... }`."
    },
    {
        "id": "e0f4357542e2412b",
        "type": "function",
        "z": "ac9683af7e82fb53",
        "g": "9e77943c233db3eb",
        "name": "Parse Analyze Request",
        "func": "// Node-RED Function Node: Parse Analyze Request\n// --- Updated: 2024-07-XX (Added 'all' time range) ---\n\n// msg.payload should contain JSON like:\n// { deviceId: \"PrusaMK4-1\", timeRange: \"24h\", selectedDrivers: {\"nozzle_temp_actual\": true, ...} }\n\nconst input = msg.payload;\n\n// --- Basic Validation ---\nif (!input || typeof input !== 'object') {\n    node.error(\"Invalid payload received. Expected JSON object.\", msg);\n    return [null, msg]; // Send to error output (output 2)\n}\nconst deviceId = input.deviceId;\n// --- Use '24h' as the default timeRange if not provided ---\nconst timeRange = input.timeRange || \"24h\";\nconst selectedDrivers = input.selectedDrivers || {}; // Default to empty object\n\nif (!deviceId || typeof deviceId !== 'string' || deviceId.trim() === '') {\n    node.error(\"Missing or invalid deviceId in payload.\", msg);\n    return [null, msg]; // Send to error output\n}\n// --- End Basic Validation ---\n\n\n// --- Calculate Start Time ---\nlet startTimeISO = null; // Initialize\n\nnode.log(`[Parse Request] Received timeRange: '${timeRange}' for device: '${deviceId}'`);\n\nif (timeRange === 'all') {\n    // For 'all time', use a very early date recognized by PostgreSQL.\n    // This effectively selects all data >= epoch start.\n    startTimeISO = '1970-01-01T00:00:00Z'; // Use Unix Epoch start as the boundary\n    node.log(`[Parse Request] Time Range is 'all', setting startTimeISO to: ${startTimeISO}`);\n} else {\n    // Calculate specific start time based on current time for other ranges\n    let targetTimeMs = new Date().getTime(); // Get current time in milliseconds UTC\n    let durationHours = 0;\n\n    switch (timeRange) {\n        case '1h':  durationHours = 1; break;\n        case '6h':  durationHours = 6; break;\n        case '7d':  durationHours = 7 * 24; break;\n        case '24h': // Fallthrough for default case\n        default:    durationHours = 24; break; // Default to 24h if invalid range provided\n    }\n    targetTimeMs -= durationHours * 60 * 60 * 1000; // Subtract duration in milliseconds\n\n    const finalStartTime = new Date(targetTimeMs); // Create Date object from calculated time\n    startTimeISO = finalStartTime.toISOString(); // Convert to ISO 8601 format (UTC)\n    node.log(`[Parse Request] Time Range: '${timeRange}', Calculated startTimeISO: ${startTimeISO}`);\n}\n// --- End Calculate Start Time ---\n\n\n// --- Prepare variables for next steps ---\n\n// Map of allowed driver keys from UI (selectedDrivers) to their DB column source\n// Keep this map updated if new selectable drivers are added or column names change.\n// REMOVED 'speed_multiplier_percent' as it's no longer used by model or UI checkbox\nconst allDriverDbColumns = {\n    'nozzle_temp_actual': 'ps.nozzle_temp_actual',\n    'bed_temp_actual': 'ps.bed_temp_actual',\n    'is_printing': 'ps.is_printing',\n    'z_height_mm': 'ps.z_height_mm',\n    // 'speed_multiplier_percent': 'ps.speed_multiplier_percent', // Removed\n    'temperature_c': 'env.temperature_c',   // From environment table\n    'humidity_percent': 'env.humidity_pct'  // From environment table (check column name)\n};\n\n// We don't strictly need columnsToSelect anymore as the SQL query fetches all relevant cols.\n// But we still need selectedDriverKeys for Correlation/Regression logic later.\nlet selectedDriverKeys = [];\nfor (const driverKey in selectedDrivers) {\n    // Check if driver is selected (value is true) AND it's a valid known driver key\n    if (selectedDrivers[driverKey] === true && allDriverDbColumns.hasOwnProperty(driverKey)) {\n        selectedDriverKeys.push(driverKey);\n    } else if (selectedDrivers[driverKey] === true) {\n        // Log if a selected key isn't in our map (maybe a typo in UI value?)\n        node.warn(`[Parse Request] Skipping unknown selected driver key '${driverKey}'.`);\n    }\n}\nnode.log(`[Parse Request] Selected Driver Keys for downstream analysis: ${selectedDriverKeys}`);\n// --- End Prepare variables ---\n\n\n// --- Pass data to the next node ---\n// The 'Build SQL for Analysis' node only needs dbParams.\n// The Python node needs analysisInputs.\n\nmsg.dbParams = [deviceId, startTimeISO]; // Params for the main SQL query node\n\nmsg.analysisInputs = {\n    deviceId: deviceId,\n    startTime: startTimeISO, // Pass the calculated start time (could be epoch start)\n    selectedDriverKeys: selectedDriverKeys // Pass the validated keys the user selected\n};\n\n// Clear payload from input node if not needed further\nmsg.payload = {};\n// Clear properties no longer needed\ndelete msg.selectColumnsSQL; // This isn't used anymore\n\nreturn [msg, null]; // Send valid requests to output 1 (main flow)",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 410,
        "y": 500,
        "wires": [
            [
                "9f67b80add894bed"
            ],
            [
                "2dc8f0c00c0dd79f"
            ]
        ],
        "info": "**Purpose:** Validates and processes the incoming request from the user. It translates the user-friendly inputs (like \"24h\") into technical parameters for the database query.\r\n\r\n**Logic:**\r\n1.  Validates the incoming JSON payload to ensure it has the required fields (`deviceId`, etc.).\r\n2.  Calculates the correct ISO 8601 start timestamp based on the `timeRange` string (e.g., \"24h\" becomes the timestamp for 24 hours ago).\r\n3.  Creates two new message properties to pass to downstream nodes:\r\n    - `msg.dbParams`: An array `[deviceId, startTimeISO]` for the PostgreSQL query.\r\n    - `msg.analysisInputs`: An object containing all the contextual information for the final Python script."
    },
    {
        "id": "9f67b80add894bed",
        "type": "function",
        "z": "ac9683af7e82fb53",
        "g": "6382c2e9dcb135c5",
        "name": "Build SQL for Analysis",
        "func": "// Receives msg.dbParams, msg.analysisInputs\n// The static SQL query is now in the postgres node\n\nconst dbParams = msg.dbParams; // Contains [deviceId, startTimeISO]\n\nif (!dbParams || dbParams.length !== 2) {\n    node.error(\"Missing required database parameters\", msg);\n    return null; // Stop flow\n}\n\n// Prepare parameters for the static query in the postgres node\nmsg.params = dbParams;\n\n// Clear properties not needed by the SQL node\ndelete msg.dbParams;\ndelete msg.selectColumnsSQL; // Ensure this is removed\n\n// Keep msg.analysisInputs for the Python node\nmsg.payload = {};\nmsg.topic = \"\"; // Clear topic\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 720,
        "y": 100,
        "wires": [
            [
                "fd667af16fc7af70"
            ]
        ],
        "info": "**Purpose:** A simple \"pass-through\" node that ensures the `msg` object is correctly formatted for the main database query node.\r\n**Logic:** It moves the `msg.dbParams` created in the previous step into the `msg.params` property, which is where the `postgresql` node expects its parameters."
    },
    {
        "id": "fd667af16fc7af70",
        "type": "postgresql",
        "z": "ac9683af7e82fb53",
        "g": "6382c2e9dcb135c5",
        "name": "Get Data for Analysis",
        "query": "-- Query selecting all potentially relevant columns, with improved Env join\nWITH EnergyPoints AS (\n    SELECT timestamp, device_id, power_watts, voltage, current_amps, plug_temp_c\n    FROM energy_data\n    WHERE device_id = $1 AND timestamp >= $2 -- $1=deviceId, $2=startTimeISO\n)\nSELECT\n    ep.timestamp,\n    ep.power_watts,\n    ep.voltage,\n    ep.current_amps,\n    ep.plug_temp_c,\n    ps.nozzle_temp_actual,\n    ps.bed_temp_actual,\n    ps.is_printing,\n    ps.z_height_mm,\n    ps.speed_multiplier_percent,\n    -- Environmental columns from the new join\n    env.temperature_c,\n    env.humidity_pct AS humidity_percent -- Still aliasing for consistency\nFROM EnergyPoints ep\n-- Lateral join for Printer Status (finds latest status at or before energy timestamp)\nLEFT JOIN LATERAL (\n    SELECT nozzle_temp_actual, bed_temp_actual, is_printing, z_height_mm, speed_multiplier_percent\n    FROM printer_status\n    WHERE device_id = ep.device_id AND timestamp <= ep.timestamp\n    ORDER BY timestamp DESC LIMIT 1\n) ps ON true\n-- Lateral join for Environment Data (finds closest reading within +/- 15 mins)\nLEFT JOIN LATERAL (\n    SELECT temperature_c, humidity_pct -- Select needed env columns\n    FROM environment_data\n    WHERE\n        -- Match on location or dummy device ID used for environment data\n        device_id = 'environment' -- Or use location_id = 'Hamburg_DE'\n        -- Define a reasonable time window around the energy timestamp\n        AND timestamp BETWEEN ep.timestamp - INTERVAL '15 minutes' AND ep.timestamp + INTERVAL '15 minutes'\n    -- Order by the absolute time difference to find the closest reading\n    ORDER BY ABS(EXTRACT(EPOCH FROM (ep.timestamp - timestamp))) ASC\n    LIMIT 1 -- Take only the single closest reading within the window\n) env ON true -- Always join, subquery finds closest or returns NULLs if none in window\nORDER BY ep.timestamp ASC;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 780,
        "y": 160,
        "wires": [
            [
                "970bdc8e3cb051e8"
            ]
        ],
        "info": "**Purpose:** Executes a powerful query to fetch a complete, unified time-series dataset for the requested device and time range.\r\n\r\n**Logic:**\r\n- The query joins `energy_data` with `printer_status` and `environment_data`.\r\n- It uses `LEFT JOIN LATERAL` to efficiently find the closest matching status and environment reading for every single energy data point. This creates a rich, high-resolution dataset perfect for analysis.\r\n\r\n**Output:**\r\n- `msg.payload`: An array of objects, where each object represents a single point in time with all available sensor data."
    },
    {
        "id": "970bdc8e3cb051e8",
        "type": "python-function",
        "z": "ac9683af7e82fb53",
        "g": "6382c2e9dcb135c5",
        "name": "Perform Analysis (ML, Regr, Corr)",
        "func": "# Node-RED Python Function Node: Perform Analysis (ML, Regr, Corr)\n# --- Final Version: XGBoost, 7 Features, Post-processing, Cost Removed, NumPy 2.0 Fix ---\n\n# --- Imports & Environment ---\nimport sys\nimport os\n\nimport pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.linear_model import LinearRegression\nimport traceback\nimport warnings\nimport gc\nfrom datetime import timedelta\nimport psycopg2\n# Removed psycopg2 imports as cost fetch is removed\n\n# --- Configuration ---\n# The MODEL_DIR is now set from an environment variable for portability\nMODEL_DIR = os.getenv('MODEL_DIR', '/models')\nTARGET_COLUMN = 'power_watts'\nACTIVE_POWER_THRESHOLD = 5.0\nIMPUTE_VALUE_WHEN_API_MISSING = 0\n\n# --- Dynamic Model Selection ---\n# Get deviceId from the input message context provided by Node-RED\ndevice_id = msg.get('analysisInputs', {}).get('deviceId', '')\n\n# Default to Prusa model files\nMODEL_FILENAME = 'best_model.joblib' # Prusa XGBoost model\nSCALER_FILENAME = 'scaler.joblib'\nMETRICS_FILENAME = 'model_evaluation_metrics.joblib'\nSCALER_COLS_FILENAME = 'scaler_columns.joblib'\nMODEL_FEATURES_FILENAME = 'model_features.joblib'\nMODEL_TYPE_FOR_LOG = 'Prusa (XGBoost)'\n\n# If it's an Ender 3, switch to the Ender 3 model files\nif 'Ender-3' in device_id:\n    node.log(\"API - Ender 3 device selected. Switching to Ender 3 model assets.\")\n    MODEL_FILENAME = 'ender3_randomforest_model.joblib' # Ender RF model\n    SCALER_FILENAME = 'ender3_scaler.joblib'\n    METRICS_FILENAME = 'ender3_model_evaluation_metrics.joblib'\n    SCALER_COLS_FILENAME = 'ender3_scaler_columns.joblib'\n    MODEL_FEATURES_FILENAME = 'ender3_model_features.joblib'\n    MODEL_TYPE_FOR_LOG = 'Ender 3 (RandomForest)'\n\nnode.log(f\"API - Using Model Type: {MODEL_TYPE_FOR_LOG}\")\n\n# Build final paths based on the selected filenames\nSCALER_PATH = os.path.join(MODEL_DIR, SCALER_FILENAME)\nMODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)\nMETRICS_PATH = os.path.join(MODEL_DIR, METRICS_FILENAME)\nSCALER_COLS_PATH = os.path.join(MODEL_DIR, SCALER_COLS_FILENAME)\nMODEL_FEATURES_PATH = os.path.join(MODEL_DIR, MODEL_FEATURES_FILENAME)\n\n# --- ADD Database Details Needed for Min Timestamp Query ---\nDB_NAME = \"reg_ml\"\nDB_USER = \"reg_ml\"\nDB_PASS = \"raptorblingx\" # Consider moving to flow/global context or env var later\nDB_HOST = \"localhost\"\nDB_PORT = \"5432\"\n# --- END ADD ---\n\n\n# --- Pre-load Model, Scaler, Feature Lists, and Metrics ---\nscaler = None; model = None; evaluation_metrics = {\"status\": \"Metrics pending load...\"}\nSCALER_COLUMNS = None; MODEL_FEATURES = None; loading_error_details = {}\ntry: scaler = joblib.load(SCALER_PATH); node.log(\"API - Loaded scaler.\")\nexcept Exception as e: loading_error_details[\"scaler\"] = f\"Scaler load error: {str(e)}\"; node.error(f\"API - {loading_error_details['scaler']}\")\ntry: SCALER_COLUMNS = joblib.load(SCALER_COLS_PATH); node.log(f\"API - Loaded scaler columns: {SCALER_COLUMNS}\")\nexcept Exception as e: loading_error_details[\"scaler_cols\"] = f\"Scaler columns load error: {str(e)}\"; node.error(f\"API - {loading_error_details['scaler_cols']}\")\ntry: model = joblib.load(MODEL_PATH); node.log(f\"API - Loaded model from {MODEL_FILENAME}.\")\nexcept Exception as e: loading_error_details[\"model\"] = f\"Model load error: {str(e)}\"; node.error(f\"API - {loading_error_details['model']}\")\ntry: MODEL_FEATURES = joblib.load(MODEL_FEATURES_PATH); node.log(f\"API - Loaded model features: {MODEL_FEATURES}\")\nexcept Exception as e: loading_error_details[\"model_features\"] = f\"Model features load error: {str(e)}\"; node.error(f\"API - {loading_error_details['model_features']}\")\ntry: evaluation_metrics = joblib.load(METRICS_PATH); node.log(f\"API - Loaded evaluation metrics (Type: {evaluation_metrics.get('model_type', 'Unknown')}).\")\nexcept Exception as e: error_msg = f\"Metrics load error: {str(e)}\"; node.error(f\"API - {error_msg}\"); evaluation_metrics = {\"mae\": \"N/A\", \"rmse\": \"N/A\", \"r_squared\": \"N/A\", \"error\": error_msg}; evaluation_metrics[\"error_metrics\"] = error_msg\n\nessential_components_missing = False\nif scaler is None or SCALER_COLUMNS is None or model is None or MODEL_FEATURES is None:\n    node.error(f\"API - CRITICAL: One or more ML assets failed to load. Errors: {loading_error_details}\")\n    essential_components_missing = True\n\n# --- Main Analysis Function Definition ---\ndef perform_analysis(data_list, selected_driver_keys, loaded_model, loaded_scaler, expected_scaler_cols, expected_model_features):\n    node.log(\"API - perform_analysis function started.\")\n    results = {\n        \"ml_prediction\": {\"timestamps\": [], \"actual\": [], \"predicted\": [], \"error\": None},\n        \"ml_feature_importance\": {\"error\": \"Not calculated yet.\"},\n        \"ml_top_drivers\": [],\n        # Removed cost fields\n        \"new_metrics\": {\"total_kwh\": None, \"avg_power_overall\": None, \"avg_power_active\": None, \"phase_analysis\": None, \"error\": None},\n        \"correlation\": {}, \"regression\": {}, \"summary\": \"Analysis started.\", \"error\": None\n        # Removed device_info\n    }\n    df = None; df_active = None; df_processed = None\n\n    # --- 1. Convert input list to DataFrame & Basic Prep ---\n    try:\n        if not data_list: raise ValueError(\"No data received from database query.\")\n        node.log(\"API - Creating DataFrame...\")\n        df = pd.DataFrame(data_list)\n        if TARGET_COLUMN not in df.columns: raise ValueError(f\"Target column '{TARGET_COLUMN}' missing.\")\n        if 'timestamp' not in df.columns: raise ValueError(\"'timestamp' column missing.\")\n\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n        df.set_index('timestamp', inplace=True, drop=False)\n        df.sort_index(inplace=True)\n        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n        node.log(f\"API - Initial DataFrame shape: {df.shape}. Columns available: {df.columns.tolist()}\")\n\n    except Exception as e: node.error(f\"API - Error during DataFrame prep: {e}\\\\n{traceback.format_exc()}\"); results[\"error\"] = f\"Data prep error: {str(e)}\"; return results\n\n        # --- 1c. Fetch Minimum Timestamp for this Device ---\n    min_timestamp_iso = None\n    device_id_for_min_ts = msg.get('analysisInputs', {}).get('deviceId')\n\n    if device_id_for_min_ts:\n        db_conn_min_ts = None\n        try:\n            node.log(f\"API - Connecting to DB to fetch min timestamp for {device_id_for_min_ts}...\")\n            db_conn_min_ts = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASS, host=DB_HOST, port=DB_PORT)\n            cur_min_ts = db_conn_min_ts.cursor()\n            # Query the absolute earliest timestamp for this device from energy_data\n            cur_min_ts.execute(\"SELECT min(timestamp) FROM energy_data WHERE device_id = %s\", (device_id_for_min_ts,))\n            result_min_ts = cur_min_ts.fetchone()\n            if result_min_ts and result_min_ts[0] is not None:\n                # Format as ISO string UTC (compatible with JS Date parsing)\n                min_timestamp_iso = result_min_ts[0].strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n                node.log(f\"API - Fetched min_timestamp_iso: {min_timestamp_iso}\")\n            else:\n                node.warn(f\"API - min_timestamp not found for device {device_id_for_min_ts} (no data?)\")\n            cur_min_ts.close()\n        except Exception as db_err:\n            node.error(f\"API - Failed to fetch min_timestamp: {db_err}\")\n        finally:\n            if db_conn_min_ts:\n                db_conn_min_ts.close()\n    else:\n         node.warn(\"API - Cannot fetch min_timestamp, device_id not found.\")\n\n    # Store the minimum timestamp in the results (even if None)\n    # Ensure device_info exists if cost fetch was removed\n    if \"device_info\" not in results: results[\"device_info\"] = {}\n    results[\"device_info\"][\"min_timestamp_iso\"] = min_timestamp_iso\n    # --- End Min Timestamp Fetch ---\n    \n    node.log(f\"API - Stored in results['device_info']: {results.get('device_info')}\")\n\n\n    # --- 2. Preprocessing for ML Model (7 Features) ---\n    try:\n        node.log(\"API - Starting ML Preprocessing for 7 features...\")\n        df_processed = pd.DataFrame(index=df.index)\n\n        missing_inputs = [f for f in expected_model_features if f not in df.columns]\n        if missing_inputs:\n             node.warn(f\"API - Input data missing required feature columns: {missing_inputs}. Adding as NaN before processing.\")\n             for f in missing_inputs: df[f] = np.nan\n\n        # 1. Clean z_height_mm\n        if 'z_height_mm' in df.columns and 'z_height_mm' in expected_model_features:\n            neg_mask = df['z_height_mm'] < 0\n            if neg_mask.sum() > 0: df.loc[neg_mask, 'z_height_mm'] = IMPUTE_VALUE_WHEN_API_MISSING\n\n        # 2. Process 'is_printing'\n        if 'is_printing' in expected_model_features:\n             if 'is_printing' in df.columns: df_processed['is_printing'] = pd.to_numeric(df['is_printing'], errors='coerce').fillna(IMPUTE_VALUE_WHEN_API_MISSING).astype(int)\n             else: df_processed['is_printing'] = IMPUTE_VALUE_WHEN_API_MISSING\n\n        # 3. Process and Impute other features\n        features_to_process = ['plug_temp_c', 'nozzle_temp_actual', 'bed_temp_actual', 'z_height_mm', 'nozzle_temp_target', 'bed_temp_target']\n        for col in features_to_process:\n            if col in expected_model_features:\n                 if col in df.columns: df_processed[col] = df[col].fillna(IMPUTE_VALUE_WHEN_API_MISSING)\n                 else: df_processed[col] = IMPUTE_VALUE_WHEN_API_MISSING\n\n        # 4. Final checks on df_processed\n        final_missing = [f for f in expected_model_features if f not in df_processed.columns]\n        if final_missing: raise ValueError(f\"Features missing after processing: {final_missing}\")\n        df_processed = df_processed[expected_model_features]\n        if df_processed.isnull().values.any(): node.error(\"API - CRITICAL: NaNs found after preprocessing! Filling with 0.\"); df_processed = df_processed.fillna(0)\n\n        node.log(f\"API - ML Preprocessing complete. Processed DF shape: {df_processed.shape}\")\n\n    except Exception as e: node.error(f\"API - Error during ML preprocessing: {e}\\\\n{traceback.format_exc()}\"); results[\"ml_prediction\"][\"error\"] = f\"ML Preprocessing failed: {str(e)}\"; results[\"ml_feature_importance\"][\"error\"] = \"ML Preprocessing failed\"\n\n    # --- 3. ML Prediction & Feature Importance ---\n    if essential_components_missing or results[\"ml_prediction\"][\"error\"]:\n        err_msg = results[\"ml_prediction\"][\"error\"] or \"ML components missing.\"\n        results[\"ml_prediction\"][\"error\"] = err_msg; results[\"ml_feature_importance\"][\"error\"] = err_msg; node.error(f\"API - Skipping ML prediction/FI: {err_msg}\")\n    elif df_processed is None or df_processed.empty:\n        err_msg = \"Processed data missing/empty.\"; results[\"ml_prediction\"][\"error\"] = err_msg; results[\"ml_feature_importance\"][\"error\"] = err_msg; node.error(\"API - \" + err_msg)\n    else:\n        try:\n            if list(df_processed.columns) != expected_scaler_cols: node.warn(f\"API - Reordering columns for scaler.\"); df_processed = df_processed[expected_scaler_cols]\n            X_predict = df_processed\n            if X_predict.isnull().values.any(): raise ValueError(\"NaNs detected before scaling.\")\n\n            node.log(f\"API - Scaling {X_predict.shape[0]} rows...\")\n            X_predict_scaled = loaded_scaler.transform(X_predict)\n            node.log(f\"API - Scaled. Predicting using model features: {expected_model_features}\")\n            raw_predictions = loaded_model.predict(X_predict_scaled)\n            node.log(f\"API - Raw predictions generated, count: {len(raw_predictions)}\")\n\n            # --- Post-Processing Rule for Idle State ---\n            node.log(\"API - Applying post-processing rule for idle state...\")\n            predictions = raw_predictions # Start with raw predictions\n            idle_check_cols = ['is_printing', 'nozzle_temp_actual', 'bed_temp_actual', 'nozzle_temp_target', 'bed_temp_target']\n            if all(col in df_processed.columns for col in idle_check_cols):\n                 idle_condition_mask = (df_processed['is_printing'] == 0) & \\\n                                       (df_processed['nozzle_temp_actual'] == IMPUTE_VALUE_WHEN_API_MISSING) & \\\n                                       (df_processed['bed_temp_actual'] == IMPUTE_VALUE_WHEN_API_MISSING) & \\\n                                       (df_processed['nozzle_temp_target'] == IMPUTE_VALUE_WHEN_API_MISSING) & \\\n                                       (df_processed['bed_temp_target'] == IMPUTE_VALUE_WHEN_API_MISSING)\n                 predictions = np.where(idle_condition_mask, 0.0, raw_predictions)\n                 num_zeroed = np.sum(idle_condition_mask)\n                 node.log(f\"API - Applied post-processing rule. Zeroed {num_zeroed} predictions based on idle state conditions.\")\n            else: node.warn(f\"API - Post-processing skipped: Missing columns needed for idle check.\")\n\n            predictions = np.maximum(0.0, predictions) # Ensure no negative predictions remain\n            # --- End Post-Processing Rule ---\n\n            results[\"ml_prediction\"][\"timestamps\"] = df.index.strftime('%Y-%m-%dT%H:%M:%S.%fZ').tolist()\n            results[\"ml_prediction\"][\"actual\"] = df[TARGET_COLUMN].tolist()\n            results[\"ml_prediction\"][\"predicted\"] = predictions.tolist() # Use final predictions\n            results[\"ml_prediction\"][\"error\"] = None\n\n            # --- Feature Importance ---\n            if hasattr(loaded_model, 'feature_importances_'):\n                try:\n                    importances = loaded_model.feature_importances_\n                    fi_dict = dict(zip(expected_model_features, importances))\n                    results[\"ml_feature_importance\"] = fi_dict\n                    # node.log(f\"API - Calculated Feature Importances: {fi_dict}\") # Can be verbose\n                    # Find Top Drivers\n                    operational_fi = { k: v for k, v in fi_dict.items() }\n                    if operational_fi:\n                        sorted_operational_fi = sorted(operational_fi.items(), key=lambda item: item[1], reverse=True)\n                        top_drivers = [item[0] for item in sorted_operational_fi[:3]]\n                        results[\"ml_top_drivers\"] = top_drivers\n                        node.log(f\"API - Top ML Drivers: {top_drivers}\")\n                except Exception as fi_e: node.error(f\"API - Error processing FI: {fi_e}\"); results[\"ml_feature_importance\"] = {\"error\": f\"FI Error: {str(fi_e)}\"}\n            else: results[\"ml_feature_importance\"] = {\"message\": \"FI not available.\"}; node.log(\"API - FI N/A.\")\n\n            del X_predict, X_predict_scaled, predictions, raw_predictions; gc.collect()\n\n        except ValueError as ve: node.error(f\"API - ML Value Error: {ve}\"); results[\"ml_prediction\"][\"error\"] = f\"ML Fail: {str(ve)}\"; results[\"ml_feature_importance\"][\"error\"] = \"Pred fail\"\n        except Exception as e: node.error(f\"API - ML Error: {e}\\\\n{traceback.format_exc()}\"); results[\"ml_prediction\"][\"error\"] = f\"ML Fail: {str(e)}\"; results[\"ml_feature_importance\"][\"error\"] = \"Pred fail\"\n\n    # --- 4. New Calculations ---\n    try:\n        node.log(\"API - Starting New Calculations (kWh, Avg Power, Phases)...\")\n        if not isinstance(df.index, pd.DatetimeIndex): df = df.set_index('timestamp', drop=False).sort_index()\n        if TARGET_COLUMN not in df.columns: raise ValueError(f\"Target column '{TARGET_COLUMN}' missing.\")\n        time_diff_sec = df.index.to_series().diff().dt.total_seconds().fillna(0)\n        time_elapsed_sec = (df.index - df.index.min()).total_seconds()\n        power_for_trapz = df[TARGET_COLUMN].fillna(0).values\n        if len(time_elapsed_sec) > 1: total_joules = np.trapz(y=power_for_trapz, x=time_elapsed_sec); total_kwh = total_joules / (3600 * 1000); results[\"new_metrics\"][\"total_kwh\"] = round(total_kwh, 4)\n        else: results[\"new_metrics\"][\"total_kwh\"] = 0.0; total_kwh = 0.0\n\n        # --- Cost Calculation Removed ---\n\n        results[\"new_metrics\"][\"avg_power_overall\"] = round(df[TARGET_COLUMN].mean(), 2)\n        df_active = df[df[TARGET_COLUMN] > ACTIVE_POWER_THRESHOLD]\n        results[\"new_metrics\"][\"avg_power_active\"] = round(df_active[TARGET_COLUMN].mean(), 2) if not df_active.empty else 0.0\n\n        df['phase'] = 'Idle'; df.loc[df[TARGET_COLUMN] > ACTIVE_POWER_THRESHOLD, 'phase'] = 'Active (Other)'\n        if 'is_printing' in df.columns: df.loc[(df['is_printing'] == 1) & (df[TARGET_COLUMN] > ACTIVE_POWER_THRESHOLD), 'phase'] = 'Printing'\n        phase_analysis = {}; phase_energies_kwh = {}; total_duration_sec = time_diff_sec.sum()\n        for phase_name, phase_df in df.groupby('phase'):\n             phase_duration_sec = time_diff_sec[phase_df.index].sum()\n             phase_time_elapsed = (phase_df.index - df.index.min()).total_seconds(); phase_power = phase_df[TARGET_COLUMN].fillna(0).values; phase_joules = 0.0\n             if len(phase_time_elapsed) > 1: sorted_indices = np.argsort(phase_time_elapsed); phase_joules = np.trapz(y=phase_power[sorted_indices], x=phase_time_elapsed[sorted_indices])\n             phase_kwh = phase_joules / (3600 * 1000); phase_energies_kwh[phase_name] = phase_kwh\n             phase_analysis[phase_name] = { \"duration_minutes\": round(phase_duration_sec / 60, 1), \"duration_percent\": round((phase_duration_sec / total_duration_sec * 100) if total_duration_sec > 0 else 0, 1), \"energy_kwh\": round(phase_kwh, 4), \"avg_power\": round(phase_df[TARGET_COLUMN].mean(), 1) if not phase_df.empty else 0 }\n        total_phase_energy_kwh = sum(phase_energies_kwh.values())\n        for phase_name in phase_analysis: phase_kwh = phase_energies_kwh.get(phase_name, 0); phase_analysis[phase_name][\"energy_percent\"] = round((phase_kwh / total_phase_energy_kwh * 100) if total_phase_energy_kwh > 0 else 0, 1)\n        results[\"new_metrics\"][\"phase_analysis\"] = phase_analysis; node.log(f\"API - Phase Analysis Results: {phase_analysis}\")\n\n    except Exception as e: node.error(f\"API - Error during new calculations: {e}\\\\n{traceback.format_exc()}\"); results[\"new_metrics\"][\"error\"] = f\"Failed: {str(e)}\"\n\n    # --- 5. Correlation & 6. Regression Analysis ---\n    # (Logic remains the same, uses original df_active & selected_driver_keys)\n    if df_active is not None and not df_active.empty:\n        node.log(f\"API - Starting Correlation on ACTIVE data for selected drivers: {selected_driver_keys}\")\n        # ... (Existing Correlation logic - needs df_active) ...\n        try:\n            valid_drivers_for_corr = [key for key in selected_driver_keys if key in df_active.columns and key != TARGET_COLUMN]\n            if valid_drivers_for_corr:\n                correlation_results_dict = {}\n                for driver_key in valid_drivers_for_corr:\n                    temp_df = df_active[[TARGET_COLUMN, driver_key]].copy().dropna()\n                    num_pairs = len(temp_df)\n                    if num_pairs > 1: # Check if enough pairs first\n                        target_std = temp_df[TARGET_COLUMN].std(); driver_std = temp_df[driver_key].std()\n                        if target_std == 0 or driver_std == 0: correlation_results_dict[driver_key] = \"N/A (No Variation)\"\n                        else: correlation_matrix = temp_df.corr(); corr_value = correlation_matrix.loc[TARGET_COLUMN, driver_key]; correlation_results_dict[driver_key] = corr_value if not pd.isna(corr_value) else \"N/A (Calc NaN)\"\n                    else: correlation_results_dict[driver_key] = \"N/A (Insufficient Data)\"\n                results[\"correlation\"] = correlation_results_dict\n            else: results[\"correlation\"] = {\"message\": \"No valid drivers selected/available in active data.\"}\n        except Exception as e: node.error(f\"API - Correlation Error: {e}\\\\n{traceback.format_exc()}\"); results[\"correlation\"] = {\"error\": f\"Corr error: {str(e)}\"}\n    else: results[\"correlation\"] = {\"message\": f\"No activity found (Power > {ACTIVE_POWER_THRESHOLD}W) for Correlation\"}\n\n    if df_active is not None and not df_active.empty:\n        node.log(f\"API - Starting Regression on ACTIVE data for selected drivers: {selected_driver_keys}\")\n        # ... (Existing Regression logic - needs df_active) ...\n        try:\n            valid_drivers_for_regr = [key for key in selected_driver_keys if key in df_active.columns and key != TARGET_COLUMN]\n            if valid_drivers_for_regr:\n                regr_df = df_active[[TARGET_COLUMN] + valid_drivers_for_regr].copy().dropna()\n                if len(regr_df) >= len(valid_drivers_for_regr) + 2:\n                    X_regr = regr_df[valid_drivers_for_regr]; y_regr = regr_df[TARGET_COLUMN]\n                    regr_model = LinearRegression(); regr_model.fit(X_regr, y_regr)\n                    results[\"regression\"] = { \"drivers\": valid_drivers_for_regr, \"coefficients\": dict(zip(valid_drivers_for_regr, np.round(regr_model.coef_, 3))), \"intercept\": round(regr_model.intercept_, 3), \"r_squared\": round(regr_model.score(X_regr, y_regr), 3), \"n_samples\": len(regr_df) }\n                    del X_regr, y_regr, regr_model, regr_df\n                else: results[\"regression\"] = {\"message\": f\"Not enough valid points after NaNs dropped ({len(regr_df)} points).\"}\n            else: results[\"regression\"] = {\"message\": \"No valid drivers selected/available for Regression.\"}\n        except Exception as e: node.error(f\"API - Regression Error: {e}\\\\n{traceback.format_exc()}\"); results[\"regression\"] = {\"error\": f\"Regr error: {str(e)}\"}\n    else: results[\"regression\"] = {\"message\": f\"No activity found (Power > {ACTIVE_POWER_THRESHOLD}W) for Regression\"}\n\n    # --- 7. Generate Final Summary ---\n    total_points = len(df) if df is not None else 'unknown'; active_points = len(df_active) if df_active is not None else 0\n    summary_parts = [f\"Analysis complete for {total_points} total data points ({active_points} considered active with Power > {ACTIVE_POWER_THRESHOLD}W).\"]\n    if results[\"new_metrics\"].get(\"total_kwh\") is not None: summary_parts.append(f\"Energy: {results['new_metrics']['total_kwh']:.3f} kWh.\")\n    if not results[\"ml_prediction\"].get(\"error\"): pred_count = len(results['ml_prediction'].get('predicted',[])); summary_parts.append(f\"ML Pred({pred_count} pts).\")\n    else: summary_parts.append(\"ML Pred failed.\")\n    if not results[\"ml_feature_importance\"].get(\"error\") and not results[\"ml_feature_importance\"].get(\"message\"): summary_parts.append(\"FI calculated.\")\n    if results[\"correlation\"] and not results[\"correlation\"].get(\"error\") and not results[\"correlation\"].get(\"message\"): num_corr_drivers = len([k for k in results[\"correlation\"] if not str(results[\"correlation\"].get(k,'N/A')).startswith('N/A')]);\n    if num_corr_drivers > 0: summary_parts.append(f\"Corr({num_corr_drivers} drivers).\")\n    if results[\"regression\"] and results[\"regression\"].get(\"r_squared\") is not None: summary_parts.append(f\"Regr R:{results['regression']['r_squared']:.2f}.\")\n    if results.get(\"error\"): summary_parts.append(f\"ERR:{results['error']}\")\n    results[\"summary\"] = \" \".join(summary_parts)\n\n    node.log(\"API - perform_analysis function finished.\")\n    if 'df' in locals(): del df;\n    if 'df_active' in locals(): del df_active;\n    if 'df_processed' in locals(): del df_processed;\n    gc.collect()\n    \n    node.log(f\"API - Returning from perform_analysis. results['device_info'] is: {results.get('device_info')}\")\n\n\n    return results\n# --- End of perform_analysis Function Definition ---\n\n\n# === Main Execution Block (Called by Node-RED) ===\nif essential_components_missing:\n    final_response_results = { \"summary\": \"Analysis failed: Critical model components could not be loaded.\", \"error\": \"Model component loading error.\", # ... other error fields ...\n                              \"ml_evaluation_metrics\": evaluation_metrics }\n    predictions_to_store = []\nelse:\n    input_data = msg.get('payload', [])\n    selected_keys = msg.get('analysisInputs', {}).get('selectedDriverKeys', [])\n    analysis_results = perform_analysis( input_data, selected_keys, model, scaler, SCALER_COLUMNS, MODEL_FEATURES )\n    \n    node.log(f\"API - analysis_results['device_info'] after function call: {analysis_results.get('device_info')}\")\n    \n    \n    predictions_to_store = []\n    ml_pred_results = analysis_results.get(\"ml_prediction\", {})\n    if isinstance(ml_pred_results, dict) and not ml_pred_results.get(\"error\"):\n        timestamps = ml_pred_results.get(\"timestamps\", []); predicted_values = ml_pred_results.get(\"predicted\", [])\n        if isinstance(timestamps, list) and isinstance(predicted_values, list) and len(timestamps) == len(predicted_values):\n            node.log(f\"API - Preparing {len(timestamps)} predictions for storage.\")\n            device_id = msg.get('analysisInputs', {}).get('deviceId', 'unknown'); model_version = evaluation_metrics.get('model_type', 'unknown_model')\n            for i in range(len(timestamps)):\n                 pred_val = predicted_values[i]\n                 if isinstance(pred_val, (int, float)) and not np.isnan(pred_val): predictions_to_store.append({ \"timestamp\": timestamps[i], \"device_id\": device_id, \"predicted_power_watts\": float(pred_val), \"model_version\": model_version })\n                 else: node.warn(f\"API - Skipping prediction storage index {i}, invalid value: {pred_val}\")\n        else: node.error(f\"Timestamp/prediction counts mismatch or not lists.\")\n    else: node.warn(f\"ML Prediction results invalid/errored. Skipping storage.\")\n\n    # Prepare final results, converting numpy types\n    final_response_results = {\n        \"summary\": analysis_results.get(\"summary\", \"Summary unavailable.\"),\n        \"new_metrics\": analysis_results.get(\"new_metrics\", {\"error\": \"Metrics unavailable\"}),\n        \"device_info\": analysis_results.get(\"device_info\", {}),\n        \"correlation\": analysis_results.get(\"correlation\", {}),\n        \"correlation\": analysis_results.get(\"correlation\", {}),\n        \"regression\": analysis_results.get(\"regression\", {}),\n        \"ml_evaluation_metrics\": evaluation_metrics,\n        \"ml_prediction_summary\": analysis_results.get(\"ml_prediction\",{}).get(\"error\") or f\"{len(predictions_to_store)} points processed.\",\n        \"ml_feature_importance\": analysis_results.get(\"ml_feature_importance\", {}),\n        \"ml_top_drivers\": analysis_results.get(\"ml_top_drivers\", [])\n    }\n    if analysis_results.get(\"error\"): final_response_results[\"error\"] = analysis_results.get(\"error\")\n\n    # --- Convert NumPy types to standard Python types for JSON ---\n    def convert_numpy_types(obj):\n        if isinstance(obj, dict):\n            return {k: convert_numpy_types(v) for k, v in obj.items()}\n        elif isinstance(obj, list):\n            return [convert_numpy_types(i) for i in obj]\n        # --- Use np.floating and np.integer for broader compatibility ---\n        elif isinstance(obj, np.floating):\n            if np.isnan(obj): return None\n            if np.isinf(obj): return None # Or 'Infinity' string\n            return float(obj)\n        elif isinstance(obj, np.integer):\n            return int(obj)\n        # --- End NumPy specific types ---\n        elif isinstance(obj, (np.ndarray,)): # Handle arrays\n             return convert_numpy_types(obj.tolist())\n        elif isinstance(obj, np.bool_):\n             return bool(obj)\n        elif pd.isna(obj): # Handle Pandas NaT or other nulls\n             return None\n        return obj\n\n    final_response_results = convert_numpy_types(final_response_results)\n    # --- END TYPE CONVERSION ---\n\n# --- Set Node-RED message outputs ---\nresponse_payload = final_response_results; predictions_list = predictions_to_store\nkeys_to_keep = ['analysisInputs', '_msgid']; original_msg_keys = list(msg.keys())\nfor key in original_msg_keys:\n     if key not in keys_to_keep: del msg[key]\nmsg['payload'] = response_payload; msg['predictions'] = predictions_list\n\n# Logging before return\nnode.log(f\"API - Final Python Output Payload Type: {type(msg['payload'])}\")\nif isinstance(msg['payload'], dict): node.log(f\"API - Final Python Output Keys: {list(msg['payload'].keys())}\")\n\n# Cleanup and Return\nif 'analysis_results' in locals(): del analysis_results\nif 'final_response_results' in locals(): del final_response_results\nif 'input_data' in locals(): del input_data; gc.collect()\nreturn msg",
        "outputs": 1,
        "x": 820,
        "y": 220,
        "wires": [
            [
                "fc3e800f7322b583"
            ]
        ],
        "info": "**Purpose:** The main \"brain\" of the analysis. It takes the large dataset from the database and performs all the statistical and machine learning calculations requested by the user.\r\n\r\n**Logic:**\r\n1.  **Prediction:** Runs the pre-trained ML model over the entire dataset to generate \"Predicted vs. Actual\" power values.\r\n2.  **Metrics Calculation:** Computes key metrics like Total kWh, Average Power, and performs a detailed phase analysis (time/energy spent Printing vs. Idle vs. Active).\r\n3.  **Statistical Analysis:** Calculates the correlation and a simple linear regression between the user-selected \"drivers\" (e.g., nozzle temperature) and the power consumption.\r\n4.  **Feature Importance:** Extracts the feature importances from the ML model to identify the top three most influential factors.\r\n\r\n**Outputs:**\r\n- **Output 1 (`msg.payload`):** A large JSON object containing all the calculated results, ready to be sent to the frontend.\r\n- **Output 2 (`msg.predictions`):** An array of all the predictions made, which is sent to a separate branch to be saved in the database."
    },
    {
        "id": "3592a09331fdbdbd",
        "type": "function",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Format API Response",
        "func": "// Node-RED Function Node: Format API Response\n// --- Updated: 2024-07-XX (Handle 'all' time range for Grafana, include new metrics/drivers) ---\n\n// --- Add this log at the START ---\nnode.log(`Format Response - Received msg.payload type: ${typeof msg.payload}`);\nif (typeof msg.payload === 'object' && msg.payload !== null) {\n    node.log(`Format Response - Received payload keys: ${Object.keys(msg.payload)}`);\n    const receivedMetrics = msg.payload.new_metrics;\n    node.log(`Format Response - Received new_metrics type: ${typeof receivedMetrics}`);\n    // Limit stringify length for potentially large phase data\n    // node.log(`Format Response - Received new_metrics content: ${JSON.stringify(receivedMetrics)?.substring(0, 500)}...`);\n}\n// --- End Log ---\n\n// msg.payload contains the analysis results from Python node\n// msg.analysisInputs contains deviceId, startTime, selectedDriverKeys\nconst results = msg.payload; // These are the results calculated by Python\nconst analysisInputs = msg.analysisInputs; // These are the original inputs to the analysis\n\n// Initialize default payload for error cases or missing inputs\nlet responsePayload = { success: false, error: \"Unknown error occurred before formatting.\" };\nmsg.statusCode = 500; // Default to Internal Server Error\n\n// Check if analysis seems to have run and required inputs are available\nconst deviceId = analysisInputs?.deviceId;\nconst startTime = analysisInputs?.startTime; // Can be ISO string or '1970-01-01T00:00:00Z'\n\nif (results && typeof results === 'object' && !results.error && deviceId && startTime) {\n    // Proceed if Python didn't return a top-level error and we have device/start info\n    try {\n        node.log(`Format Response: Formatting for device: ${deviceId}, startTime marker: ${startTime}`);\n\n        // --- Generate Grafana Panel URLs ---\n        const grafanaBaseUrl = \"https://lauds.intel50001.com\"; // Your Grafana public URL\n        const dashboardUID = \"dej62anu0b3swf\";             // Your Dashboard UID\n        const dashboardName = \"prusa\";                     // Your Dashboard Name/Slug\n\n        // --- Determine Correct Panel ID ---\n        let panel1Id = \"1\"; // Default Panel ID for Actual vs Predicted\n        if (deviceId === 'PrusaMK4-1') {\n            panel1Id = \"3\";\n            node.log(`Format Response: Using Panel ID ${panel1Id} for PrusaMK4-1`);\n        } else {\n            node.log(`Format Response: Using default Panel ID ${panel1Id} for ${deviceId}`);\n        }\n\n        // --- Determine Grafana 'from' timestamp ---\n        let fromMs = null; // Use null to indicate invalid/missing time\n        const toMs = new Date().getTime(); // Use current time for 'to'\n\n        // Get the minimum timestamp fetched by Python (might be null)\n        const minTimestampIso = results?.device_info?.min_timestamp_iso; // Use optional chaining\n\n        if (startTime) { // Check if startTime marker exists\n            if (startTime === '1970-01-01T00:00:00Z') {\n                // Handle the 'all time' marker\n                if (minTimestampIso) { // If we successfully fetched the actual min timestamp\n                    const minDate = new Date(minTimestampIso);\n                    if (!isNaN(minDate)) {\n                        fromMs = minDate.getTime();\n                        node.log(`Format Response: 'All Time' range - using actual min_timestamp, fromMs: ${fromMs}`);\n                    } else {\n                        node.warn(`Format Response: Could not parse min_timestamp_iso: ${minTimestampIso}. Defaulting 'from' to epoch.`);\n                        fromMs = 0; // Fallback to epoch if min ts parsing fails\n                    }\n                } else {\n                    // Fallback if min_timestamp couldn't be fetched (e.g., no data for device)\n                    node.warn(\"Format Response: 'All Time' range - min_timestamp not available. Defaulting 'from' to epoch.\");\n                    fromMs = 0; // Default to epoch start if no actual min timestamp found\n                }\n            } else {\n                // Handle specific time ranges (1h, 6h, etc.)\n                const startDate = new Date(startTime);\n                if (!isNaN(startDate)) {\n                    fromMs = startDate.getTime();\n                    // node.log(`Format Response: Specific startTime parsed: ${startTime}, fromMs: ${fromMs}`); // Optional log\n                } else {\n                    node.error(`Format Response: Invalid non-'all' startTime format: ${startTime}.`);\n                    // fromMs remains null\n                }\n            }\n        } else {\n            // startTime itself was missing\n            node.error(`Format Response: Missing startTime in analysisInputs.`);\n            // fromMs remains null\n        }\n    // --- END Determine Grafana 'from' timestamp ---\n\n    // --- Construct URLs ONLY if fromMs is valid (not null) ---\n\n        let urlPanel1 = null;\n        if (fromMs !== null) {\n            urlPanel1 = `${grafanaBaseUrl}/d-solo/${dashboardUID}/${dashboardName}?orgId=1&theme=light&panelId=${panel1Id}&from=${fromMs}&to=${toMs}&var-deviceId=${encodeURIComponent(deviceId)}`;\n            node.log(`Format Response: Generated Panel 1 URL: ${urlPanel1}`);\n        } else {\n            node.log(\"Format Response: Skipping Grafana URL generation due to invalid 'from' time.\");\n        }\n\n        // --- Prepare final success payload ---\n        // Ensure ALL expected keys from the Python output (results) are included here\n        responsePayload = {\n            success: true,\n            error: null, // No top-level error from Python node\n            results: {\n                summary: results.summary || \"Summary unavailable.\",\n                new_metrics: results.new_metrics || { \"error\": \"Metrics missing from backend\" }, // Include new metrics\n                correlation: results.correlation || {},\n                regression: results.regression || {},\n                ml_prediction_summary: results.ml_prediction_summary || \"Prediction status unknown.\",\n                ml_evaluation_metrics: results.ml_evaluation_metrics || { status: \"Metrics could not be loaded.\" }, // Use correct key\n                ml_feature_importance: results.ml_feature_importance || {},\n                ml_top_drivers: results.ml_top_drivers || [], // Include top drivers\n                grafanaUrls: {\n                    panel1: urlPanel1 // Pass the potentially null URL\n                    // panel2: urlPanel2 // Add panel 2 URL here if used\n                }\n            }\n        };\n        msg.statusCode = 200; // OK\n\n    } catch (e) {\n        // Catch errors during the formatting process itself\n        node.error(`Format Response: Error during formatting: ${e}\\n${e.stack}`, msg);\n        responsePayload = { success: false, error: `Internal formatting error: ${e.message}` };\n        msg.statusCode = 500;\n    }\n\n} else {\n    // Handle cases where Python node failed or required inputs were missing before formatting\n    let errorReason = results?.error || \"Analysis failed or inputs missing.\";\n    if (!deviceId) errorReason += \" Missing deviceId.\";\n    if (!startTime) errorReason += \" Missing startTime.\";\n    node.error(`Format Response: Pre-check failed. Reason: ${errorReason}`, msg);\n    responsePayload = { success: false, error: errorReason }; // Use more specific error\n    // msg.statusCode remains 500 (default)\n}\n\n// Set the final payload to be sent back to the UI\nmsg.payload = responsePayload;\n\n// Clean up intermediate properties from the message object\ndelete msg.analysisInputs;\ndelete msg.predictions;\ndelete msg.topic;\ndelete msg.params;\n// delete msg.dbParams; // Usually safe to delete\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1620,
        "y": 380,
        "wires": [
            [
                "2dc8f0c00c0dd79f"
            ]
        ],
        "info": "**Purpose:** The final step before sending the data back to the user. It formats the raw results from the Python script into the final, clean JSON structure that the `analysis_page.html` frontend expects.\r\n**Logic:** It builds the final response object, including the summary text, metrics, correlation results, and dynamically generated Grafana URLs."
    },
    {
        "id": "2dc8f0c00c0dd79f",
        "type": "http response",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Send API Response",
        "statusCode": "",
        "headers": {},
        "x": 1900,
        "y": 500,
        "wires": [],
        "info": "**Purpose:** Sends the final, formatted JSON response back to the `analysis_page.html` frontend.\r\n**Logic:** Sets the HTTP status code to `200 OK` and sends the `msg.payload`."
    },
    {
        "id": "de086ea3e0127637",
        "type": "http in",
        "z": "ac9683af7e82fb53",
        "name": "GET /api/devices",
        "url": "/api/devices",
        "method": "get",
        "upload": false,
        "swaggerDoc": "",
        "x": 1520,
        "y": 40,
        "wires": [
            [
                "27a2e876613b93a9"
            ]
        ]
    },
    {
        "id": "27a2e876613b93a9",
        "type": "postgresql",
        "z": "ac9683af7e82fb53",
        "name": "Get Devices for UI",
        "query": "-- Fetch devices formatted for the dropdown\nSELECT friendly_name AS label, device_id AS value\nFROM devices\nORDER BY friendly_name;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1570,
        "y": 100,
        "wires": [
            [
                "61eb43d26e318c36"
            ]
        ]
    },
    {
        "id": "61eb43d26e318c36",
        "type": "http response",
        "z": "ac9683af7e82fb53",
        "name": "",
        "statusCode": "",
        "headers": {},
        "x": 1650,
        "y": 160,
        "wires": []
    },
    {
        "id": "3dad15f0c8d11ced",
        "type": "postgresql",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Insert Prediction",
        "query": "INSERT INTO ml_predictions (\n    timestamp, device_id, predicted_power_watts, model_version\n)\nSELECT\n    ts, -- Alias from UNNEST\n    dev, -- Alias from UNNEST\n    pwr, -- Alias from UNNEST\n    ver  -- Alias from UNNEST\nFROM UNNEST(\n    $1::TIMESTAMPTZ[], -- Parameter 1: Array of timestamps\n    $2::TEXT[],        -- Parameter 2: Array of device IDs\n    $3::FLOAT[],       -- Parameter 3: Array of predictions\n    $4::TEXT[]         -- Parameter 4: Array of model versions\n) AS t(ts, dev, pwr, ver) -- Define aliases for columns from UNNEST\nON CONFLICT DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1260,
        "y": 460,
        "wires": [
            []
        ],
        "info": "**Purpose:** Saves the historical predictions generated during the analysis into the `ml_predictions` table. This allows the data to be used later without re-running the analysis.\r\n**Logic:** Uses the `UNNEST` function to efficiently insert a large number of rows in a single query."
    },
    {
        "id": "fc3e800f7322b583",
        "type": "function",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Prepare Batched Params for UNNEST",
        "func": "// msg.payload = main analysis results\n// msg.predictions = full array of prediction objects {ts, dev_id, pred_pwr, model_ver}\n\nconst predictions = msg.predictions;\nconst batchSize = 100; // Process in chunks within this function\nlet allParams = []; // Array to hold all parameters for potentially multiple DB calls\n\nif (!Array.isArray(predictions) || predictions.length === 0) {\n    node.warn(\"No predictions array found or empty, skipping insert preparation.\");\n    // Send the original payload along the main path, but stop this insert path\n    // To do this, we need two outputs from this function node.\n    // Output 1: Main payload (passthrough)\n    // Output 2: Database parameters (or null if no predictions)\n    return [msg, null]; // Send original msg out output 1, null out output 2\n}\n\nnode.log(`Preparing ${predictions.length} predictions for batched UNNEST insert...`);\n\nlet currentBatchParams = {\n    timestamps: [],\n    device_ids: [],\n    predicted_watts: [],\n    model_versions: []\n};\nlet batchCount = 0;\n\nfor (const pred of predictions) {\n    // Basic validation for each object\n    if (pred && pred.timestamp && pred.device_id && typeof pred.predicted_power_watts === 'number' && !isNaN(pred.predicted_power_watts) && pred.model_version) {\n        currentBatchParams.timestamps.push(pred.timestamp);\n        currentBatchParams.device_ids.push(pred.device_id);\n        currentBatchParams.predicted_watts.push(pred.predicted_power_watts);\n        currentBatchParams.model_versions.push(pred.model_version);\n        batchCount++;\n\n        // If batch size reached, prepare parameters for this batch\n        if (batchCount >= batchSize) {\n            // Create parameters array FOR ONE DB CALL for this batch\n            allParams.push({\n                params: [\n                    currentBatchParams.timestamps,\n                    currentBatchParams.device_ids,\n                    currentBatchParams.predicted_watts,\n                    currentBatchParams.model_versions\n                ],\n                // Include _msgid context if needed for debugging, but params is key\n                 _msgid_batch_start: msg._msgid + \"_batch_\" + (allParams.length * batchSize)\n            });\n            // Reset for next batch\n            currentBatchParams = { timestamps: [], device_ids: [], predicted_watts: [], model_versions: [] };\n            batchCount = 0;\n        }\n    } else {\n         node.warn(`Skipping invalid prediction object in batch: ${JSON.stringify(pred)}`);\n    }\n}\n\n// Add any remaining predictions in the last partial batch\nif (batchCount > 0) {\n     allParams.push({\n         params: [\n             currentBatchParams.timestamps,\n             currentBatchParams.device_ids,\n             currentBatchParams.predicted_watts,\n             currentBatchParams.model_versions\n         ],\n          _msgid_batch_start: msg._msgid + \"_batch_\" + (allParams.length * batchSize)\n     });\n}\n\nnode.log(`Prepared ${allParams.length} batches for insert.`);\n\n// --- IMPORTANT ---\n// Keep the original msg.payload for the main response path (Output 1)\n// Create a *new* message object containing the array of parameter batches for the DB path (Output 2)\nlet dbMsg = {\n    payload: allParams, // Array of {params: [...]} objects\n     _msgid: msg._msgid // Can reuse original msgid for this branch\n};\n\n// Output 1: Original message (minus predictions) for the HTTP response path\n// Output 2: New message with batched parameters for the DB insert path\ndelete msg.predictions; // Clean original message\nreturn [ msg, dbMsg ];",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1210,
        "y": 280,
        "wires": [
            [
                "3592a09331fdbdbd"
            ],
            [
                "d69fce717cce3024"
            ]
        ],
        "info": "**Purpose:** Prepares the large array of predictions from the Python script for efficient insertion into the database.\r\n**Logic:** It transforms the array of prediction objects into four separate arrays (timestamps, device_ids, predicted_watts, model_versions), which is the format required for PostgreSQL's efficient `UNNEST` function. It also splits the data into batches to avoid sending a single massive query."
    },
    {
        "id": "d69fce717cce3024",
        "type": "split",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Split Parameter Batches",
        "splt": "\\n",
        "spltType": "str",
        "arraySplt": 1,
        "arraySpltType": "len",
        "stream": false,
        "addname": "",
        "property": "payload",
        "x": 1270,
        "y": 340,
        "wires": [
            [
                "c998f79c73ca0cda"
            ]
        ]
    },
    {
        "id": "c998f79c73ca0cda",
        "type": "change",
        "z": "ac9683af7e82fb53",
        "g": "4080a0de8969fa04",
        "name": "Set Batch Params",
        "rules": [
            {
                "t": "set",
                "p": "params",
                "pt": "msg",
                "to": "payload.params",
                "tot": "msg"
            },
            {
                "t": "delete",
                "p": "payload",
                "pt": "msg"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 1250,
        "y": 400,
        "wires": [
            [
                "3dad15f0c8d11ced"
            ]
        ]
    },
    {
        "id": "766af32f4fe6ef26",
        "type": "inject",
        "z": "3248d6a231f4e9d0",
        "g": "97c76169fe166c15",
        "name": "Trigger Predict Every 10s",
        "props": [
            {
                "p": "payload"
            },
            {
                "p": "topic",
                "vt": "str"
            }
        ],
        "repeat": "10",
        "crontab": "",
        "once": true,
        "onceDelay": "10",
        "topic": "",
        "payload": "",
        "payloadType": "date",
        "x": 220,
        "y": 160,
        "wires": [
            [
                "fb200dd03d87ca0a"
            ]
        ],
        "info": "**Purpose:** The entry point for the flow. It triggers the entire prediction sequence at a fixed interval.\r\n**Frequency:** Runs every 10 seconds."
    },
    {
        "id": "fb200dd03d87ca0a",
        "type": "postgresql",
        "z": "3248d6a231f4e9d0",
        "g": "97c76169fe166c15",
        "name": "Get Device List for UI",
        "query": "SELECT device_id, api_ip, api_key\nFROM devices\nWHERE api_ip IS NOT NULL AND api_ip <> ''\n  AND api_key IS NOT NULL AND api_key <> '';",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 240,
        "y": 220,
        "wires": [
            [
                "727ae746539a786d"
            ]
        ],
        "info": "**Purpose:** Fetches the list of all devices that are configured to use the local PrusaLink API (i.e., they have an `api_ip` and `api_key`).\r\n**Output:** An array of device objects."
    },
    {
        "id": "727ae746539a786d",
        "type": "split",
        "z": "3248d6a231f4e9d0",
        "g": "97c76169fe166c15",
        "name": "Split Devices",
        "splt": "\\n",
        "spltType": "str",
        "arraySplt": 1,
        "arraySpltType": "len",
        "stream": false,
        "addname": "",
        "property": "payload",
        "x": 230,
        "y": 280,
        "wires": [
            [
                "5e276bfbbd3f9bb6"
            ]
        ],
        "info": "**Purpose:** Takes the array of devices from the previous node and splits it into a sequence of individual messages, one for each device. This allows the rest of the flow to process one printer at a time."
    },
    {
        "id": "5e276bfbbd3f9bb6",
        "type": "function",
        "z": "3248d6a231f4e9d0",
        "g": "9c69214ff198d9d8",
        "name": "Prepare Latest Data Query",
        "func": "// msg.payload contains a single printer object from the split node\n// e.g., { device_id: 'PrusaMK4-1', api_ip: '...', ... }\nconst printerInfo = msg.payload;\nconst deviceId = printerInfo.device_id;\n\nif (!deviceId) {\n    node.error(\"Missing device_id after split\", msg);\n    return null;\n}\n\n// Prepare parameters for the static SQL query in the next node\nmsg.params = [deviceId]; // Parameter $1 will be deviceId\n\n// Pass along device_id for later use when inserting prediction\nmsg.device_id = deviceId;\n\n// Clear unnecessary properties\nmsg.payload = {};\nmsg.topic = \"\";\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 600,
        "y": 280,
        "wires": [
            [
                "f3cf04893924fa13"
            ]
        ],
        "info": "**Purpose:** Prepares the `msg` object for the database query.\r\n**Logic:** It takes the `device_id` from the incoming message and places it into `msg.params`, which is the format required by the `postgresql` node."
    },
    {
        "id": "f3cf04893924fa13",
        "type": "postgresql",
        "z": "3248d6a231f4e9d0",
        "g": "9c69214ff198d9d8",
        "name": "Get Latest Data",
        "query": "-- Static Query to get latest data for one device ($1)\nWITH LatestStatus AS (\n    SELECT * FROM printer_status\n    WHERE device_id = $1 -- Use parameter\n    ORDER BY timestamp DESC\n    LIMIT 1\n), LatestEnergy AS (\n    SELECT * FROM energy_data\n    WHERE device_id = $1 -- Use parameter\n    ORDER BY timestamp DESC\n    LIMIT 1\n)\nSELECT\n    COALESCE(ls.timestamp, le.timestamp) as latest_timestamp,\n    $1 as device_id, -- Explicitly select the device_id passed as parameter\n    ls.state_text, ls.is_operational, ls.is_printing, ls.is_paused, ls.is_error,\n    ls.is_busy, ls.is_sd_ready, ls.nozzle_temp_actual, ls.nozzle_temp_target,\n    ls.bed_temp_actual, ls.bed_temp_target, ls.z_height_mm, ls.speed_multiplier_percent,\n    le.voltage, le.current_amps, le.plug_temp_c\nFROM LatestStatus ls\nFULL OUTER JOIN LatestEnergy le ON ls.device_id = le.device_id;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 600,
        "y": 340,
        "wires": [
            [
                "ebffcd036e7af362"
            ]
        ],
        "info": "**Purpose:** Gathers the single most recent sensor reading from both the `printer_status` and `energy_data` tables for the specific device being processed.\r\n**Output:** A single row of combined data containing all the features needed for the model."
    },
    {
        "id": "ebffcd036e7af362",
        "type": "function",
        "z": "3248d6a231f4e9d0",
        "g": "9c69214ff198d9d8",
        "name": "Prepare Features",
        "func": "// msg.payload should be an array containing 0 or 1 row\n// with combined latest status and energy data.\nif (!msg.payload || !Array.isArray(msg.payload) || msg.payload.length === 0) {\n    node.warn(`No recent combined data found for device ${msg.original_payload?.device_id}. Skipping prediction.`);\n    return null; // Stop if no data\n}\n\nconst latestData = msg.payload[0];\n\n// Prepare the feature object required by the Python node\n// This structure MUST match what the Python prediction part expects\n\n// Handle boolean conversion (DB returns 0/1 after our preprocessing)\nconst isPrinting = latestData.is_printing === 1 || latestData.is_printing === true;\n\n// Create the feature object - use null if data is missing\nlet features = {\n    'voltage': latestData.voltage ?? null,\n    'current_amps': latestData.current_amps ?? null,\n    'plug_temp_c': latestData.plug_temp_c ?? null,\n    'is_printing': isPrinting ? 1 : 0, // Ensure 0/1 for model\n    'nozzle_temp_actual': latestData.nozzle_temp_actual ?? null,\n    'bed_temp_actual': latestData.bed_temp_actual ?? null,\n    'z_height_mm': latestData.z_height_mm ?? null,\n    'speed_multiplier_percent': latestData.speed_multiplier_percent ?? null\n     // Add other features if your model uses them\n};\n\n// Store device_id for inserting prediction later\nmsg.device_id = latestData.device_id || msg.original_payload?.device_id;\n// Use latest timestamp from data if available\nmsg.prediction_timestamp = latestData.latest_timestamp || new Date().toISOString();\n\n// Pass ONLY the features object as payload to Python node\nmsg.payload = features;\n\n// Clear unneeded properties\ndelete msg.topic;\ndelete msg.params;\ndelete msg.original_payload;\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 630,
        "y": 400,
        "wires": [
            [
                "3be8ddb37a93844d"
            ]
        ],
        "info": "**Purpose:** Transforms the raw data from the database into the exact JSON format that the Python ML model expects.\r\n**Logic:** It renames keys, handles `null` values, and ensures the structure matches the model's input requirements."
    },
    {
        "id": "3be8ddb37a93844d",
        "type": "python-function",
        "z": "3248d6a231f4e9d0",
        "g": "9c69214ff198d9d8",
        "name": "Generate Prediction",
        "func": "# Node-RED Python Function Node: Generate Prediction (Live Predictor Flow)\n# --- Final Version: XGBoost, 7 Features, Post-processing ---\n\n# --- Imports & Environment ---\nimport sys\nimport os\n# --- Add venv path ---\nvenv_path = '/home/ubuntu/monitor_ml/venv/lib/python3.12/site-packages'\nif venv_path not in sys.path:\n    sys.path.append(venv_path)\n\nimport pandas as pd\nimport numpy as np\nimport joblib\nimport traceback\nimport warnings\n\n# --- Suppress Warnings ---\nwarnings.filterwarnings(\"ignore\", category=UserWarning, message=\"X does not have valid feature names\")\nwarnings.filterwarnings(\"ignore\", category=FutureWarning) # Broader future warning ignore\n\n# --- Configuration ---\nMODEL_DIR = '/home/ubuntu/monitor_ml/models'\nIMPUTE_VALUE_WHEN_API_MISSING = 0\n\n# --- Dynamic Model Selection ---\n# Get deviceId from the input message\ndevice_id = msg.get('device_id', '')\n\n# Default to Prusa model files\nMODEL_FILENAME = 'best_model.joblib'\nSCALER_FILENAME = 'scaler.joblib'\nSCALER_COLS_FILENAME = 'scaler_columns.joblib'\nMODEL_FEATURES_FILENAME = 'model_features.joblib'\nMODEL_TYPE_FOR_LOG = 'Prusa (XGBoost)'\n\n# If it's an Ender 3, switch to the Ender 3 model files\nif 'Ender-3' in device_id:\n    node.log(f\"Predictor - Ender 3 device ({device_id}) selected. Switching models.\")\n    MODEL_FILENAME = 'ender3_randomforest_model.joblib'\n    SCALER_FILENAME = 'ender3_scaler.joblib'\n    SCALER_COLS_FILENAME = 'ender3_scaler_columns.joblib'\n    MODEL_FEATURES_FILENAME = 'ender3_model_features.joblib'\n    MODEL_TYPE_FOR_LOG = 'Ender 3 (RandomForest)'\n\n# No log here to reduce noise in live predictor, unless needed for debugging\n# node.log(f\"Predictor - Using Model Type: {MODEL_TYPE_FOR_LOG}\")\n\n# Build final paths based on the selected filenames\nSCALER_PATH = os.path.join(MODEL_DIR, SCALER_FILENAME)\nMODEL_PATH = os.path.join(MODEL_DIR, MODEL_FILENAME)\nSCALER_COLS_PATH = os.path.join(MODEL_DIR, SCALER_COLS_FILENAME)\nMODEL_FEATURES_PATH = os.path.join(MODEL_DIR, MODEL_FEATURES_FILENAME)\n\n# --- Pre-load Model, Scaler, and Feature Lists ---\n# (Loads the latest artifacts saved by train_model.py)\nscaler = None; model = None; loading_error = None\nSCALER_COLUMNS = None; MODEL_FEATURES = None\nloading_error_details = {}\ntry: scaler = joblib.load(SCALER_PATH); node.log(\"Predictor - Loaded scaler.\")\nexcept Exception as e: loading_error_details[\"scaler\"] = f\"Scaler load error: {str(e)}\"; node.error(f\"Predictor - {loading_error_details['scaler']}\")\ntry: SCALER_COLUMNS = joblib.load(SCALER_COLS_PATH); node.log(f\"Predictor - Loaded scaler columns ({len(SCALER_COLUMNS) if SCALER_COLUMNS else 'None'}).\")\nexcept Exception as e: loading_error_details[\"scaler_cols\"] = f\"Scaler columns load error: {str(e)}\"; node.error(f\"Predictor - {loading_error_details['scaler_cols']}\")\ntry: model = joblib.load(MODEL_PATH); node.log(f\"Predictor - Loaded model from {MODEL_FILENAME}.\")\nexcept Exception as e: loading_error_details[\"model\"] = f\"Model load error: {str(e)}\"; node.error(f\"Predictor - {loading_error_details['model']}\")\ntry: MODEL_FEATURES = joblib.load(MODEL_FEATURES_PATH); node.log(f\"Predictor - Loaded model features ({len(MODEL_FEATURES) if MODEL_FEATURES else 'None'}).\")\nexcept Exception as e: loading_error_details[\"model_features\"] = f\"Model features load error: {str(e)}\"; node.error(f\"Predictor - {loading_error_details['model_features']}\")\n\nessential_components_missing = False\nif scaler is None or SCALER_COLUMNS is None or model is None or MODEL_FEATURES is None:\n    node.error(f\"Predictor - CRITICAL: One or more ML assets failed to load. Errors: {loading_error_details}\")\n    essential_components_missing = True\nloading_error = \"; \".join([f\"{k}: {v}\" for k, v in loading_error_details.items()]) if loading_error_details else None\n\n# === Main Execution Block (Called by Node-RED) ===\noutput_msg = None\n\nif essential_components_missing:\n    node.error(f\"Predictor - Aborting prediction due to essential component load failure: {loading_error}\")\nelse:\n    feature_dict = msg.get('payload', {}) # Input is a dictionary\n    device_id_from_input = msg.get('device_id', 'unknown_live_predictor')\n\n    if not isinstance(feature_dict, dict) or not feature_dict:\n        node.error(f\"Predictor - Input payload not a valid dictionary or empty for {device_id_from_input}.\")\n    else:\n        # node.log(f\"Predictor - Received features for {device_id_from_input}: {feature_dict}\")\n        try:\n            # --- Preprocessing for ML Model (7 Features) ---\n            # Create a single-row DataFrame from the input dictionary\n            # Ensure all expected model features exist as keys, even if value is None\n            input_data_with_all_keys = {f: feature_dict.get(f) for f in MODEL_FEATURES}\n            predict_df_processed = pd.DataFrame([input_data_with_all_keys], index=[0]) # Use index 0\n\n            # 1. Clean z_height_mm\n            if 'z_height_mm' in predict_df_processed.columns:\n                # Use .loc to modify the DataFrame slice correctly\n                predict_df_processed.loc[0, 'z_height_mm'] = pd.to_numeric(predict_df_processed.loc[0, 'z_height_mm'], errors='coerce')\n                if pd.notna(predict_df_processed.loc[0, 'z_height_mm']) and predict_df_processed.loc[0, 'z_height_mm'] < 0:\n                    predict_df_processed.loc[0, 'z_height_mm'] = IMPUTE_VALUE_WHEN_API_MISSING\n\n            # 2. Process 'is_printing'\n            if 'is_printing' in predict_df_processed.columns:\n                 processed_val = pd.to_numeric(predict_df_processed.loc[0, 'is_printing'], errors='coerce')\n                 predict_df_processed.loc[0, 'is_printing'] = int(processed_val) if pd.notna(processed_val) else IMPUTE_VALUE_WHEN_API_MISSING\n            elif 'is_printing' in MODEL_FEATURES: # Should be present now\n                 predict_df_processed['is_printing'] = IMPUTE_VALUE_WHEN_API_MISSING\n\n            # 3. Process and Impute other FINAL_MODEL_FEATURES\n            features_to_process = ['plug_temp_c', 'nozzle_temp_actual', 'bed_temp_actual', 'z_height_mm', 'nozzle_temp_target', 'bed_temp_target']\n            for col in features_to_process:\n                 if col in predict_df_processed.columns:\n                     # Impute NaNs (which includes None from .get() earlier)\n                     if pd.isna(predict_df_processed.loc[0, col]):\n                          predict_df_processed.loc[0, col] = IMPUTE_VALUE_WHEN_API_MISSING\n                 elif col in MODEL_FEATURES: # Expected but somehow still missing\n                      predict_df_processed[col] = IMPUTE_VALUE_WHEN_API_MISSING\n\n            # 4. Final checks and column ordering for scaler\n            missing_scaler_cols = [f for f in SCALER_COLUMNS if f not in predict_df_processed.columns]\n            if missing_scaler_cols:\n                 raise ValueError(f\"Scaler features missing after processing: {missing_scaler_cols}\")\n\n            # Reorder columns to match scaler order before scaling\n            X_predict = predict_df_processed[SCALER_COLUMNS]\n\n            # Final NaN check before scaling\n            if X_predict.isnull().values.any():\n                 nan_cols = X_predict.columns[X_predict.isnull().any()].tolist()\n                 node.error(f\"Predictor - CRITICAL: NaNs found before scaling in {nan_cols}! Filling with 0.\")\n                 X_predict = X_predict.fillna(0)\n\n            # --- Scaling & Prediction ---\n            # node.log(f\"Predictor - Data ready for scaling for {device_id_from_input}: {X_predict.iloc[0].to_dict()}\")\n            X_predict_scaled = scaler.transform(X_predict)\n            raw_prediction = model.predict(X_predict_scaled)[0]\n            # node.log(f\"Predictor - Raw prediction for {device_id_from_input}: {raw_prediction:.4f}\")\n\n            # --- Post-Processing Rule for Idle State ---\n            final_prediction = 0.0 # Default\n            # Check if the conditions for idle are met using the *processed* data\n            try:\n                # Retrieve processed values safely, defaulting to the imputed value if column somehow missing\n                is_printing_val = int(X_predict.get('is_printing', IMPUTE_VALUE_WHEN_API_MISSING).iloc[0])\n                nozzle_actual_val = X_predict.get('nozzle_temp_actual', IMPUTE_VALUE_WHEN_API_MISSING).iloc[0]\n                bed_actual_val = X_predict.get('bed_temp_actual', IMPUTE_VALUE_WHEN_API_MISSING).iloc[0]\n                nozzle_target_val = X_predict.get('nozzle_temp_target', IMPUTE_VALUE_WHEN_API_MISSING).iloc[0]\n                bed_target_val = X_predict.get('bed_temp_target', IMPUTE_VALUE_WHEN_API_MISSING).iloc[0]\n\n                # Check if all relevant conditions indicate idle/off\n                is_idle = (is_printing_val == 0 and\n                           nozzle_actual_val == IMPUTE_VALUE_WHEN_API_MISSING and\n                           bed_actual_val == IMPUTE_VALUE_WHEN_API_MISSING and\n                           nozzle_target_val == IMPUTE_VALUE_WHEN_API_MISSING and\n                           bed_target_val == IMPUTE_VALUE_WHEN_API_MISSING)\n\n                if is_idle:\n                    final_prediction = 0.0\n                    # node.log(f\"Predictor - Post-processing: Setting prediction to 0 for {device_id_from_input} based on idle conditions.\")\n                else:\n                    # Use model prediction, ensuring non-negative\n                    final_prediction = max(0.0, float(raw_prediction) if not np.isnan(raw_prediction) else 0.0)\n                    # node.log(f\"Predictor - Post-processing: Using model prediction {final_prediction:.4f} for {device_id_from_input}.\")\n\n            except Exception as post_proc_e:\n                 node.error(f\"Predictor - Error during post-processing logic for {device_id_from_input}: {post_proc_e}\")\n                 # Fallback to raw (non-negative) prediction if post-processing logic fails\n                 final_prediction = max(0.0, float(raw_prediction) if not np.isnan(raw_prediction) else 0.0)\n\n            # --- Format Output ---\n            output_payload = { \"predicted_power_watts\": final_prediction }\n            output_msg = {'payload': output_payload, 'device_id': device_id_from_input}\n\n        except ValueError as ve: node.error(f\"Predictor - Value error for {device_id_from_input}: {ve}\\\\n{traceback.format_exc()}\"); output_msg = None\n        except Exception as e: node.error(f\"Predictor - General error for {device_id_from_input}: {e}\\\\n{traceback.format_exc()}\"); output_msg = None\n\n# Return the final message object (or None if errors)\nreturn output_msg",
        "outputs": 1,
        "x": 640,
        "y": 460,
        "wires": [
            [
                "fb9f1203b23b0fbc"
            ]
        ],
        "info": "**Purpose:** The core of the flow. It uses a pre-trained machine learning model to predict the printer's power consumption based on its live sensor readings.\r\n\r\n**Logic:**\r\n1.  **Dynamic Model Selection:** Selects the correct model file (e.g., `best_model.joblib` for Prusa, `ender3_...` for Ender 3) based on the `device_id`.\r\n2.  **Load Artifacts:** Loads the corresponding scaler, feature list, and trained model from the `/home/ubuntu/monitor_ml/models` directory.\r\n3.  **Preprocessing:** Cleans the input features from Node-RED to match the format the model was trained on (e.g., imputing missing values with 0).\r\n4.  **Prediction:** Uses the loaded model to make the `predict()` call.\r\n5.  **Post-processing:** Applies a rule to set the prediction to `0.0` if the features indicate the printer is in an idle or off state.\r\n\r\n**Output:** A `msg.payload` object containing the final prediction, e.g., `{ \"predicted_power_watts\": 85.5 }`."
    },
    {
        "id": "fb9f1203b23b0fbc",
        "type": "function",
        "z": "3248d6a231f4e9d0",
        "g": "ac90879e0d7b329f",
        "name": "Prepare Prediction Insert",
        "func": "// msg.payload = { predicted_power_watts: ... } from Python node\n// msg.device_id = \"PrusaMK4-1\" (passed along from before Python node)\n\nconst predictionResult = msg.payload;\nconst deviceId = msg.device_id; // Get device_id passed along\nconst predictionValue = predictionResult?.predicted_power_watts; // Use optional chaining\nconst model_version = 'XGBoost'; // Hardcoded for now\nconst timestamp = new Date().toISOString(); // Use current time for prediction timestamp\n\n// Validation\nif (!deviceId || typeof predictionValue !== 'number' || isNaN(predictionValue)) {\n    node.error(`Invalid data for prediction insert. Device: ${deviceId}, Prediction: ${predictionValue}`, msg);\n    return null; // Stop if data is invalid\n}\n\n// Prepare parameters for the static query in the postgres node\n// Order: timestamp, device_id, predicted_power_watts, model_version\nmsg.params = [\n    timestamp,         // $1\n    deviceId,          // $2\n    predictionValue,   // $3\n    model_version      // $4\n];\n\n// Clean up message\nmsg.payload = {};\nmsg.topic = \"\";\n// delete msg.device_id; // Optional cleanup\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 970,
        "y": 460,
        "wires": [
            [
                "c67612e2cda72292"
            ]
        ],
        "info": "**Purpose:** Formats the prediction result into the correct structure for saving to the database.\r\n**Logic:** It creates the `msg.params` array with the `timestamp`, `device_id`, `predicted_power_watts`, and `model_version` in the correct order for the final `INSERT` query."
    },
    {
        "id": "c67612e2cda72292",
        "type": "postgresql",
        "z": "3248d6a231f4e9d0",
        "g": "ac90879e0d7b329f",
        "name": "Insert Prediction",
        "query": "INSERT INTO ml_predictions (\n    timestamp, device_id, predicted_power_watts, model_version\n)\nVALUES ($1, $2, $3, $4)\nON CONFLICT DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 980,
        "y": 520,
        "wires": [
            []
        ],
        "info": "**Purpose:** Inserts the new power prediction into the `ml_predictions` table.\r\n**Logic:** Executes the final `INSERT` query. `ON CONFLICT DO NOTHING` prevents errors from duplicate timestamps."
    },
    {
        "id": "fa8886be6b4eac09",
        "type": "function",
        "z": "fa2590c7f7889790",
        "name": "Prepare Env Insert",
        "func": "const weatherData = msg.payload;\n\nif (!weatherData || !weatherData.main || !weatherData.weather || !weatherData.name) {\n    node.error(\"Invalid or incomplete weather data received\", msg);\n    return null;\n}\n\nconst timestamp = new Date().toISOString(); // Using JS timestamp for now\nconst locationId = `${weatherData.name}_${weatherData.sys?.country || 'DE'}`;\nconst temperature = weatherData.main.temp ?? null;\nconst humidity = weatherData.main.humidity ?? null; // Value for humidity_pct\nconst condition = weatherData.weather.length > 0 ? weatherData.weather[0].main : null;\nconst source = \"DHT22_Sensor\";\n// Add dummy/placeholder values for columns we don't get from API (or fix table later)\nconst deviceIdForEnv = \"environment\"; // Use a fixed dummy ID\nconst pressure = weatherData.main.pressure ?? null; // Get pressure if available\n\n// Prepare parameters for the ACTUAL table structure\n// Order MUST match the INSERT statement's columns\n// timestamp, device_id, location_id, temperature_c, humidity_pct, pressure_hpa, weather_condition, source\nmsg.params = [\n    timestamp,          // $1 (Using JS timestamp now)\n    deviceIdForEnv,     // $2\n    locationId,         // $3\n    temperature,        // $4\n    humidity,           // $5 (Goes into humidity_pct)\n    pressure,           // $6 (Goes into pressure_hpa)\n    condition,          // $7 (Need to add weather_condition column to INSERT)\n    source              // $8 (Need to add source column to INSERT)\n];\n\nmsg.payload = {};\nmsg.topic = \"\";\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1210,
        "y": 500,
        "wires": [
            [
                "6c84bf4c3a68e698"
            ]
        ]
    },
    {
        "id": "6c84bf4c3a68e698",
        "type": "postgresql",
        "z": "fa2590c7f7889790",
        "name": "Insert Env Data",
        "query": "INSERT INTO environment_data (\n    -- List columns EXACTLY as in the table from \\d\n    timestamp,\n    device_id,\n    location_id,\n    temperature_c,\n    humidity_pct, -- Use correct column name\n    pressure_hpa, -- Include this column\n    weather_condition, -- Add this column\n    source -- Add this column\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7, $8) -- Match parameter count\nON CONFLICT (timestamp, device_id) DO NOTHING; -- Use ACTUAL primary key",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1400,
        "y": 500,
        "wires": [
            []
        ]
    },
    {
        "id": "aacf049e0513607a",
        "type": "function",
        "z": "fa2590c7f7889790",
        "name": "Adapt Combined DHT22 Data",
        "func": "// Node-RED Function: Adapt Combined DHT22 Data\n\nconst dhtData = msg.payload; // Now receives { temperature: X, humidity: Y }\n\nif (dhtData === null || typeof dhtData !== 'object' ||\n    typeof dhtData.temperature !== 'number' ||\n    typeof dhtData.humidity !== 'number') {\n    node.error(\"Invalid or incomplete combined DHT22 data received: \" + JSON.stringify(dhtData), msg);\n    return null;\n}\n\nconst temperature_c = dhtData.temperature;\nconst humidity_pct = dhtData.humidity;\n\n// Create the structure expected by 'Prepare Env Insert'\nmsg.payload = {\n    main: {\n        temp: temperature_c,\n        humidity: humidity_pct,\n        pressure: null\n    },\n    weather: [{ main: \"Local Sensor\" }],\n    name: \"LabSensor\", // Or specific location ID for your lab\n    sys: {\n        country: \"DE\" // Or your country code\n    }\n};\n\nnode.log(\"Adapted Combined DHT22 data: Temp=\" + temperature_c + \"C, Hum=\" + humidity_pct + \"%\");\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 970,
        "y": 500,
        "wires": [
            [
                "fa8886be6b4eac09"
            ]
        ]
    },
    {
        "id": "efaf2866c11c6fcd",
        "type": "mqtt in",
        "z": "fa2590c7f7889790",
        "name": "",
        "topic": "esp32/raptorblingx/dht22/humidity",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 370,
        "y": 540,
        "wires": [
            [
                "2c546d0e9506ae67"
            ]
        ]
    },
    {
        "id": "6361f5586683574f",
        "type": "mqtt in",
        "z": "fa2590c7f7889790",
        "name": "",
        "topic": "esp32/raptorblingx/dht22/temperature_c",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 350,
        "y": 460,
        "wires": [
            [
                "2c546d0e9506ae67"
            ]
        ]
    },
    {
        "id": "2c546d0e9506ae67",
        "type": "function",
        "z": "fa2590c7f7889790",
        "name": "Combine Temp & Humidity",
        "func": "// Node-RED Function: Combine Temperature & Humidity\n\nconst topic = msg.topic;\nconst payloadValue = parseFloat(msg.payload); // Assuming payload is just the number\n\nif (isNaN(payloadValue)) {\n    node.warn(\"Received non-numeric payload on topic: \" + topic + \" - Payload: \" + msg.payload);\n    return null; // Ignore invalid data\n}\n\n// Use flow context to store the latest readings\n// The context keys should be unique to this specific sensor if you have multiple DHT22s\nconst tempContextKey = \"dht22_temperature_c\";\nconst humContextKey = \"dht22_humidity_pct\";\n\nlet temperature = flow.get(tempContextKey);\nlet humidity = flow.get(humContextKey);\n\nif (topic.endsWith(\"temperature_c\")) {\n    temperature = payloadValue;\n    flow.set(tempContextKey, temperature);\n    // node.log(\"Stored temperature: \" + temperature);\n} else if (topic.endsWith(\"humidity\")) {\n    humidity = payloadValue;\n    flow.set(humContextKey, humidity);\n    // node.log(\"Stored humidity: \" + humidity);\n} else {\n    node.warn(\"Received message on unexpected DHT22 topic: \" + topic);\n    return null;\n}\n\n// Check if both values have been received\nif (typeof temperature === 'number' && typeof humidity === 'number') {\n    node.log(`Combining: Temp=${temperature}, Hum=${humidity}`);\n\n    // Create the payload expected by the \"Adapt DHT22 Data\" node\n    msg.payload = {\n        temperature: temperature,\n        humidity: humidity\n    };\n\n    // Reset context for the next pair of readings\n    flow.set(tempContextKey, undefined); // Or null\n    flow.set(humContextKey, undefined); // Or null\n\n    msg.topic = \"dht22/combined\"; // Set a new topic for the combined message\n    return msg; // Send the combined message\n} else {\n    // One of the values is still missing, wait for the other\n    // node.log(\"Waiting for other DHT22 value...\");\n    return null; // Don't send anything yet\n}",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 680,
        "y": 500,
        "wires": [
            [
                "aacf049e0513607a"
            ]
        ]
    },
    {
        "id": "da83c0553e3afc18",
        "type": "http in",
        "z": "249c21de5a8d56e0",
        "name": "GET /api/dpp_summary",
        "url": "/api/dpp_summary",
        "method": "get",
        "upload": false,
        "swaggerDoc": "",
        "x": 160,
        "y": 260,
        "wires": [
            [
                "749a57547b06df04"
            ]
        ],
        "info": "**Purpose:** Defines a public HTTP endpoint to provide a comprehensive summary of all printers for the Digital Product Passport (DPP) frontend.\n\n**Endpoint:** `GET /api/dpp_summary`\n\n**Logic:**\n- Listens for incoming GET requests.\n- Can optionally accept a `?scenario=` query parameter to trigger mock or dynamic simulation data for testing purposes. If no scenario is provided, it defaults to \"live\".\n\n**Output:**\n- Passes the `http` request object to the `exec` node."
    },
    {
        "id": "a096c3c3bc0cadfa",
        "type": "http response",
        "z": "249c21de5a8d56e0",
        "name": "Send DPP Summary",
        "statusCode": "200",
        "headers": {
            "content-type": "application/json"
        },
        "x": 1020,
        "y": 260,
        "wires": [],
        "info": "**Purpose:** Sends the JSON data generated by the Python script back to the client (the DPP frontend).\n\n**Logic:**\n- Takes the JSON string from the previous node's `msg.payload`.\n- Sets the HTTP `Content-Type` header to `application/json` to ensure the browser interprets the response correctly.\n- Sends the payload with a `200 OK` status code."
    },
    {
        "id": "467711c80608b20c",
        "type": "debug",
        "z": "249c21de5a8d56e0",
        "name": "debug 43",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 760,
        "y": 220,
        "wires": []
    },
    {
        "id": "749a57547b06df04",
        "type": "exec",
        "z": "249c21de5a8d56e0",
        "command": "/home/ubuntu/monitor_ml/venv/bin/python",
        "addpay": "",
        "append": "/home/ubuntu/monitor_ml/dpp_simulator.py --scenario live",
        "useSpawn": "false",
        "timer": "",
        "winHide": false,
        "oldrc": false,
        "name": "",
        "x": 520,
        "y": 260,
        "wires": [
            [
                "a096c3c3bc0cadfa",
                "467711c80608b20c"
            ],
            [
                "b95aceeec407ac3b"
            ],
            [
                "a717652788b078f6"
            ]
        ],
        "info": "**Purpose:** Executes the main Python script responsible for gathering, processing, and formatting all the data for the DPP.\n\n**Command:** `/home/ubuntu/monitor_ml/dpp_simulator.py --scenario live`\n\n**Logic:**\n1.  Calls the Python interpreter from the project's virtual environment.\n2.  Runs the `dpp_simulator.py` script.\n3.  The `--scenario live` argument tells the script to fetch real-time data from the PostgreSQL database.\n4.  The script's output (a single line of JSON) is passed to `stdout` (the first output of this node).\n\n**Output:**\n- `msg.payload`: A string containing the JSON summary of all printers."
    },
    {
        "id": "b95aceeec407ac3b",
        "type": "debug",
        "z": "249c21de5a8d56e0",
        "name": "debug 45",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 800,
        "y": 280,
        "wires": []
    },
    {
        "id": "a717652788b078f6",
        "type": "debug",
        "z": "249c21de5a8d56e0",
        "name": "debug 46",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 780,
        "y": 360,
        "wires": []
    },
    {
        "id": "f77d140fdd22352b",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/accel/x",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 400,
        "wires": [
            [
                "0c59e6a6c648cb94"
            ]
        ]
    },
    {
        "id": "2d183ac8c2d9dfd3",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/accel/y",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 460,
        "wires": [
            [
                "2fd609f72fb77e4b"
            ]
        ]
    },
    {
        "id": "3fecf642c398afec",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/accel/z",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 520,
        "wires": [
            [
                "2b0a996e7caaa58d"
            ]
        ]
    },
    {
        "id": "8950e05ca866624d",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/gyro/x",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 720,
        "wires": [
            [
                "f72a1cf8c3a8820c"
            ]
        ]
    },
    {
        "id": "7dc2945d2e4ddd8b",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/gyro/y",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 780,
        "wires": [
            [
                "60e80e7a6e1a6906"
            ]
        ]
    },
    {
        "id": "52fdc90785b7a1d7",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/gyro/z",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 240,
        "y": 840,
        "wires": [
            [
                "5396a4653d7c0e57"
            ]
        ]
    },
    {
        "id": "1fa08ed00a895506",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "",
        "topic": "esp32/raptorblingx/mpu6050/temperature_c",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 290,
        "y": 1000,
        "wires": [
            [
                "4816faa0ed4ee79e",
                "a397a019ff154ae9"
            ]
        ]
    },
    {
        "id": "024bf21a6248a91b",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "",
        "topic": "esp32/raptorblingx/max6675/temperature_c",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 270,
        "y": 1200,
        "wires": [
            [
                "8cc82821c9778c40"
            ]
        ]
    },
    {
        "id": "77f68480bd37ebd6",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "topic": "esp32/raptorblingx/dht22/temperature_c",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 450,
        "y": 100,
        "wires": [
            [
                "3e01886783462c76",
                "ada47b8b28f15571"
            ]
        ]
    },
    {
        "id": "4fb96e9054bdf405",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "topic": "esp32/raptorblingx/dht22/humidity",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 430,
        "y": 160,
        "wires": [
            [
                "777b7e75e17f5c70",
                "eb13bac943346fd7"
            ]
        ]
    },
    {
        "id": "3e01886783462c76",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "temperature_c",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 690,
        "y": 100,
        "wires": [
            [
                "2d1a2e9c46e83e5e"
            ]
        ]
    },
    {
        "id": "777b7e75e17f5c70",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "humidity_pct",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 690,
        "y": 160,
        "wires": [
            [
                "2d1a2e9c46e83e5e"
            ]
        ]
    },
    {
        "id": "0c59e6a6c648cb94",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "ax",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 400,
        "wires": [
            [
                "341fbee8495b1bd8"
            ]
        ]
    },
    {
        "id": "2fd609f72fb77e4b",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "ay",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 460,
        "wires": [
            [
                "341fbee8495b1bd8"
            ]
        ]
    },
    {
        "id": "2b0a996e7caaa58d",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "az",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 520,
        "wires": [
            [
                "341fbee8495b1bd8"
            ]
        ]
    },
    {
        "id": "f72a1cf8c3a8820c",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "gx",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 720,
        "wires": [
            [
                "c7e3549eb6f42dda"
            ]
        ]
    },
    {
        "id": "60e80e7a6e1a6906",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "gy",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 780,
        "wires": [
            [
                "c7e3549eb6f42dda"
            ]
        ]
    },
    {
        "id": "5396a4653d7c0e57",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "topic",
                "pt": "msg",
                "to": "gz",
                "tot": "str"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 470,
        "y": 840,
        "wires": [
            [
                "c7e3549eb6f42dda"
            ]
        ]
    },
    {
        "id": "4816faa0ed4ee79e",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "payload",
                "pt": "msg",
                "to": "$number(payload)",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 560,
        "y": 1000,
        "wires": [
            [
                "d23eed6a980f1398"
            ]
        ]
    },
    {
        "id": "8cc82821c9778c40",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "payload",
                "pt": "msg",
                "to": "$number(payload)",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 540,
        "y": 1200,
        "wires": [
            [
                "1be94df15edd18b0"
            ]
        ]
    },
    {
        "id": "7a4b6bd3f341238a",
        "type": "mqtt in",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "",
        "topic": "tele/smartplug_1/SENSOR",
        "qos": "2",
        "datatype": "auto-detect",
        "broker": "becc22b8f4461a4d",
        "nl": false,
        "rap": true,
        "rh": 0,
        "inputs": 0,
        "x": 190,
        "y": 1360,
        "wires": [
            [
                "d3de12f14d0f6a67",
                "2e2665c651268a2b"
            ]
        ]
    },
    {
        "id": "b04fbf43fa8829ce",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "Prepare DHT22 Insert",
        "func": "// Input msg.payload is { \"temperature_c\": \"26.2\", \"humidity_pct\": \"58.7\" } (strings)\nconst dhtStringData = msg.payload;\n\nif (!dhtStringData || typeof dhtStringData.temperature_c === 'undefined' || typeof dhtStringData.humidity_pct === 'undefined') {\n    node.error(\"Invalid or incomplete DHT22 string data received from Join\", msg);\n    return null;\n}\n\n// Convert to numbers here\nconst temp_c_num = parseFloat(dhtStringData.temperature_c);\nconst humidity_pct_num = parseFloat(dhtStringData.humidity_pct);\n\n// Check if conversion was successful and they are numbers\nif (isNaN(temp_c_num) || isNaN(humidity_pct_num)) {\n    node.error(\"Failed to convert DHT22 string values to numbers\", msg);\n    return null;\n}\n\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\";\n\nmsg.params = [\n    timestamp,           // $1\n    deviceId,            // $2\n    printerId,           // $3\n    temp_c_num,          // $4 (use the converted number)\n    humidity_pct_num     // $5 (use the converted number)\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1060,
        "y": 100,
        "wires": [
            [
                "7ef660eb1fcdad18",
                "883aea39948696ea"
            ]
        ]
    },
    {
        "id": "7ef660eb1fcdad18",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "query": "INSERT INTO dht22_data (\n    timestamp, device_id, printer_id, temperature_c, humidity_pct\n)\nVALUES ($1, $2, $3, $4, $5)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1250,
        "y": 100,
        "wires": [
            []
        ]
    },
    {
        "id": "30ea1788a5f64e85",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "Prepare MPU Gyro Insert",
        "func": "const gyroData = msg.payload; // Should be { gx: ..., gy: ..., gz: ... }\n\nif (!gyroData || typeof gyroData.gx !== 'number' || typeof gyroData.gy !== 'number' || typeof gyroData.gz !== 'number') {\n    node.error(\"Invalid or incomplete MPU gyroscope data\", msg);\n    return null;\n}\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\";\n\nmsg.params = [\n    timestamp,   // $1\n    deviceId,    // $2\n    printerId,   // $3\n    gyroData.gx, // $4\n    gyroData.gy, // $5\n    gyroData.gz  // $6\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 870,
        "y": 720,
        "wires": [
            [
                "8e0e73e8a1d28b6f",
                "34f84b9d88038512"
            ]
        ]
    },
    {
        "id": "8e0e73e8a1d28b6f",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "query": "INSERT INTO mpu6050_gyroscope_data (\n    timestamp, device_id, printer_id, gyro_x, gyro_y, gyro_z\n)\nVALUES ($1, $2, $3, $4, $5, $6)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1070,
        "y": 720,
        "wires": [
            []
        ]
    },
    {
        "id": "d23eed6a980f1398",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "Prepare MPU Temp Insert",
        "func": "const tempValue = msg.payload; // Numeric temperature\n\nif (typeof tempValue !== 'number' || isNaN(tempValue)) {\n    node.error(\"Invalid MPU temperature value\", msg);\n    return null;\n}\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\";\n\nmsg.params = [\n    timestamp,    // $1\n    deviceId,     // $2\n    printerId,    // $3\n    tempValue     // $4\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 770,
        "y": 1000,
        "wires": [
            [
                "857d777ce2057c48",
                "ca5aa4b3df152834"
            ]
        ]
    },
    {
        "id": "857d777ce2057c48",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "",
        "query": "INSERT INTO mpu6050_temperature_data (\n    timestamp, device_id, printer_id, temperature_c\n)\nVALUES ($1, $2, $3, $4)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 990,
        "y": 1000,
        "wires": [
            []
        ]
    },
    {
        "id": "1be94df15edd18b0",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "Prepare MAX6675 Temp Insert",
        "func": "const tempValue = msg.payload; // Numeric temperature\n\nif (typeof tempValue !== 'number' || isNaN(tempValue)) {\n    node.error(\"Invalid MAX6675 temperature value\", msg);\n    return null;\n}\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\";\n\nmsg.params = [\n    timestamp,    // $1\n    deviceId,     // $2\n    printerId,    // $3\n    tempValue     // $4\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 770,
        "y": 1200,
        "wires": [
            [
                "3a967bc486f43c82",
                "cdf20cc9119bd677"
            ]
        ]
    },
    {
        "id": "3a967bc486f43c82",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "",
        "query": "INSERT INTO max6675_temperature_data (\n    timestamp, device_id, printer_id, temperature_c\n)\nVALUES ($1, $2, $3, $4)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1010,
        "y": 1200,
        "wires": [
            []
        ]
    },
    {
        "id": "d3de12f14d0f6a67",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "Prepare Smart Plug Insert",
        "func": "const tasmotaData = msg.payload; // Assumes MQTT In node outputs parsed JSON\n\nif (!tasmotaData || !tasmotaData.Time || !tasmotaData.ENERGY) {\n    node.error(\"Invalid or incomplete Tasmota SENSOR data\", msg);\n    return null;\n}\n\nconst timestamp = new Date(tasmotaData.Time).toISOString();\nconst topicParts = msg.topic.split('/');\nconst deviceId = topicParts.length > 1 ? topicParts[1] : \"unknown_smartplug\";\n\nconst energy = tasmotaData.ENERGY;\nconst power_w = energy.Power ?? null;\nconst energy_total_kwh = energy.Total ?? null;\nconst energy_today_kwh = energy.Today ?? null;\nconst voltage_v = energy.Voltage ?? null;\nconst current_a = energy.Current ?? null;\nconst power_factor = energy.Factor ?? null;\nconst apparent_power_va = energy.ApparentPower ?? null;\nconst reactive_power_var = energy.ReactivePower ?? null;\n\nnode.warn(`Power data missing for device ${deviceId} at ${timestamp}: ${JSON.stringify(msg)}`);\n\nmsg.params = [\n    timestamp,             // $1\n    deviceId,              // $2\n    power_w,               // $3\n    energy_total_kwh,      // $4\n    energy_today_kwh,      // $5\n    voltage_v,             // $6\n    current_a,             // $7\n    power_factor,          // $8\n    apparent_power_va,     // $9\n    reactive_power_var     // $10\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 430,
        "y": 1360,
        "wires": [
            [
                "3549f4574b9800c8"
            ]
        ]
    },
    {
        "id": "3549f4574b9800c8",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "",
        "query": "INSERT INTO smartplug_data (\n    timestamp, device_id, power_w, energy_total_kwh, energy_today_kwh,\n    voltage_v, current_a, power_factor, apparent_power_va, reactive_power_var\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\nON CONFLICT (timestamp, device_id) DO UPDATE SET\n    power_w = EXCLUDED.power_w,\n    energy_total_kwh = EXCLUDED.energy_total_kwh,\n    energy_today_kwh = EXCLUDED.energy_today_kwh,\n    voltage_v = EXCLUDED.voltage_v,\n    current_a = EXCLUDED.current_a,\n    power_factor = EXCLUDED.power_factor,\n    apparent_power_va = EXCLUDED.apparent_power_va,\n    reactive_power_var = EXCLUDED.reactive_power_var;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 630,
        "y": 1360,
        "wires": [
            []
        ]
    },
    {
        "id": "c7e3549eb6f42dda",
        "type": "join",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "",
        "mode": "custom",
        "build": "object",
        "property": "payload",
        "propertyType": "msg",
        "key": "topic",
        "joiner": "\\n",
        "joinerType": "str",
        "useparts": false,
        "accumulate": false,
        "timeout": "1",
        "count": "3",
        "reduceRight": false,
        "reduceExp": "",
        "reduceInit": "",
        "reduceInitType": "",
        "reduceFixup": "",
        "x": 650,
        "y": 780,
        "wires": [
            [
                "30ea1788a5f64e85"
            ]
        ]
    },
    {
        "id": "2d1a2e9c46e83e5e",
        "type": "join",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "",
        "mode": "custom",
        "build": "object",
        "property": "payload",
        "propertyType": "msg",
        "key": "topic",
        "joiner": "\\n",
        "joinerType": "str",
        "useparts": false,
        "accumulate": false,
        "timeout": "1",
        "count": "2",
        "reduceRight": false,
        "reduceExp": "",
        "reduceInit": "",
        "reduceInitType": "",
        "reduceFixup": "",
        "x": 870,
        "y": 140,
        "wires": [
            [
                "b04fbf43fa8829ce"
            ]
        ]
    },
    {
        "id": "883aea39948696ea",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "debug 31",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1160,
        "y": 60,
        "wires": []
    },
    {
        "id": "a397a019ff154ae9",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "debug 41",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 510,
        "y": 1040,
        "wires": []
    },
    {
        "id": "ca5aa4b3df152834",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "93d1043233d62247",
        "name": "debug 43",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 910,
        "y": 1040,
        "wires": []
    },
    {
        "id": "cdf20cc9119bd677",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "debug 44",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 970,
        "y": 1240,
        "wires": []
    },
    {
        "id": "01929e1883714b74",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "query": "INSERT INTO mpu6050_accelerometer_data (\n    timestamp, device_id, printer_id, accel_x, accel_y, accel_z\n)\nVALUES ($1, $2, $3, $4, $5, $6)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1350,
        "y": 400,
        "wires": [
            []
        ]
    },
    {
        "id": "aa107ae95410814c",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "debug 34",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 1350,
        "y": 340,
        "wires": []
    },
    {
        "id": "341fbee8495b1bd8",
        "type": "join",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "",
        "mode": "custom",
        "build": "object",
        "property": "payload",
        "propertyType": "msg",
        "key": "topic",
        "joiner": "\\n",
        "joinerType": "str",
        "useparts": false,
        "accumulate": false,
        "timeout": "1",
        "count": "3",
        "reduceRight": false,
        "reduceExp": "",
        "reduceInit": "",
        "reduceInitType": "",
        "reduceFixup": "",
        "x": 630,
        "y": 460,
        "wires": [
            [
                "0abcfd1a02f4a19a",
                "642a28ac55077c32"
            ]
        ]
    },
    {
        "id": "0abcfd1a02f4a19a",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Prepare MPU Accel Insert",
        "func": "const accelData = msg.payload; // Should be { ax: ..., ay: ..., az: ... }\n\nif (!accelData || typeof accelData.ax !== 'number' || typeof accelData.ay !== 'number' || typeof accelData.az !== 'number') {\n    node.error(\"Invalid or incomplete MPU accelerometer data\", msg);\n    return null;\n}\n\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\"; // Or null\n\nmsg.params = [\n    timestamp,    // $1\n    deviceId,     // $2\n    printerId,    // $3\n    accelData.ax, // $4\n    accelData.ay, // $5\n    accelData.az  // $6\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 870,
        "y": 400,
        "wires": [
            [
                "01929e1883714b74",
                "aa107ae95410814c"
            ]
        ]
    },
    {
        "id": "642a28ac55077c32",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Calculate MPU RMS & Apply Manual Threshold",
        "func": "const accelData = msg.payload; // Expects { ax: ..., ay: ..., az: ... }\n\nif (!accelData || typeof accelData.ax !== 'number' || typeof accelData.ay !== 'number' || typeof accelData.az !== 'number') {\n    node.error(\"RMS Calc: Invalid MPU accelerometer data received from Join\", msg);\n    return null;\n}\n\n// Calculate magnitude of acceleration vector\nconst magnitude = Math.sqrt(\n    accelData.ax * accelData.ax +\n    accelData.ay * accelData.ay +\n    accelData.az * accelData.az\n);\n\n// Subtract 1g for gravity (approximate). \n// Assumes MPU6050 gives readings around 1g for static Z-axis due to gravity.\n// This value might need slight tuning if your baseline 'g' is consistently off from 1.0\nconst vibration = Math.abs(magnitude - 9.81); // Or Math.abs(magnitude - 1.0) if your MPU outputs in 'g's directly\n// If your MPU already outputs m/s^2 and z is ~9.8 when still, this is fine.\n// If your MPU is outputting raw ADC values, this math needs to be scaled.\n// Given your previous debug values (-0.9, -9.9, -4.5), it seems like Z is not isolated gravity.\n// A simpler RMS without gravity subtraction might be better initially if orientation is not fixed.\n\n// --- Simpler RMS Approach (less sensitive to orientation, good for general vibration) ---\n// Calculate RMS of the changes or just the raw values if consistently oriented.\n// For now, let's use a simpler approach that looks at overall G-force magnitude change.\n// The AI's original: const g = Math.sqrt(ax*ax + ay*ay + az*az) - 1; const rms = Math.sqrt(g*g);\n// This is | |vector_a| - 1g | which is good if 1g is perfectly along one axis when idle.\n\n// Let's use the AI's simplified RMS for now:\nconst g_force_magnitude = Math.sqrt(accelData.ax * accelData.ax + accelData.ay * accelData.ay + accelData.az * accelData.az);\n\n// Assuming your accelerometer is outputting in m/s^2, and '1g' is approx 9.81 m/s^2.\n// If it's outputting in 'g's directly, use 1.0 instead of 9.81.\n// For simplicity, let's assume you want to detect any significant deviation from a stable state.\n// The AI's suggestion for RMS was:\n// const g_val = Math.sqrt(ax*ax + ay*ay + az*az) - 1; // if output is in 'g'\n// const rms_val = Math.sqrt(g_val*g_val); // This is just Math.abs(g_val)\n\n// Let's calculate the magnitude of the AC component (vibration) assuming gravity is somewhat stable.\n// A true RMS over a window is better, but for MVP let's do a simpler \"activity level\".\n// We need a baseline 'still' magnitude. For now, let's just use magnitude.\n// For MVP, a simpler \"activity\" metric might be just the magnitude if it changes enough.\n\n// Let's refine the RMS calculation for the sliding window as discussed in the AI plan (Phase 0, step 2)\n// but implement it simply here for now. The key is the thresholding.\n\n// For this MVP, let's use the magnitude of the vector and assume '1g' is the baseline.\n// This is a simplification. A proper RMS over a window of (magnitude - average_idle_magnitude) is better.\n// The AI suggested: const g = Math.sqrt(ax*ax + ay*ay + az*az) - 1; // (if '1' is 1g)\n//                     const rms = Math.sqrt(g*g); // which is effectively Math.abs(g)\n\n// Let's assume your MPU6050 output for ax, ay, az is in m/s^2.\n// And when stationary, one axis (e.g., az) shows ~9.81 m/s^2 (or -9.81).\n// A simple \"activity\" can be the change from this.\n// For now, to match AI's simple RMS for the MVP:\nconst current_rms_value = Math.abs(g_force_magnitude - 9.81); // Adjust 9.81 if your 'g' units are different or if baseline is different\n\n// Get the manual threshold from flow context (set by a dashboard input)\nconst manual_threshold = flow.get(\"manual_mpu_threshold\") || 0.05; // Default if not set\n\nconst isMoving = (current_rms_value > manual_threshold) ? 1 : 0;\n\nmsg.payload = {\n    is_moving: isMoving,\n    moving_rms: parseFloat(current_rms_value.toFixed(3)), // Store the calculated RMS\n    moving_threshold: manual_threshold\n    // We'll add process_phase: null here later, or it will be handled by another function\n};\n// We will prepare params for PostgreSQL in the next function node\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 880,
        "y": 480,
        "wires": [
            [
                "03ba2dc03bc7ac47"
            ]
        ]
    },
    {
        "id": "03ba2dc03bc7ac47",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Prepare Derived Status Insert",
        "func": "const derivedData = msg.payload; // Expects { is_moving: ..., moving_rms: ..., moving_threshold: ... }\n\nif (typeof derivedData.is_moving === 'undefined') { // Basic check\n    node.error(\"Derived Status: Incomplete data received\", msg);\n    return null;\n}\n\nconst timestamp = new Date().toISOString();\nconst deviceId = \"ESP32_SensorHub_Raptor\";\nconst printerId = \"PRUSA_MK3_Test_TR\";\n\n// For table: printer_derived_status \n// (timestamp, device_id, printer_id, is_moving, moving_rms, moving_threshold, process_phase)\nmsg.params = [\n    timestamp,                  // $1\n    deviceId,                   // $2\n    printerId,                  // $3\n    derivedData.is_moving,      // $4\n    derivedData.moving_rms,     // $5\n    derivedData.moving_threshold, // $6\n    null                        // $7 (process_phase will be updated later)\n];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 910,
        "y": 520,
        "wires": [
            [
                "d6ac7d1660c10d16",
                "c76f96030d02bb57"
            ]
        ]
    },
    {
        "id": "d6ac7d1660c10d16",
        "type": "ui_numeric",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Set MPU Threshold",
        "label": "MPU Moving Threshold",
        "tooltip": "Vibration RMS threshold to detect movement",
        "group": "2b76591607efec25",
        "order": 0,
        "width": "3",
        "height": "1",
        "wrap": false,
        "passthru": true,
        "topic": "topic",
        "topicType": "msg",
        "format": "{{value}}",
        "min": 0,
        "max": "1",
        "step": "0.01",
        "className": "",
        "x": 1170,
        "y": 540,
        "wires": [
            [
                "4d42faa80d69d4e3"
            ]
        ]
    },
    {
        "id": "4d42faa80d69d4e3",
        "type": "change",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Store MPU Threshold",
        "rules": [
            {
                "t": "set",
                "p": "manual_mpu_threshold",
                "pt": "flow",
                "to": "payload",
                "tot": "msg"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 1370,
        "y": 540,
        "wires": [
            []
        ]
    },
    {
        "id": "c76f96030d02bb57",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "5e9c772230c2d4b1",
        "name": "Prepare Derived Status Insert",
        "query": "INSERT INTO printer_derived_status (\n    timestamp, device_id, printer_id, is_moving, moving_rms, moving_threshold, process_phase\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7)\nON CONFLICT (timestamp, device_id) DO UPDATE SET\n    is_moving = EXCLUDED.is_moving,\n    moving_rms = EXCLUDED.moving_rms,\n    moving_threshold = EXCLUDED.moving_threshold;\n    -- Don't update process_phase here if it's being set by another flow later",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1240,
        "y": 500,
        "wires": [
            []
        ]
    },
    {
        "id": "34f84b9d88038512",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "fc75ba5343df4163",
        "name": "debug 30",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 990,
        "y": 780,
        "wires": []
    },
    {
        "id": "ada47b8b28f15571",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "debug 35",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 730,
        "y": 60,
        "wires": []
    },
    {
        "id": "eb13bac943346fd7",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "3227026642a6ed7d",
        "name": "debug 37",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 630,
        "y": 200,
        "wires": []
    },
    {
        "id": "2e2665c651268a2b",
        "type": "function",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "Format for energy_data",
        "func": "const tasmotaData = msg.payload;\n\nif (!tasmotaData || !tasmotaData.Time || !tasmotaData.ENERGY) {\n    node.error(\"Tasmota SENSOR data for energy_data table is invalid.\", msg);\n    return null;\n}\n\n// Hardcode the device ID for the printer this plug is attached to\nconst deviceId = 'Ender-3-Pro-1';\n\nconst energy = tasmotaData.ENERGY;\nconst power_watts = energy.Power ?? null;\nconst total_wh = (energy.Total * 1000) ?? null; // Tasmota reports kWh, convert to Wh\nconst voltage = energy.Voltage ?? null;\nconst current_amps = energy.Current ?? null;\nconst plug_temp_c = null; // Tasmota ENERGY payload doesn't have plug temp\nconst energy_today_kwh = energy.Today ?? null;\n\n\nmsg.params = [\n    new Date(tasmotaData.Time).toISOString(), // $1: timestamp\n    deviceId,                                 // $2: device_id\n    power_watts,                              // $3: power_watts\n    total_wh,                                 // $4: energy_total_wh\n    voltage,                                  // $5: voltage\n    current_amps,                             // $6: current_amps\n    plug_temp_c,\n    energy_today_kwh                              \n];\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 380,
        "y": 1460,
        "wires": [
            [
                "567460cf38ab8b90",
                "b8b9fa1094ca6c9c"
            ]
        ]
    },
    {
        "id": "567460cf38ab8b90",
        "type": "postgresql",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "Insert into energy_data",
        "query": "INSERT INTO energy_data (\n    timestamp, device_id, power_watts, energy_total_wh,\n    voltage, current_amps, plug_temp_c, energy_today_kwh\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7, $8)\nON CONFLICT (timestamp, device_id) DO NOTHING;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 620,
        "y": 1460,
        "wires": [
            []
        ]
    },
    {
        "id": "b8b9fa1094ca6c9c",
        "type": "debug",
        "z": "44c225e855f817f8",
        "g": "75074842157a7df5",
        "name": "debug 52",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 510,
        "y": 1500,
        "wires": []
    },
    {
        "id": "798789cfc80de203",
        "type": "comment",
        "z": "44c225e855f817f8",
        "g": "ce458d19dac54c24",
        "name": "",
        "info": "**Purpose:** Adapts and standardizes the data from a Tasmota-flashed smart plug to match the schema of the main `energy_data` table.\n\n**Logic:**\n1.  Receives the Tasmota `SENSOR` JSON payload.\n2.  Extracts the `Power`, `Total` (energy), `Voltage`, and `Current` values.\n3.  **Important:** It hardcodes the `device_id` to `'Ender-3-Pro-1'`, correctly associating this specific plug's data with the Ender 3 Pro printer.\n4.  Converts the energy from kWh (Tasmota's format) to Wh to match the `energy_data` table's standard unit.\n\n**Output:**\n- `msg.params`: A correctly formatted array ready for insertion into the `energy_data` table.",
        "x": 300,
        "y": 1260,
        "wires": []
    },
    {
        "id": "a7242811e93e7be7",
        "type": "inject",
        "z": "28ad1cc5547cbab4",
        "name": "",
        "props": [
            {
                "p": "payload"
            },
            {
                "p": "topic",
                "vt": "str"
            }
        ],
        "repeat": "900",
        "crontab": "",
        "once": true,
        "onceDelay": "1",
        "topic": "",
        "payload": "",
        "payloadType": "date",
        "x": 110,
        "y": 540,
        "wires": [
            [
                "1ee47b8c409b842a"
            ]
        ]
    },
    {
        "id": "1ee47b8c409b842a",
        "type": "function",
        "z": "28ad1cc5547cbab4",
        "name": "Prepare Get Our Devices",
        "func": "msg.params = [];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 310,
        "y": 580,
        "wires": [
            [
                "593361445b476de3"
            ]
        ]
    },
    {
        "id": "593361445b476de3",
        "type": "postgresql",
        "z": "28ad1cc5547cbab4",
        "name": "Get Device List",
        "query": "SELECT\n    device_id,\n    simplyprint_id,\n    sp_company_id,\n    sp_api_key\nFROM devices\nWHERE simplyprint_id IS NOT NULL\n  AND sp_company_id IS NOT NULL\n  AND sp_api_key IS NOT NULL;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 500,
        "y": 640,
        "wires": [
            [
                "942803aaca3750ef"
            ]
        ]
    },
    {
        "id": "942803aaca3750ef",
        "type": "function",
        "z": "28ad1cc5547cbab4",
        "name": "Prepare Job History Request",
        "func": "// msg.payload contains the array of devices from the database.\nconst devices = msg.payload;\n\nif (!Array.isArray(devices) || devices.length === 0) {\n    node.warn(\"No SimplyPrint devices with full credentials found in database.\");\n    return null; // Stop the flow\n}\n\nconst requestMessages = []; // Array to hold all messages to be sent\n\nfor (const device of devices) {\n    if (!device.simplyprint_id || !device.sp_company_id || !device.sp_api_key) {\n        node.warn(`Skipping device with incomplete SimplyPrint credentials: ${device.device_id}`);\n        continue;\n    }\n\n    // Create a new message object for this device's API call\n    const newMsg = {\n        method: \"POST\",\n        headers: {\n            'X-API-KEY': device.sp_api_key,       // <-- DYNAMIC from DB\n            'Content-Type': 'application/json'\n        },\n        url: `https://api.simplyprint.io/${device.sp_company_id}/printers/Get`, // <-- DYNAMIC from DB\n        payload: { \"pid\": parseInt(device.simplyprint_id, 10) },\n        internal_device_id: device.device_id // Pass our internal ID along\n    };\n\n    requestMessages.push(newMsg);\n}\n\n// Return the entire array of messages. Node-RED will send them one by one.\nreturn [requestMessages];",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 720,
        "y": 700,
        "wires": [
            [
                "4fd21579aa625bbd"
            ]
        ]
    },
    {
        "id": "4fd21579aa625bbd",
        "type": "http request",
        "z": "28ad1cc5547cbab4",
        "name": "Get Printer Data",
        "method": "use",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 900,
        "y": 760,
        "wires": [
            [
                "b5cf5822bf59d0bb"
            ]
        ]
    },
    {
        "id": "b5cf5822bf59d0bb",
        "type": "function",
        "z": "28ad1cc5547cbab4",
        "name": "Process & Prepare Insert",
        "func": "// Node: Process Printer Data & Prepare Insert (Corrected Single-Message Pattern)\n\nconst apiResponse = msg.payload;\nconst internalDeviceId = msg.internal_device_id;\n\n\n// --- Validate the API response structure ---\nif (!apiResponse || !apiResponse.status || !Array.isArray(apiResponse.data) || apiResponse.data.length === 0) {\n    // FIX: Combine message and object into a single string argument for node.warn()\n    node.warn(`Invalid API response or empty data array received. Original message: ${JSON.stringify(msg)}`);\n    return null;\n}\n\nconst printerData = apiResponse.data[0];\nconst job = printerData.job;\n\nif (!job || !job.id) {\n    node.warn(\"No job information in API response for \" + internalDeviceId);\n    return null;\n}\n\nconst simplyprintJobId = job.id.toString();\nconst filename = job.file;\nconst status = job.state;\nconst endTime = job.ended;\nconst durationSeconds = job.time ? Math.round(job.time) : null;\nconst filamentGrams = null; // Placeholder\n\nlet startTime = null;\nif (endTime && typeof durationSeconds === 'number') {\n    try {\n        const endDate = new Date(endTime);\n        const startDate = new Date(endDate.getTime() - (durationSeconds * 1000));\n        startTime = startDate.toISOString();\n    } catch (e) {\n        node.error(`Could not calculate start time for job ${simplyprintJobId}: ${e}`);\n    }\n}\n\n// Overwrite msg.params with the array for the next node\nmsg.params = [\n    simplyprintJobId,\n    internalDeviceId,\n    startTime,\n    endTime,\n    durationSeconds,\n    status,\n    filename,\n    filamentGrams\n];\n\n// Clear the payload as it's not needed by the postgres node\nmsg.payload = {};\n\n// Return the single, prepared message\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1090,
        "y": 840,
        "wires": [
            [
                "2e03ce18e7b43a0e"
            ]
        ]
    },
    {
        "id": "2e03ce18e7b43a0e",
        "type": "postgresql",
        "z": "28ad1cc5547cbab4",
        "name": "Insert/Update Job Data",
        "query": "INSERT INTO print_jobs (\n    simplyprint_job_id, device_id, start_time, end_time,\n    duration_seconds, status, filename, filament_used_g\n)\nVALUES ($1, $2, $3, $4, $5, $6, $7, $8)\nON CONFLICT (simplyprint_job_id) DO UPDATE SET\n    end_time = EXCLUDED.end_time,\n    duration_seconds = EXCLUDED.duration_seconds,\n    status = EXCLUDED.status;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1350,
        "y": 900,
        "wires": [
            []
        ]
    },
    {
        "id": "02ea663491d7ef4b",
        "type": "inject",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Poll All Printers Every 30s",
        "props": [],
        "repeat": "30",
        "crontab": "",
        "once": true,
        "onceDelay": "1",
        "topic": "",
        "x": 180,
        "y": 220,
        "wires": [
            [
                "d6bbc141d674690b"
            ]
        ]
    },
    {
        "id": "d6bbc141d674690b",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Get All Devices Config",
        "query": "SELECT * FROM devices WHERE device_id != 'environment';",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 220,
        "y": 260,
        "wires": [
            [
                "3bf69c618d3771ca"
            ]
        ],
        "info": "**Purpose:** Fetches the configuration for all active 3D printers from the `devices` table in the database.\r\n\r\n**Trigger:** Fired every 30 seconds by the \"Poll All Printers\" inject node.\r\n\r\n**Output:**\r\n- `msg.payload`: An array of objects, where each object is a row from the `devices` table.\r\n\r\n**Next Step:** The payload is passed to a `split` node to process each device individually."
    },
    {
        "id": "3bf69c618d3771ca",
        "type": "split",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "For Each Device",
        "splt": "\\n",
        "spltType": "str",
        "arraySplt": 1,
        "arraySpltType": "len",
        "stream": false,
        "addname": "",
        "property": "payload",
        "x": 250,
        "y": 320,
        "wires": [
            [
                "f3858a8857ffde13"
            ]
        ]
    },
    {
        "id": "b27da203e5c23ee9",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare SimplyPrint Request",
        "func": "const device = msg.payload;\n// Save the full config for later enrichment steps\nmsg.original_device_config = device; \n\nmsg.method = \"POST\";\nmsg.headers = {\n    'X-API-KEY': device.sp_api_key, // Use the key from this specific device's row\n    'Content-Type': 'application/json'\n};\nmsg.url = `https://api.simplyprint.io/${device.sp_company_id}/printers/Get`;\nmsg.payload = { \"pid\": parseInt(device.simplyprint_id, 10) };\n\nreturn msg;",
        "outputs": 1,
        "timeout": "",
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 680,
        "y": 600,
        "wires": [
            [
                "ea15470d20a551d0",
                "b9a4c25e40aeeef0"
            ]
        ]
    },
    {
        "id": "f4ec324598c62401",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare PrusaLink Request",
        "func": "const device = msg.payload;\n\n// Save the full device config so we can use it again in the next step\nmsg.original_device_config = device;\n\n// Prepare the FIRST API call to the /printer endpoint\nmsg.url = `http://${device.api_ip}/api/printer`;\nmsg.headers = { 'X-Api-Key': device.api_key };\nmsg.payload = {}; // This is a GET request, so payload is empty\n\nreturn msg;",
        "outputs": 1,
        "timeout": "",
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 800,
        "y": 240,
        "wires": [
            [
                "2ad6a970bba49d5f",
                "e4a60772850676ff"
            ]
        ]
    },
    {
        "id": "ea15470d20a551d0",
        "type": "http request",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call SimplyPrint API",
        "method": "POST",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": true,
        "x": 680,
        "y": 660,
        "wires": [
            [
                "5dda7fb58e2cb2a2",
                "d43ff076a1a9a7bf"
            ]
        ]
    },
    {
        "id": "2ad6a970bba49d5f",
        "type": "http request",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call Prusa /printer API",
        "method": "GET",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": true,
        "headers": [],
        "x": 1080,
        "y": 240,
        "wires": [
            [
                "153a9432435bf76b",
                "574260bbc0dc2b2f"
            ]
        ]
    },
    {
        "id": "153a9432435bf76b",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare Prusa /job Request",
        "func": "// Store the response from the first API call (/printer)\nmsg.printer_api_response = msg.payload;\n\n// Retrieve the saved device config from the first step\nconst device = msg.original_device_config;\n\n// Prepare the SECOND API call to the /job endpoint\nmsg.url = `http://${device.api_ip}/api/job`;\n\n// Re-apply the authentication headers for this second request\nmsg.headers = { 'X-Api-Key': device.api_key };\n\nreturn msg;",
        "outputs": 1,
        "timeout": "",
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1300,
        "y": 360,
        "wires": [
            [
                "23ca3a3983ca05ef",
                "7633245e76a0f219"
            ]
        ]
    },
    {
        "id": "23ca3a3983ca05ef",
        "type": "http request",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call Prusa /job API",
        "method": "GET",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": true,
        "headers": [],
        "x": 1510,
        "y": 500,
        "wires": [
            [
                "bfb231c8765823a8",
                "18c9e99643ee6bcd"
            ]
        ]
    },
    {
        "id": "bfb231c8765823a8",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Parse PrusaLink Data",
        "func": "// --- Get data from previous nodes ---\nconst printer_response = msg.printer_api_response;\nconst job_response = msg.payload;\nconst device = msg.original_device_config;\nconst last_status = flow.get('printer_status_' + device.device_id) || {};\n\n// --- Safety Check ---\nif (!printer_response || !printer_response.state) {\n    node.warn(`No valid /printer response for ${device.friendly_name}. Skipping.`);\n    return null;\n}\n\n// --- Parse Current and Previous States ---\nconst stateFlags = printer_response.state?.flags ?? {};\nconst is_printing_now = stateFlags.printing ?? false;\nconst was_printing = last_status.is_printing ?? false;\nconst current_filename = job_response?.job?.file?.name ?? null;\n\n// --- NEW: Smart Job Creation/Update Logic ---\n// This logic handles the creation of new jobs for reprints.\nif (is_printing_now && !was_printing && current_filename) {\n    // This is a \"Job Start\" event. A print has just begun.\n    // We will create a NEW job record every time this happens.\n    const new_job_msg = {\n        topic: \"CREATE_NEW_PRUSA_JOB\",\n        query: `\n            INSERT INTO print_jobs (device_id, filename, status, start_time)\n            VALUES ($1, $2, 'printing', NOW());\n        `,\n        params: [device.device_id, current_filename]\n    };\n    // Use node.send to fire this off as a separate action.\n    // The main flow will continue in parallel.\n    node.send([null, null, new_job_msg]); // Sending to a NEW 3rd output\n}\n// --- END of NEW Logic ---\n\n// --- Store the current status in memory for the next cycle ---\nflow.set('printer_status_' + device.device_id, {\n    is_printing: is_printing_now,\n    filename: current_filename,\n    device_id: device.device_id\n});\n\n// --- Job Completion Detection (Existing Logic) ---\nif (was_printing && !is_printing_now) {\n    const end_of_job_msg = {\n        topic: \"CALCULATE_FINAL_ENERGY\",\n        params: [last_status.device_id, last_status.filename]\n    };\n    \n    // --- NEW: Add logic to update the job status to 'done' ---\n    const update_job_status_msg = {\n        topic: \"UPDATE_PRUSA_JOB_STATUS\",\n        query: `\n            UPDATE print_jobs \n            SET status = 'done', end_time = NOW(), duration_seconds = EXTRACT(EPOCH FROM (NOW() - start_time))\n            WHERE device_id = $1 AND filename = $2 AND status = 'printing';\n        `,\n        params: [last_status.device_id, last_status.filename]\n    };\n    node.send([null, end_of_job_msg, update_job_status_msg]); // Send to outputs 2 and 3\n}\n\n// --- Prepare the original status insert message for Output 1 ---\n// --- Prepare the main status insert message for Output 1 ---\nconst params = [\n    new Date().toISOString(), // 1\n    device.device_id, // 2\n    printer_response.state?.text ?? 'Unknown', // 3\n    stateFlags.operational ?? false, // 4\n    is_printing_now, // 5\n    stateFlags.paused ?? false, // 6\n    stateFlags.error ?? false, // 7\n    stateFlags.busy ?? false, // 8\n    printer_response.temperature?.tool0?.actual ?? null, // 9\n    printer_response.temperature?.tool0?.target ?? null, // 10\n    printer_response.temperature?.bed?.actual ?? null, // 11\n    printer_response.temperature?.bed?.target ?? null, // 12\n    printer_response.telemetry?.material ?? null, // 13\n    current_filename, // 14\n    (job_response?.progress?.completion ?? 0) * 100, // 15\n    job_response?.progress?.printTimeLeft ?? null, // 16\n    // --- THIS IS THE FIX ---\n    // Add a null placeholder for ambient_temp_c, which PrusaLink does not provide.\n    null // 17\n];\nmsg.params = params;",
        "outputs": 3,
        "timeout": "",
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1840,
        "y": 640,
        "wires": [
            [
                "76faa27c3f22fa95",
                "cda295997d384d1b",
                "3bc77aad3c1f970d"
            ],
            [
                "81d3cb6157d204a7",
                "853372a55c401c65"
            ],
            [
                "3893c4f9f6dfef59",
                "1a68329a7809840d"
            ]
        ]
    },
    {
        "id": "f297e1970a6e9404",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Route by Data Source Strategy",
        "func": "const device = msg.payload;\n\n// If it has an api_ip, it's a PrusaLink device.\nif (device.api_ip && device.api_ip !== '') {\n    // Send to Output 1\n    return [msg, null];\n}\n// Otherwise, if it has a simplyprint_id, it's a SimplyPrint device.\nelse if (device.simplyprint_id) {\n    // Send to Output 2\n    return [null, msg];\n}\n// Ignore devices that don't match.\nreturn null;",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 370,
        "y": 440,
        "wires": [
            [
                "f4ec324598c62401",
                "d72cfa8a09b4ac1a"
            ],
            [
                "9745ef2b3e3aa7e2",
                "b27da203e5c23ee9"
            ]
        ]
    },
    {
        "id": "76faa27c3f22fa95",
        "type": "link out",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Send Prusa Data to DB",
        "mode": "link",
        "links": [
            "af2f0b8c71e0ef6c"
        ],
        "x": 2590,
        "y": 480,
        "wires": [],
        "l": true
    },
    {
        "id": "5dda7fb58e2cb2a2",
        "type": "link out",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call Job Detail Subflow",
        "mode": "link",
        "links": [
            "31749266865874cf"
        ],
        "x": 710,
        "y": 720,
        "wires": [],
        "l": true
    },
    {
        "id": "bf152e33e1198b2b",
        "type": "link in",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "Receive Job Upsert Data",
        "links": [
            "566c89287199eab1"
        ],
        "x": 2930,
        "y": 340,
        "wires": [
            [
                "2686e15ef3e6984e"
            ]
        ],
        "l": true
    },
    {
        "id": "2686e15ef3e6984e",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "Upsert Job Details",
        "query": "INSERT INTO print_jobs (\n    simplyprint_job_id, device_id, start_time, end_time, duration_seconds,\n    status, filename, filament_used_g, gcode_analysis_data, part_metadata,\n    nozzle_diameter, filament_diameter\n) \nVALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)\nON CONFLICT (simplyprint_job_id) \nDO UPDATE SET \n    status = EXCLUDED.status,\n    end_time = EXCLUDED.end_time,\n    duration_seconds = EXCLUDED.duration_seconds,\n    filament_used_g = EXCLUDED.filament_used_g,\n    gcode_analysis_data = EXCLUDED.gcode_analysis_data,\n    part_metadata = EXCLUDED.part_metadata,\n    nozzle_diameter = EXCLUDED.nozzle_diameter,\n    filament_diameter = EXCLUDED.filament_diameter;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 3150,
        "y": 340,
        "wires": [
            []
        ]
    },
    {
        "id": "af2f0b8c71e0ef6c",
        "type": "link in",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "Receive Status Insert Data",
        "links": [
            "76faa27c3f22fa95",
            "d980d78960bfd999"
        ],
        "x": 2910,
        "y": 200,
        "wires": [
            [
                "434602b76f18b34a"
            ]
        ],
        "l": true
    },
    {
        "id": "434602b76f18b34a",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "Insert Standardized Status",
        "query": "INSERT INTO printer_status (\n    timestamp, device_id, state_text, is_operational, is_printing, \n    is_paused, is_error, is_busy, nozzle_temp_actual, nozzle_temp_target, \n    bed_temp_actual, bed_temp_target, material, filename, progress_percent, \n    time_left_seconds, ambient_temp_c\n) \nVALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)\nON CONFLICT (device_id, timestamp) \nDO UPDATE SET \n    state_text = EXCLUDED.state_text, \n    is_operational = EXCLUDED.is_operational, \n    is_printing = EXCLUDED.is_printing, \n    is_paused = EXCLUDED.is_paused, \n    is_error = EXCLUDED.is_error, \n    is_busy = EXCLUDED.is_busy, \n    nozzle_temp_actual = EXCLUDED.nozzle_temp_actual, \n    nozzle_temp_target = EXCLUDED.nozzle_temp_target, \n    bed_temp_actual = EXCLUDED.bed_temp_actual, \n    bed_temp_target = EXCLUDED.bed_temp_target, \n    material = EXCLUDED.material, \n    filename = EXCLUDED.filename, \n    progress_percent = EXCLUDED.progress_percent, \n    time_left_seconds = EXCLUDED.time_left_seconds,\n    ambient_temp_c = EXCLUDED.ambient_temp_c;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 3160,
        "y": 200,
        "wires": [
            []
        ]
    },
    {
        "id": "9745ef2b3e3aa7e2",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Output 2: Route by Data Source Strategy",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "payload",
        "targetType": "msg",
        "statusVal": "",
        "statusType": "auto",
        "x": 740,
        "y": 460,
        "wires": []
    },
    {
        "id": "e4a60772850676ff",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare PrusaLink Request output",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 820,
        "y": 320,
        "wires": []
    },
    {
        "id": "574260bbc0dc2b2f",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call Prusa /printer API output",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1400,
        "y": 240,
        "wires": []
    },
    {
        "id": "7633245e76a0f219",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare Prusa /job Request",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1400,
        "y": 320,
        "wires": []
    },
    {
        "id": "18c9e99643ee6bcd",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call Prusa /job API",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1530,
        "y": 460,
        "wires": []
    },
    {
        "id": "3bc77aad3c1f970d",
        "type": "switch",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Is Prusa Printing?",
        "property": "params[4]",
        "propertyType": "msg",
        "rules": [
            {
                "t": "true"
            }
        ],
        "checkall": "true",
        "repair": false,
        "outputs": 1,
        "x": 2410,
        "y": 640,
        "wires": [
            [
                "38850782ee90eabb",
                "075caf0daf376cc6",
                "95202ab5fa233a47"
            ]
        ]
    },
    {
        "id": "38850782ee90eabb",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Set Params for Energy Subflow",
        "func": "// msg.params[1] is device_id, msg.params[13] is filename\nmsg.params = [msg.params[1], msg.params[13]];\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 2730,
        "y": 560,
        "wires": [
            [
                "6f5a6bdde6455ef0"
            ]
        ]
    },
    {
        "id": "6f5a6bdde6455ef0",
        "type": "link out",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "link out 1",
        "mode": "link",
        "links": [
            "878bdfc6b43e57cb"
        ],
        "x": 3000,
        "y": 560,
        "wires": [],
        "l": true
    },
    {
        "id": "5a0b6ccc23334296",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Check if Job Analyzed",
        "query": "SELECT gcode_analysis_data FROM print_jobs WHERE device_id = $1 AND filename = $2;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 2980,
        "y": 660,
        "wires": [
            [
                "6d7486e2afc97f13"
            ]
        ]
    },
    {
        "id": "6d7486e2afc97f13",
        "type": "switch",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Is Analysis Missing?",
        "property": "payload[0].gcode_analysis_data",
        "propertyType": "msg",
        "rules": [
            {
                "t": "null"
            }
        ],
        "checkall": "true",
        "repair": false,
        "outputs": 1,
        "x": 3220,
        "y": 660,
        "wires": [
            [
                "9fb13978446f7b8a"
            ]
        ]
    },
    {
        "id": "9fb13978446f7b8a",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Prepare G-code Download",
        "func": "const device = msg.original_device_config;\nconst filename = msg.params[13];\n\n// Store these for the final database update\nmsg.device_id_for_update = msg.params[1];\nmsg.filename_for_update = filename;\n\nmsg.headers = { 'X-Api-Key': device.api_key };\nmsg.url = `http://${device.api_ip}/api/files/local/${filename}`;\nmsg.payload = {};\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 3280,
        "y": 700,
        "wires": [
            [
                "8b6805e59ca0e048"
            ]
        ]
    },
    {
        "id": "8b6805e59ca0e048",
        "type": "http request",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Download G-code File",
        "method": "GET",
        "ret": "txt",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 3300,
        "y": 740,
        "wires": [
            [
                "e5f04ef6f5bc94fc"
            ]
        ]
    },
    {
        "id": "e5f04ef6f5bc94fc",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Parse G-code & Prep DB",
        "func": "const gcodeText = msg.payload;\nif (typeof gcodeText !== 'string' || gcodeText.length === 0) {\n    node.warn(\"G-code content was empty, skipping analysis.\");\n    return null;\n}\n\n// --- JavaScript version of your Python parser ---\nconst metadata = {};\nconst pattern_equals = /^;\\s*([^=]+?)\\s*=\\s*(.*)/;\nconst lines = gcodeText.split('\\\\n');\n\nfor (const line of lines) {\n    const match = line.match(pattern_equals);\n    if (match) {\n        const key = match[1].trim();\n        const value = match[2].trim();\n        metadata[key] = value;\n    }\n}\n\nconst analysis_data = {};\nif (metadata.layer_height) {\n    analysis_data.layerHeight = parseFloat(metadata.layer_height);\n}\nif (metadata.model_size) {\n    const dims = metadata.model_size.split(',');\n    if (dims.length === 3) {\n        analysis_data.modelSize = {\n            x: parseFloat(dims[0]),\n            y: parseFloat(dims[1]),\n            z: parseFloat(dims[2])\n        };\n    }\n}\n// --- End of parser ---\n\n// Prepare parameters for the final database update\nmsg.params = [\n    JSON.stringify(analysis_data), // The new analysis object\n    msg.device_id_for_update,\n    msg.filename_for_update\n];\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 3330,
        "y": 780,
        "wires": [
            [
                "060a8b27d87f8bf9"
            ]
        ]
    },
    {
        "id": "060a8b27d87f8bf9",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "UPDATE print_jobs with Analysis",
        "query": "UPDATE print_jobs SET gcode_analysis_data = $1 WHERE device_id = $2 AND filename = $3;\n",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 3380,
        "y": 820,
        "wires": [
            []
        ]
    },
    {
        "id": "f3858a8857ffde13",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Get Previous State",
        "func": "// Get the device_id from the incoming message\nconst deviceId = msg.payload.device_id;\n\n// Retrieve the last known status for this specific device from flow-level memory.\n// The '|| {}' provides a safe default if nothing is stored yet.\nconst lastStatus = flow.get('printer_status_' + deviceId) || {};\n\n// Attach the retrieved last_status to the message so subsequent nodes can access it\nmsg.last_status = lastStatus;\n\n// Pass the message along the flow\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 290,
        "y": 380,
        "wires": [
            [
                "f297e1970a6e9404"
            ]
        ]
    },
    {
        "id": "81d3cb6157d204a7",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Prepare Final Energy Query",
        "func": "// This function will receive a message with device_id and filename\nconst device_id = msg.params[0];\nconst filename = msg.params[1];\n\n// This query will calculate and update the session_energy_wh in one go\nmsg.topic = \"UPDATE_FINAL_ENERGY\";\nmsg.query = `\n    WITH final_energy AS (\n        SELECT energy_total_wh\n        FROM energy_data\n        WHERE device_id = $1\n        ORDER BY timestamp DESC\n        LIMIT 1\n    )\n    UPDATE print_jobs\n    SET session_energy_wh = final_energy.energy_total_wh - print_jobs.start_energy_wh\n    FROM final_energy\n    WHERE print_jobs.device_id = $1\n    AND print_jobs.filename = $2\n    AND print_jobs.start_energy_wh IS NOT NULL;\n`;\nmsg.params = [device_id, filename]; // Parameters for the query\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1900,
        "y": 700,
        "wires": [
            [
                "76e36f5c70691ad5"
            ]
        ]
    },
    {
        "id": "76e36f5c70691ad5",
        "type": "link out",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Trigger Final Energy Calc",
        "mode": "link",
        "links": [
            "b882adb136a0e909"
        ],
        "x": 1930,
        "y": 760,
        "wires": [],
        "l": true,
        "info": "This node triggers the separate Historical Enrichment Flow, which is a major processing step"
    },
    {
        "id": "d43ff076a1a9a7bf",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Call SimplyPrint API output",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1000,
        "y": 660,
        "wires": []
    },
    {
        "id": "b9a4c25e40aeeef0",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Prepare SimplyPrint Request output",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1020,
        "y": 600,
        "wires": []
    },
    {
        "id": "d72cfa8a09b4ac1a",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Output 1: Route by Data Source Strategy",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "payload",
        "targetType": "msg",
        "statusVal": "",
        "statusType": "auto",
        "x": 740,
        "y": 420,
        "wires": []
    },
    {
        "id": "8df1e9e0aa3c3d82",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Group 1: Data Input & Routing",
        "info": "This group's responsibility is to fetch the raw data from its source (the database for configuration, and then the printer APIs).",
        "x": 300,
        "y": 100,
        "wires": []
    },
    {
        "id": "abc0bca12f6f89e4",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Group 2: Data Processing & Enrichment",
        "info": "    This group takes the raw API data, parses it, standardizes it, detects job state changes, and triggers further enrichment processes.",
        "x": 2310,
        "y": 460,
        "wires": []
    },
    {
        "id": "711e7c68cc8edf38",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "Group 3: Data Output",
        "info": "This group's sole responsibility is to take the fully processed and standardized data and save it to the database. It is primarily composed of your \"database sink\" nodes.\n",
        "x": 2900,
        "y": 100,
        "wires": []
    },
    {
        "id": "7e24e1bcd17d804e",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "DB: Get Device Configurations",
        "info": "**Purpose:** Fetches the configuration for all active 3D printers from the `devices` table in the database.\n\n**Trigger:** Fired every 30 seconds by the \"Poll All Printers\" inject node.\n\n**Output:**\n- `msg.payload`: An array of objects, where each object is a row from the `devices` table.\n\n**Next Step:** The payload is passed to a `split` node to process each device individually.",
        "x": 490,
        "y": 260,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "fa5fe3526a66b815",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "Route: PrusaLink or SimplyPrint?",
        "info": "**Purpose:** Inspects the configuration for a single device and routes the flow based on the data source available.\n\n**Inputs:**\n- `msg.payload`: A single device object from the database.\n\n**Logic:**\n- If `api_ip` exists, the device uses the local PrusaLink API. The message is sent to **Output 1**.\n- If `simplyprint_id` exists, the device is managed via the SimplyPrint cloud service. The message is sent to **Output 2**.\n- If neither exists, the message is dropped.\n\n**Outputs:**\n- **Output 1:** For PrusaLink devices.\n- **Output 2:** For SimplyPrint devices.",
        "x": 370,
        "y": 480,
        "wires": []
    },
    {
        "id": "ad0abf33e2e61735",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "API: Get Prusa Printer State",
        "info": "**Purpose:** Makes an HTTP GET request to the `/api/printer` endpoint of a local PrusaLink-enabled printer.\n\n**Inputs:**\n- `msg.url`: The target URL (e.g., http://192.168.1.10/api/printer).\n- `msg.headers`: Contains the `X-Api-Key` for authentication.\n- `msg.original_device_config`: The full database row for this device is preserved for later use.\n\n**Output:**\n- `msg.payload`: The JSON response from the printer, containing state, temperatures, and flags.\n- `msg.original_device_config`: The original device config is passed through.\n\n**Next Step:** The response is passed to the \"Prepare Prusa /job Request\" node to make the second required API call.",
        "x": 1080,
        "y": 200,
        "wires": []
    },
    {
        "id": "721f5a33a2061419",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Process: Parse PrusaLink Response & Detect Job State",
        "info": "**Purpose:** This is the main processing hub for PrusaLink devices. It combines the `/printer` and `/job` API responses, standardizes the data, and detects if a print job has just started or finished.\n\n**Inputs:**\n- `msg.printer_api_response`: The JSON response from the `/printer` endpoint.\n- `msg.payload`: The JSON response from the `/job` endpoint.\n- `msg.original_device_config`: The full database config for the device.\n- `msg.last_status`: The previous state of the printer (is_printing, filename) retrieved from flow memory.\n\n**Logic:**\n1.  Compares `is_printing_now` with `was_printing` from the previous cycle.\n2.  **Job Start Detection:** If `!was_printing && is_printing_now`, it triggers the \"Record Start Energy\" subflow.\n3.  **Job End Detection:** If `was_printing && !is_printing_now`, it triggers the \"Calculate Final Energy\" subflow.\n4.  Formats the combined data into a standardized structure for the `printer_status` database table.\n\n**Outputs:**\n- **Output 1:** A message with standardized `params` for inserting into the `printer_status` table. Sent on every poll.\n- **Output 2:** A trigger message (`CALCULATE_FINAL_ENERGY`) sent *only* when a job has just finished.",
        "x": 2000,
        "y": 520,
        "wires": []
    },
    {
        "id": "f81e90cc3d42a0f9",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Trigger: Enrich SimplyPrint Job",
        "info": "**Purpose:** For SimplyPrint devices, this node triggers the \"Historical Enrichment Flow\".\n\n**Logic:**\n- It passes the live API response and the device's database configuration to the subflow.\n- The subflow is responsible for making additional API calls to SimplyPrint to get rich details about the current job (e.g., filament usage, start/end times, G-code analysis data).\n- This separation keeps the main flow clean, delegating the complex enrichment logic to a dedicated subflow.\n\n**Next Step:** The \"Historical Enrichment Flow\" will execute and eventually send messages to the \"Data Output\" link-in nodes (`Upsert to print_jobs`, `Insert to printer_status`, etc.).",
        "x": 3030,
        "y": 520,
        "wires": []
    },
    {
        "id": "52a6268367a8d644",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "DB: Is G-code Analyzed?",
        "info": "**Purpose:** Prevents re-analyzing the G-code for a print job that is already in progress and has been analyzed.\n\n**Inputs:**\n- `msg.params`: Contains the `device_id` and `filename`.\n\n**Logic:**\n- Queries the `print_jobs` table to check if the `gcode_analysis_data` column is `NULL` for the current job.\n- If the column is `NULL` (meaning it needs analysis), the message is passed to the \"Is Analysis Missing?\" switch.\n\n**Next Step:** If analysis is needed, the flow proceeds to download and parse the G-code file.",
        "x": 2890,
        "y": 620,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "af3255605d249b0d",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Process: Parse G-code Metadata",
        "info": "**Purpose:** Parses the downloaded G-code file text to extract key metadata left by the slicer (e.g., PrusaSlicer).\n\n**Inputs:**\n- `msg.payload`: The raw text content of the `.gcode` file.\n\n**Logic:**\n- Uses regular expressions to find and extract key-value pairs from the G-code comments (lines starting with `;`).\n- It specifically looks for metadata like `layer_height`, `model_size`, etc.\n- The extracted metadata is formatted into a JSON object.\n\n**Output:**\n- `msg.params`: An array containing the JSON analysis data, `device_id`, and `filename`, ready for the final database `UPDATE` query.",
        "x": 3670,
        "y": 820,
        "wires": []
    },
    {
        "id": "f571406301ee9470",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "DB: Insert/Update Printer Status",
        "info": "**Purpose:** Inserts a new row into the `printer_status` time-series table. This serves as a log of the printer's state at a specific point in time.\n\n**Triggered By:**\n- The \"Parse PrusaLink Data\" node for Prusa printers.\n- The \"Historical Enrichment Flow\" for SimplyPrint printers.\n\n**Logic:**\n- The incoming message contains `msg.params`, an array with all the required data points (timestamp, device_id, temps, state, etc.) in a standardized format.\n- An `INSERT` query is executed. It uses `ON CONFLICT DO UPDATE` to handle rare cases of duplicate timestamps, ensuring the latest data is always present.",
        "x": 3170,
        "y": 160,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "526fc8f040df3cba",
        "type": "comment",
        "z": "c4582a5c3c4d6d09",
        "g": "5f3f1baac114fb7c",
        "name": "DB: Upsert Print Job",
        "info": "**Purpose:** Inserts a new record into the `print_jobs` table when a job is first detected, or updates an existing record as more details become available (e.g., final status, filament usage).\n\n**Triggered By:**\n- The \"Historical Enrichment Flow\" after fetching job details from the SimplyPrint API.\n\n**Logic:**\n- Uses `INSERT ... ON CONFLICT (simplyprint_job_id) DO UPDATE`.\n- This allows the flow to create the job record once and then enrich it over time without creating duplicates.",
        "x": 3130,
        "y": 300,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "c59b3ae72ac4073a",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Check if Prusa Job is Analyzed",
        "query": "-- Check if analysis data already exists for this job\nSELECT gcode_analysis_data FROM print_jobs WHERE device_id = $1 AND filename = $2;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 2610,
        "y": 780,
        "wires": [
            [
                "de12c14d1a3c57d5"
            ]
        ]
    },
    {
        "id": "075caf0daf376cc6",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Prepare Job Analysis Check",
        "func": "const device_id = msg.params[1];\nconst filename = msg.params[13];\n\n// --- THIS IS THE FIX ---\n// Overwrite msg.params with a NEW array containing ONLY the 2 parameters\n// that the \"Check if Job Analyzed\" node is expecting.\nmsg.params = [device_id, filename];\n\n// We also need to preserve the original device configuration from the start of the flow\n// so that we can use it later to get the api_ip and api_key for downloading the G-code.\nmsg.preserved_device_config = msg.original_device_config;\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 2540,
        "y": 740,
        "wires": [
            [
                "c59b3ae72ac4073a"
            ]
        ]
    },
    {
        "id": "de12c14d1a3c57d5",
        "type": "switch",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Is Analysis Missing?",
        "property": "payload[0].gcode_analysis_data",
        "propertyType": "msg",
        "rules": [
            {
                "t": "null"
            }
        ],
        "checkall": "true",
        "repair": false,
        "outputs": 1,
        "x": 2640,
        "y": 820,
        "wires": [
            [
                "f56cc50a4481ddce"
            ]
        ]
    },
    {
        "id": "f56cc50a4481ddce",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Build PrusaLink G-code URL",
        "func": "// The device config was preserved in the \"Prepare Analysis Check\" node.\nconst device = msg.preserved_device_config;\n// The filename was the second parameter we set.\nconst filename = msg.params[1];\n\n// Preserve the device_id and filename for the final database update.\nmsg.device_id_for_update = msg.params[0];\nmsg.filename_for_update = msg.params[1];\n\n// PrusaLink API endpoint for downloading a file from the local SD card.\nmsg.url = `http://${device.api_ip}/api/files/local/${encodeURIComponent(filename)}`;\n\nmsg.headers = {\n    'X-Api-Key': device.api_key\n};\n\n// Clear payload for the GET request.\nmsg.payload = {};\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 2710,
        "y": 860,
        "wires": [
            [
                "31b1ea47700de376"
            ]
        ]
    },
    {
        "id": "31b1ea47700de376",
        "type": "http request",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "API: Download G-code",
        "method": "GET",
        "ret": "txt",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 2740,
        "y": 900,
        "wires": [
            [
                "4958a8c7f64eaabd"
            ]
        ]
    },
    {
        "id": "4958a8c7f64eaabd",
        "type": "file",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Save to /tmp/prusa_gcode.gcode",
        "filename": "/tmp/prusa_gcode.gcode",
        "filenameType": "str",
        "appendNewline": false,
        "createDir": true,
        "overwriteFile": "true",
        "encoding": "none",
        "x": 2820,
        "y": 940,
        "wires": [
            [
                "af950d41f1c8252e"
            ]
        ]
    },
    {
        "id": "af950d41f1c8252e",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Build Prusa Analyzer Command",
        "func": "// We need a unique job ID for the analyzer script.\n// PrusaLink jobs don't have a numeric ID like SimplyPrint,\n// so we will create a unique identifier from the device and filename.\nconst unique_job_id = msg.device_id_for_update + '_' + msg.filename_for_update;\n\n// The main python command is in the exec node.\n// This payload contains only the arguments for the script.\nmsg.payload = `/home/ubuntu/monitor_ml/gcode_analyzer.py --file /tmp/prusa_gcode.gcode --jobid '${unique_job_id}'`;\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 2870,
        "y": 980,
        "wires": [
            [
                "b8edd70e91510d03"
            ]
        ]
    },
    {
        "id": "b8edd70e91510d03",
        "type": "exec",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "command": "/home/ubuntu/monitor_ml/venv/bin/python",
        "addpay": "payload",
        "append": "",
        "useSpawn": "false",
        "timer": "",
        "winHide": false,
        "oldrc": false,
        "name": "Run G-code Analyzer",
        "x": 2880,
        "y": 1020,
        "wires": [
            [
                "19af9013e2ec06d3"
            ],
            [],
            []
        ]
    },
    {
        "id": "19af9013e2ec06d3",
        "type": "json",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Parse Analyzer Output",
        "property": "payload",
        "action": "obj",
        "pretty": false,
        "x": 2940,
        "y": 1060,
        "wires": [
            [
                "cb5a40c591c23af4"
            ]
        ]
    },
    {
        "id": "cb5a40c591c23af4",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Prepare Prusa Analysis for DB",
        "func": "const analysisResult = msg.payload;\n\n// Stop if the script failed to produce a thumbnail.\nif (!analysisResult || !analysisResult.thumbnail_url) {\n    node.warn(\"Prusa G-code analysis did not return a thumbnail. Stopping.\");\n    return null;\n}\n\n// Prepare parameters for the final SQL UPDATE query.\n// [$1: analysis_data, $2: thumbnail_url, $3: device_id, $4: filename]\nmsg.params = [\n    JSON.stringify(analysisResult),\n    analysisResult.thumbnail_url,\n    msg.device_id_for_update,\n    msg.filename_for_update\n];\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 3010,
        "y": 1100,
        "wires": [
            [
                "c4637953a58714ae"
            ]
        ]
    },
    {
        "id": "c4637953a58714ae",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "DB: UPDATE Job with Analysis",
        "query": "UPDATE print_jobs\nSET\n  gcode_analysis_data = $1,\n  thumbnail_url = $2\nWHERE\n  device_id = $3 AND filename = $4;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 3040,
        "y": 1140,
        "wires": [
            []
        ]
    },
    {
        "id": "08941a4001c4ec9a",
        "type": "inject",
        "z": "c4582a5c3c4d6d09",
        "g": "b1bed7a2a4a4d39a",
        "name": "3389466",
        "props": [
            {
                "p": "original_device_config",
                "v": "{\"device_id\":\"prusa_i3_mk2_virtuell_schreibtisch\",\"device_model\":\"i3 MK2\",\"shelly_id\":null,\"api_ip\":null,\"api_key\":null,\"friendly_name\":\"Prusa i3 MK2 virtuell Schreibtisch\",\"location\":\"Fab Lab Fabulous St. Pauli\",\"notes\":null,\"printer_size_category\":\"Unknown\",\"simplyprint_id\":\"35675\",\"last_seen\":\"2025-07-18T06:26:34.482Z\",\"sp_company_id\":\"17378\",\"sp_api_key\":\"a012f5a8-4046-4fb5-98fe-a95d977fa3c5\",\"gcode_preview_host\":null,\"gcode_preview_api_key\":null,\"bed_width\":250,\"bed_depth\":210}",
                "vt": "json"
            },
            {
                "p": "payload"
            },
            {
                "p": "live_data",
                "v": "{\"data\":[{\"id\":35675,\"job\":{\"uid\":\"4f200e18-2230-4425-96cc-c1c5eec3e820\"},\"printer\":{\"state\":\"operational\"}}]}",
                "vt": "json"
            }
        ],
        "repeat": "",
        "crontab": "",
        "once": false,
        "onceDelay": 0.1,
        "topic": "",
        "payload": "{\"data\":[{\"id\":35675,\"job\":{\"uid\":\"4f200e18-2230-4425-96cc-c1c5eec3e820\"},\"printer\":{\"state\":\"operational\"}}]}",
        "payloadType": "json",
        "x": 360,
        "y": 720,
        "wires": [
            [
                "5dda7fb58e2cb2a2"
            ]
        ]
    },
    {
        "id": "95202ab5fa233a47",
        "type": "function",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Format Params for Analysis Check",
        "func": "// This function receives the full message with 16 parameters from the main status update.\n// It correctly extracts only the two parameters needed for the next database node.\n\n// Preserve the original device config for the download step later in the chain.\nmsg.preserved_device_config = msg.original_device_config;\n\n// Overwrite msg.params with a new array containing only device_id and filename.\nmsg.params = [\n    msg.params[1], // device_id\n    msg.params[13] // filename\n];\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 2720,
        "y": 660,
        "wires": [
            [
                "5a0b6ccc23334296"
            ]
        ]
    },
    {
        "id": "cda295997d384d1b",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "debug 13",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1970,
        "y": 580,
        "wires": []
    },
    {
        "id": "3893c4f9f6dfef59",
        "type": "postgresql",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "Prusa Job State Handler",
        "query": "",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 2200,
        "y": 660,
        "wires": [
            []
        ]
    },
    {
        "id": "1a68329a7809840d",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "debug 15",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 2170,
        "y": 780,
        "wires": []
    },
    {
        "id": "853372a55c401c65",
        "type": "debug",
        "z": "c4582a5c3c4d6d09",
        "g": "39cad17b39cec1d1",
        "name": "debug 16",
        "active": false,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 2250,
        "y": 600,
        "wires": []
    },
    {
        "id": "31749266865874cf",
        "type": "link in",
        "z": "088fab733419c707",
        "g": "d46e71e1a4ec093a",
        "name": "Get Rich Details for Job1",
        "links": [
            "5dda7fb58e2cb2a2"
        ],
        "x": 370,
        "y": 460,
        "wires": [
            [
                "9253f90316936f73"
            ]
        ],
        "l": true,
        "info": "**Purpose:** The entry point for this sub-flow. It listens for trigger messages from the main `Master Ingestion Flow`.\r\n\r\n**Input:** A `msg` object containing `msg.original_device_config` and `msg.payload` (with the live data from the initial poll)."
    },
    {
        "id": "9253f90316936f73",
        "type": "function",
        "z": "088fab733419c707",
        "g": "d46e71e1a4ec093a",
        "name": "Prepare Single Job Request",
        "func": "const live_data = msg.payload;\nconst device = msg.original_device_config;\n\n// --- DYNAMICALLY FIND THE CORRECT PRINTER ---\nconst target_printer_id = parseInt(device.simplyprint_id, 10);\nconst printer_data = live_data.data?.find(p => p.id === target_printer_id);\n\nif (!printer_data) {\n    node.error(`Prepare Request Error: Did not find printer with ID ${target_printer_id} in API response.`, msg);\n    return null;\n}\n\nmsg.live_data = live_data;\n\n// --- CHECK FOR JOB UID ---\nconst job_uid = printer_data?.job?.uid;\n\nif (!job_uid) {\n    msg.payload = {};\n    return [null, msg]; // Bypass to output 2\n}\n\n// --- PREPARE THE JOB DETAILS REQUEST ---\nconst url = `https://api.simplyprint.io/${device.sp_company_id}/jobs/GetDetails?id=${job_uid}`;\n\n// --- NEW LOGGING ---\nnode.log(\"-----------------------------------------\");\nnode.log(`Found job_uid: ${job_uid}`);\nnode.log(`Preparing to call URL: ${url}`);\nnode.log(\"-----------------------------------------\");\n// --- END NEW LOGGING ---\n\nmsg.method = \"GET\";\nmsg.headers = { 'X-API-KEY': device.sp_api_key };\nmsg.url = url;\nmsg.payload = {};\n\nreturn [msg, null]; // Continue to HTTP Request node",
        "outputs": 2,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 660,
        "y": 460,
        "wires": [
            [
                "4582f5ee6c82a831",
                "856d2b19e2a0d021"
            ],
            [
                "4abf6ef935ae28bb",
                "bc7506c79a70c5d8"
            ]
        ],
        "info": "**Purpose:** Prepares the API call to fetch detailed information for the currently active print job.\r\n\r\n**Logic:**\r\n1.  Finds the specific printer's data within the `live_data` payload.\r\n2.  Extracts the unique job identifier (`job_uid`). If no job is active, the flow is bypassed.\r\n3.  Constructs the specific URL for the SimplyPrint `/jobs/GetDetails` API endpoint using the `job_uid`.\r\n\r\n**Output:** A correctly formatted `msg` object with `msg.url` and `msg.headers` ready for the `http request` node."
    },
    {
        "id": "4abf6ef935ae28bb",
        "type": "function",
        "z": "088fab733419c707",
        "g": "2406f1dc5d32b76a",
        "name": "Parse and Merge All Data",
        "func": "// --- Get data from previous nodes --- \nconst job_details = msg.payload.job;\nconst live_data = msg.live_data;\nconst device = msg.original_device_config;\nconst last_status = flow.get('printer_status_' + device.device_id) || {};\n\n// --- Find the correct printer ---\nconst target_printer_id = parseInt(device.simplyprint_id, 10);\nconst api_response_data = live_data.data?.find(p => p.id === target_printer_id);\n\nif (!api_response_data) {\n    node.error(`Parse/Merge Error: Did not find printer with ID ${target_printer_id}.`, msg);\n    return null;\n}\n\n// --- Unify the Filename and State ---\nconst current_filename = job_details?.file || api_response_data.job?.file || null;\nconst stateText = api_response_data.printer?.state?.charAt(0).toUpperCase() + api_response_data.printer.state.slice(1) || 'Unknown';\nconst is_printing_now = ['printing', 'heating'].includes(stateText.toLowerCase());\nconst was_printing = last_status.is_printing ?? false;\n\n// --- Initialize all outgoing messages ---\nlet msg_job_upsert = null;\nlet msg_status_update = null;\nlet msg_end_of_job = null;\nlet msg_start_energy_trigger = null;\nlet msg_gcode_analysis_trigger = null;\n\n// --- Job Completion Detection ---\nif (was_printing && !is_printing_now && last_status.filename) {\n    msg_end_of_job = {\n        topic: \"CALCULATE_FINAL_ENERGY\",\n        params: [last_status.device_id, last_status.filename]\n    };\n}\n\n// --- Update flow memory for the NEXT cycle ---\nflow.set('printer_status_' + device.device_id, {\n    is_printing: is_printing_now,\n    filename: current_filename,\n    device_id: device.device_id\n});\n\n// --- Prepare Status Update ---\n// --- Prepare Status Update ---\nmsg_status_update = {\n    topic: \"INSERT_PRINTER_STATUS\",\n    params: [\n        new Date().toISOString(), // 1\n        device.device_id, // 2\n        stateText, // 3\n        stateText.toLowerCase() !== 'offline', // 4\n        is_printing_now, // 5\n        stateText.toLowerCase() === 'paused', // 6\n        stateText.toLowerCase() === 'error', // 7\n        ['printing', 'paused', 'heating'].includes(stateText.toLowerCase()), // 8\n        api_response_data.printer.temps?.current?.tool?.[0] ?? null, // 9\n        api_response_data.printer.temps?.target?.tool?.[0] ?? null, // 10\n        api_response_data.printer.temps?.current?.bed ?? null, // 11\n        api_response_data.printer.temps?.target?.bed ?? null, // 12\n        api_response_data.filament?.[0]?.type?.name ?? null, // 13\n        current_filename, // 14\n        api_response_data.job?.percentage ?? null, // 15\n        api_response_data.job?.time ?? null, // 16\n        // THE NEW PARAMETER\n        api_response_data.printer.temps?.ambient ?? null // 17\n    ]\n};\n\n// --- Prepare Job Upsert, Triggers, and NEW Part Metadata Logic ---\nif (job_details && job_details.id) {\n    const gcodeAnalysis = job_details.analysis ? JSON.stringify(job_details.analysis) : null;\n    let filamentGrams = null;\n    if (job_details.filament?.e0?.fil?.[0]?.gram) {\n        filamentGrams = job_details.filament.e0.fil[0].gram;\n    }\n\n// ================== NEW LOGIC START ==================\nlet partMetadata = null;\nif (Array.isArray(job_details.customFields) && job_details.customFields.length > 0) {\n    const modelDataField = job_details.customFields.find(field => field.id === 'modeldata');\n    \n    if (modelDataField && modelDataField.value && typeof modelDataField.value.string === 'string') {\n        let rawString = modelDataField.value.string;\n        \n        try {\n            // Find the first occurrence of '['\n            const startIndex = rawString.indexOf('[');\n            // Find the last occurrence of ']'\n            const endIndex = rawString.lastIndexOf(']');\n            \n            if (startIndex !== -1 && endIndex !== -1 && endIndex > startIndex) {\n                // Extract the substring between the first '[' and last ']'\n                let jsonArrayString = rawString.substring(startIndex, endIndex + 1);\n                \n                // Replace all single quotes with double quotes\n                jsonArrayString = jsonArrayString.replace(/'/g, '\"');\n                \n                // Parse the clean string\n                partMetadata = JSON.parse(jsonArrayString);\n            } else {\n                node.warn(`Could not find a JSON array '[...]' in modelData string: ${rawString}`);\n            }\n\n        } catch (e) {\n            node.warn(`Could not parse cleaned modelData for job ${job_details.id}. Error: ${e.message}`);\n        }\n    }\n}\n// =================== NEW LOGIC END ===================\n    msg_job_upsert = {\n        topic: \"UPSERT_PRINT_JOB\",\n        params: [\n            job_details.id.toString(), // 1\n            device.device_id, // 2\n            job_details.started, // 3\n            job_details.ended, // 4\n            job_details.totalPrintTime, // 5\n\n            // CORRECTED: Use the detailed state from the job_details\n            job_details.state, // 6\n\n            current_filename, // 7\n            filamentGrams, // 8\n            gcodeAnalysis, // 9\n            partMetadata ? JSON.stringify(partMetadata) : null, // 10\n\n            // NEW PARAMETERS\n            job_details.analysis?.nozzleSize ?? null, // 11 - Get nozzle size from analysis\n            msg.payload.filament?.[0]?.dia ?? null // 12 - Get filament diameter from main payload\n        ]\n    };\n\n    if (is_printing_now && !was_printing && current_filename) {\n        msg_start_energy_trigger = {\n            topic: \"RECORD_START_ENERGY\",\n            params: [device.device_id, current_filename]\n        };\n    }\n\n    if (current_filename && device.gcode_preview_host && device.gcode_preview_api_key) {\n        msg_gcode_analysis_trigger = {\n            topic: \"ANALYZE_GCODE\",\n            job_id: job_details.id.toString(),\n            filename: current_filename,\n            gcode_host: device.gcode_preview_host,\n            gcode_api_key: device.gcode_preview_api_key,\n            job_details: job_details,\n            original_device_config: device\n        };\n    }\n}\n\nreturn [msg_job_upsert, msg_status_update, msg_end_of_job, msg_start_energy_trigger, msg_gcode_analysis_trigger];",
        "outputs": 5,
        "timeout": "",
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1210,
        "y": 460,
        "wires": [
            [
                "566c89287199eab1"
            ],
            [
                "d980d78960bfd999"
            ],
            [
                "235f4c81c8825e75"
            ],
            [
                "11be79141838bc02"
            ],
            [
                "548b0a238325e0b8"
            ]
        ],
        "info": "**Purpose:** The central processing hub of this entire flow. It merges all available data sources (live poll, detailed job API) and determines what actions need to be taken.\r\n\r\n**Logic:**\r\n1.  Detects job start/end transitions and prepares trigger messages for energy calculations.\r\n2.  Standardizes the printer status data for insertion into the `printer_status` table.\r\n3.  Parses the `modelData` from the `customFields` array.\r\n4.  Prepares a complete message with all job details (`filament_used_g`, `part_metadata`, etc.) for insertion into the `print_jobs` table.\r\n5.  Prepares a trigger message for the G-code analysis pipeline if a job is active.\r\n\r\n**Outputs:** This node has 5 outputs, each sending a different, specialized message to a `link out` node to trigger a specific action in the main flow or other subflows."
    },
    {
        "id": "566c89287199eab1",
        "type": "link out",
        "z": "088fab733419c707",
        "g": "2406f1dc5d32b76a",
        "name": "Upsert to print_jobs",
        "mode": "link",
        "links": [
            "bf152e33e1198b2b"
        ],
        "x": 1570,
        "y": 360,
        "wires": [],
        "l": true,
        "info": "**Purpose:** Acts as a named portal to send a fully prepared message back to the `Data Output` section of the `Master Ingestion Flow`. This keeps the flow diagram clean by avoiding long wires. This specific link sends the message to update the `print_jobs` table."
    },
    {
        "id": "d980d78960bfd999",
        "type": "link out",
        "z": "088fab733419c707",
        "g": "2406f1dc5d32b76a",
        "name": "Insert to printer_status",
        "mode": "link",
        "links": [
            "af2f0b8c71e0ef6c"
        ],
        "x": 1580,
        "y": 420,
        "wires": [],
        "l": true
    },
    {
        "id": "4582f5ee6c82a831",
        "type": "http request",
        "z": "088fab733419c707",
        "g": "d46e71e1a4ec093a",
        "name": "",
        "method": "GET",
        "ret": "obj",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 890,
        "y": 400,
        "wires": [
            [
                "4abf6ef935ae28bb"
            ]
        ],
        "info": "**Purpose:** Executes the API call to SimplyPrint to get the rich, detailed data for the specific job.\r\n\r\n**Output:** `msg.payload` will contain the full JSON response from the SimplyPrint API for that job, including start/end times, filament usage, and any `customFields`."
    },
    {
        "id": "235f4c81c8825e75",
        "type": "link out",
        "z": "088fab733419c707",
        "g": "2406f1dc5d32b76a",
        "name": "Trigger Final Energy Calc",
        "mode": "link",
        "links": [
            "b882adb136a0e909"
        ],
        "x": 1590,
        "y": 480,
        "wires": [],
        "l": true
    },
    {
        "id": "11be79141838bc02",
        "type": "link out",
        "z": "088fab733419c707",
        "g": "2406f1dc5d32b76a",
        "name": "link out 2",
        "mode": "link",
        "links": [
            "878bdfc6b43e57cb"
        ],
        "x": 1540,
        "y": 520,
        "wires": [],
        "l": true
    },
    {
        "id": "548b0a238325e0b8",
        "type": "function",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Build G-code Download URL",
        "func": "// This node now builds the direct API call and PRESERVES critical data for later nodes.\n\n// --- PRESERVE DATA ---\n// We are copying the data we need into new 'preserved_' properties.\n// This protects them from being overwritten by the http request or exec nodes.\nmsg.preserved_job_id = msg.job_id;\nmsg.preserved_device_config = msg.original_device_config;\nmsg.preserved_job_details = msg.job_details;\n// -------------------\n\nconst device = msg.original_device_config;\n\nmsg.url = `https://api.simplyprint.io/${device.sp_company_id}/printers/DownloadGcode?job_uid=${msg.job_details.uid}`;\n\nmsg.headers = {\n    'X-API-KEY': device.sp_api_key\n};\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 1580,
        "y": 660,
        "wires": [
            [
                "70cdf05dcd27462d"
            ]
        ],
        "info": "**Purpose:** Constructs the correct API URL to download the G-code file for the current job from SimplyPrint.\r\n**Important:** This node was recently fixed to use the correct `/jobs/{uid}/gcode` endpoint. It also preserves key information like the `job_id` for later steps."
    },
    {
        "id": "70cdf05dcd27462d",
        "type": "http request",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Download G-code",
        "method": "GET",
        "ret": "txt",
        "paytoqs": "ignore",
        "url": "",
        "tls": "",
        "persist": false,
        "proxy": "",
        "insecureHTTPParser": false,
        "authType": "",
        "senderr": false,
        "headers": [],
        "x": 1630,
        "y": 720,
        "wires": [
            [
                "7ac7a420743ace0c"
            ]
        ]
    },
    {
        "id": "7ac7a420743ace0c",
        "type": "file",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Save G-code to /tmp",
        "filename": "/tmp/temp_gcode.gcode",
        "filenameType": "str",
        "appendNewline": false,
        "createDir": true,
        "overwriteFile": "true",
        "encoding": "none",
        "x": 1660,
        "y": 780,
        "wires": [
            [
                "a6a79f6ee9526497"
            ]
        ]
    },
    {
        "id": "a6a79f6ee9526497",
        "type": "change",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Build Analyzer Command",
        "rules": [
            {
                "t": "set",
                "p": "payload",
                "pt": "msg",
                "to": "'/home/ubuntu/monitor_ml/gcode_analyzer.py --file /tmp/temp_gcode.gcode --jobid ' & preserved_job_id",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 1670,
        "y": 840,
        "wires": [
            [
                "1895161b40f4b2c6"
            ]
        ]
    },
    {
        "id": "1895161b40f4b2c6",
        "type": "exec",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "command": "/home/ubuntu/monitor_ml/venv/bin/python",
        "addpay": "payload",
        "append": "",
        "useSpawn": "false",
        "timer": "",
        "winHide": false,
        "oldrc": false,
        "name": "Run G-code Analyzer",
        "x": 1680,
        "y": 900,
        "wires": [
            [
                "637017bc129598ca"
            ],
            [],
            []
        ],
        "info": "**Purpose:** Executes the `gcode_analyzer.py` script to extract the thumbnail and perform per-part volume analysis.\r\n**Logic:** It passes the path to the temporarily saved G-code file (`/tmp/temp_gcode.gcode`) and the `job_id` to the script."
    },
    {
        "id": "a849c171e8e54fe4",
        "type": "change",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Prepare Analysis for DB",
        "rules": [
            {
                "t": "set",
                "p": "params",
                "pt": "msg",
                "to": "[payload.thumbnail_url, payload.per_part_analysis, preserved_job_id]",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 2010,
        "y": 940,
        "wires": [
            [
                "fa016904d46e14e2"
            ]
        ]
    },
    {
        "id": "fa016904d46e14e2",
        "type": "postgresql",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "UPDATE Job with Analysis",
        "query": "UPDATE print_jobs \nSET thumbnail_url = $1, per_part_analysis = $2 \nWHERE simplyprint_job_id = $3;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 2040,
        "y": 980,
        "wires": [
            []
        ],
        "info": "**Purpose:** The final step of the analysis pipeline. It takes the results from the Python script and saves them to the correct record in the `print_jobs` table.\r\n**Logic:** Updates the `thumbnail_url` and `per_part_analysis` columns for the specific `simplyprint_job_id`."
    },
    {
        "id": "637017bc129598ca",
        "type": "json",
        "z": "088fab733419c707",
        "g": "ec87e2210a0fba2e",
        "name": "Parse Analyzer Output",
        "property": "payload",
        "action": "obj",
        "pretty": false,
        "x": 1960,
        "y": 900,
        "wires": [
            [
                "a849c171e8e54fe4"
            ]
        ]
    },
    {
        "id": "856d2b19e2a0d021",
        "type": "debug",
        "z": "088fab733419c707",
        "g": "d46e71e1a4ec093a",
        "name": "debug 17",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 830,
        "y": 280,
        "wires": []
    },
    {
        "id": "bc7506c79a70c5d8",
        "type": "debug",
        "z": "088fab733419c707",
        "g": "d46e71e1a4ec093a",
        "name": "debug 18",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 810,
        "y": 560,
        "wires": []
    },
    {
        "id": "878bdfc6b43e57cb",
        "type": "link in",
        "z": "efc63501e85537ea",
        "name": "Trigger Record Start Energy",
        "links": [
            "11be79141838bc02",
            "6f5a6bdde6455ef0"
        ],
        "x": 300,
        "y": 100,
        "wires": [
            [
                "7f9f2abe039b6633"
            ]
        ],
        "l": true,
        "info": "**Purpose:** The entry point for this sub-flow. It listens for trigger messages from the main ingestion flows when a new job is detected.\r\n**Input:** `msg.params` containing `[device_id, filename]`."
    },
    {
        "id": "201a4d3f3c3c73d1",
        "type": "postgresql",
        "z": "efc63501e85537ea",
        "name": "Get Job from DB",
        "query": "SELECT start_energy_wh FROM print_jobs WHERE device_id = $1 AND filename = $2;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 530,
        "y": 200,
        "wires": [
            [
                "35af4e085770ab9f"
            ]
        ],
        "info": "**Purpose:** Checks the `print_jobs` table to see if a `start_energy_wh` value has already been recorded for this specific job.\r\n**Logic:** This prevents the flow from accidentally overwriting the start energy value if it is triggered multiple times for the same job."
    },
    {
        "id": "0833afc4d50143f8",
        "type": "postgresql",
        "z": "efc63501e85537ea",
        "name": "Get Latest energy_total_wh",
        "query": "SELECT energy_total_wh FROM energy_data WHERE device_id = $1 ORDER BY timestamp DESC LIMIT 1;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1340,
        "y": 380,
        "wires": [
            [
                "f2f0c199278d9bcc"
            ]
        ],
        "info": "**Purpose:** Fetches the single most recent `energy_total_wh` value from the `energy_data` table for the specific device.\r\n**Logic:** Queries the `energy_data` hypertable, ordering by `timestamp DESC` and taking the `LIMIT 1` result. This provides the cumulative energy reading at the exact moment the print started."
    },
    {
        "id": "018fb6adb54d8369",
        "type": "postgresql",
        "z": "efc63501e85537ea",
        "name": "UPDATE print_jobs",
        "query": "UPDATE print_jobs SET start_energy_wh = $1 WHERE device_id = $2 AND filename = $3;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 1730,
        "y": 480,
        "wires": [
            [
                "2bc4e3d36526ced3"
            ]
        ],
        "info": "**Purpose:** Updates the `print_jobs` table to store the cumulative energy reading at the beginning of a job.\r\n\r\n**Inputs:**\r\n- `msg.params`: Contains `[energy_total_wh, device_id, filename]`.\r\n\r\n**Logic:**\r\n- Executes an `UPDATE` query to set the `start_energy_wh` column for the specific job that was just started.\r\n- This stored value is crucial for calculating the total energy consumed by the session (`session_energy_wh`) when the job is finished."
    },
    {
        "id": "35af4e085770ab9f",
        "type": "switch",
        "z": "efc63501e85537ea",
        "name": "Did We Find a Job?",
        "property": "payload",
        "propertyType": "msg",
        "rules": [
            {
                "t": "nempty"
            }
        ],
        "checkall": "true",
        "repair": false,
        "outputs": 1,
        "x": 690,
        "y": 240,
        "wires": [
            [
                "8e598ed1e28066d2"
            ]
        ]
    },
    {
        "id": "8e598ed1e28066d2",
        "type": "switch",
        "z": "efc63501e85537ea",
        "name": "Is Start Energy Missing?",
        "property": "payload.0.start_energy_wh",
        "propertyType": "msg",
        "rules": [
            {
                "t": "null"
            }
        ],
        "checkall": "true",
        "repair": false,
        "outputs": 1,
        "x": 890,
        "y": 300,
        "wires": [
            [
                "081319de22b6fc8c"
            ]
        ],
        "info": "**Purpose:** The main control gate for this flow.\r\n**Logic:** It checks if the `start_energy_wh` from the previous query is `null`. If it is `null`, it means we need to record the start energy, and the message is passed through. If it is not `null`, the flow stops here, preventing duplicate writes."
    },
    {
        "id": "7f9f2abe039b6633",
        "type": "delay",
        "z": "efc63501e85537ea",
        "name": "",
        "pauseType": "delay",
        "timeout": "1",
        "timeoutUnits": "seconds",
        "rate": "1",
        "nbRateUnits": "1",
        "rateUnits": "second",
        "randomFirst": "1",
        "randomLast": "5",
        "randomUnits": "seconds",
        "drop": false,
        "allowrate": false,
        "outputs": 1,
        "x": 380,
        "y": 160,
        "wires": [
            [
                "201a4d3f3c3c73d1"
            ]
        ],
        "info": "**Purpose:** Pauses the flow for a very short, random interval (1-5 seconds).\r\n**Logic:** This is a defensive measure to prevent a race condition. It ensures that if the \"job started\" signal arrives at the exact same moment as an energy reading, we wait a second to make sure the latest energy data has been committed to the database before we query it."
    },
    {
        "id": "2bc4e3d36526ced3",
        "type": "debug",
        "z": "efc63501e85537ea",
        "name": "debug 49",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "true",
        "targetType": "full",
        "statusVal": "",
        "statusType": "auto",
        "x": 1760,
        "y": 540,
        "wires": []
    },
    {
        "id": "9634d11f263187fe",
        "type": "debug",
        "z": "efc63501e85537ea",
        "name": "debug 53",
        "active": true,
        "tosidebar": true,
        "console": false,
        "tostatus": false,
        "complete": "false",
        "statusVal": "",
        "statusType": "auto",
        "x": 1700,
        "y": 360,
        "wires": []
    },
    {
        "id": "f2f0c199278d9bcc",
        "type": "change",
        "z": "efc63501e85537ea",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "params",
                "pt": "msg",
                "to": "[payload[0].energy_total_wh, params[0], filename]",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 1520,
        "y": 420,
        "wires": [
            [
                "018fb6adb54d8369",
                "9634d11f263187fe"
            ]
        ]
    },
    {
        "id": "081319de22b6fc8c",
        "type": "change",
        "z": "efc63501e85537ea",
        "name": "",
        "rules": [
            {
                "t": "set",
                "p": "filename",
                "pt": "msg",
                "to": "params[1]",
                "tot": "jsonata"
            },
            {
                "t": "set",
                "p": "params",
                "pt": "msg",
                "to": "[ msg. params[0] ]",
                "tot": "jsonata"
            }
        ],
        "action": "",
        "property": "",
        "from": "",
        "to": "",
        "reg": false,
        "x": 1120,
        "y": 340,
        "wires": [
            [
                "0833afc4d50143f8"
            ]
        ]
    },
    {
        "id": "0b07c1f972d0a066",
        "type": "comment",
        "z": "efc63501e85537ea",
        "name": "DB: Get Latest Energy Reading",
        "info": "**Purpose:** Fetches the single most recent `energy_total_wh` value from the `energy_data` table for a specific device.\n\n**Trigger:** Fired when a new print job is detected to record the starting energy value.\n\n**Logic:**\n- It queries the `energy_data` hypertable, ordering by `timestamp DESC` and taking the `LIMIT 1` result.\n- This provides the cumulative energy reading at the exact moment the print started.",
        "x": 1370,
        "y": 340,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "754dba38ed3317aa",
        "type": "comment",
        "z": "efc63501e85537ea",
        "name": "DB: Set Job Start Energy",
        "info": "**Purpose:** Fetches the single most recent `energy_total_wh` value from the `energy_data` table for a specific device.\n\n**Trigger:** Fired when a new print job is detected to record the starting energy value.\n\n**Logic:**\n- It queries the `energy_data` hypertable, ordering by `timestamp DESC` and taking the `LIMIT 1` result.\n- This provides the cumulative energy reading at the exact moment the print started.",
        "x": 1770,
        "y": 440,
        "wires": [],
        "icon": "font-awesome/fa-database"
    },
    {
        "id": "b882adb136a0e909",
        "type": "link in",
        "z": "f7f46f6cd7efe35e",
        "name": "",
        "links": [
            "235f4c81c8825e75",
            "76e36f5c70691ad5"
        ],
        "x": 290,
        "y": 400,
        "wires": [
            [
                "9fa1aa8f2135c4fb",
                "68ed7d4c1d4b2e52"
            ]
        ],
        "l": true,
        "info": "**Purpose:** The entry point for this sub-flow. It listens for trigger messages from the main ingestion flows when a job has finished.\r\n**Input:** `msg.params` containing `[device_id, filename]`."
    },
    {
        "id": "9fa1aa8f2135c4fb",
        "type": "function",
        "z": "f7f46f6cd7efe35e",
        "d": true,
        "name": "Prepare Final Energy Query",
        "func": "const device_id = msg.params[0];\nconst filename = msg.params[1];\n\n// If for some reason the filename is missing from the previous state, we cannot proceed.\nif (!filename) {\n    node.warn(`Cannot calculate final energy for device ${device_id} because filename is missing.`);\n    return null;\n}\n\n// This powerful query does the entire calculation and update in one atomic database step.\nmsg.query = `\n    WITH final_energy AS (\n        -- First, get the absolute latest total energy reading for this device\n        SELECT energy_total_wh\n        FROM energy_data\n        WHERE device_id = $1\n        ORDER BY timestamp DESC\n        LIMIT 1\n    )\n    -- Now, update the corresponding record in the print_jobs table\n    UPDATE print_jobs\n    -- Set our existing column to the difference between the final energy and the stored start energy\n    SET session_energy_wh = final_energy.energy_total_wh - print_jobs.start_energy_wh\n    FROM final_energy\n    -- We only do this for the specific job that just finished\n    WHERE print_jobs.device_id = $1\n    AND print_jobs.filename = $2\n    -- Crucially, only do this if we have a start_energy_wh to calculate from\n    AND print_jobs.start_energy_wh IS NOT NULL\n    -- And only if we haven't already calculated it (prevents running twice)\n    AND print_jobs.session_energy_wh IS NULL;\n`;\n\n// The parameters for the SQL query\nmsg.params = [device_id, filename];\n\nreturn msg;",
        "outputs": 1,
        "timeout": 0,
        "noerr": 0,
        "initialize": "",
        "finalize": "",
        "libs": [],
        "x": 540,
        "y": 340,
        "wires": [
            [
                "68ed7d4c1d4b2e52"
            ]
        ]
    },
    {
        "id": "68ed7d4c1d4b2e52",
        "type": "postgresql",
        "z": "f7f46f6cd7efe35e",
        "name": "Save Final Energy",
        "query": "WITH final_energy AS (\n    -- First, get the absolute latest total energy reading for this device\n    SELECT energy_total_wh\n    FROM energy_data\n    WHERE device_id = $1 -- Corresponds to msg.params[0]\n    ORDER BY timestamp DESC\n    LIMIT 1\n)\n-- Now, update the corresponding record in the print_jobs table\nUPDATE print_jobs\n-- Set our existing column to the difference between the final energy and the stored start energy\nSET session_energy_wh = final_energy.energy_total_wh - print_jobs.start_energy_wh\nFROM final_energy\n-- We only do this for the specific job that just finished\nWHERE print_jobs.device_id = $1      -- Corresponds to msg.params[0]\nAND print_jobs.filename = $2         -- Corresponds to msg.params[1]\n-- Crucially, only do this if we have a start_energy_wh to calculate from\nAND print_jobs.start_energy_wh IS NOT NULL\n-- And only if we haven't already calculated it (prevents running twice)\nAND print_jobs.session_energy_wh IS NULL;",
        "postgreSQLConfig": "4259e91acb63e17b",
        "split": false,
        "rowsPerMsg": 1,
        "outputs": 1,
        "x": 810,
        "y": 400,
        "wires": [
            []
        ],
        "info": "**Purpose:** Atomically calculates and saves the final energy consumption for a completed print job.\r\n\r\n**Inputs:**\r\n- `msg.params`: An array `[device_id, filename]`.\r\n\r\n**Logic:**\r\n- The query uses a Common Table Expression (CTE) to get the *latest* `energy_total_wh` for the device.\r\n- It then performs an `UPDATE` on the `print_jobs` table.\r\n- It calculates `session_energy_wh` by subtracting the job's `start_energy_wh` from the latest reading.\r\n- The entire operation is atomic, ensuring accuracy and efficiency. Conditions prevent it from running twice on the same job."
    },
    {
        "id": "b5c22f4fd7650821",
        "type": "comment",
        "z": "f7f46f6cd7efe35e",
        "name": "Process: Build Final Energy Query",
        "info": "**Purpose:** Constructs a single, powerful SQL query to calculate and save the final energy consumption for a completed print job.\n\n**Triggered By:** The job completion detection logic in the main flows.\n\n**Logic:**\n- The query uses a Common Table Expression (CTE) to get the *latest* `energy_total_wh` for the device.\n- It then performs an `UPDATE` on the `print_jobs` table.\n- It calculates `session_energy_wh` by subtracting the job's `start_energy_wh` (stored at the beginning of the print) from the latest `energy_total_wh`.\n- This atomic operation ensures the calculation is accurate and efficient.",
        "x": 560,
        "y": 280,
        "wires": []
    }
]
